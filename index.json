[{"uri":"/BIO-BTE-06-L-7/NB04a_Fragmentation_for_peptide_identification.html","title":"NB04a Fragmentation for peptide identification\n","content":"(**\n# NB04a Fragmentation for peptide identification\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB04a_Fragmentation_for_peptide_identification.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB04a_NB04b/NB04a_Fragmentation_for_peptide_identification.ipynb)\n\n1. Understanding MS2 spectra: From peptide to fragment\n2. Simulate MS2 Fragmentation\n3. Questions\n4. References\n\n*)\n\n(**\n## Understanding MS2 spectra: From peptide to fragment\n\nThe currency of information for identification in MS-based proteomics is the fragment ion spectrum (MS/MS spectrum) that is typically \nderived from the fragmentation of a specific peptide in the collision cell of a mass spectrometer. Peptides produce fragments that provide \ninformation on their amino acid sequence. The correct assignment of such a spectrum to a peptide sequence is the central step to link \nm/z values and ion intensities to biology (Nesvizhskii et al. 2007). \n\n![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/FragmentIonNomenclature.PNG)\n\n**Figure 4: The Roepstorff-Fohlmann-Biemann nomenclature of fragment ions.**\nN-terminal and C-terminal peptide fragments result of dissociation of electron bonds along the peptide backbone.\n\nDuring the unimolecular peptide ion dissociation processes, different chemical reactions can lead to different types \nof product ions. The types of ions observed in MS/MS experiments depend on the physicochemical properties of the amino \nacids and their sequence, on the amount of internal energy, and on the peptide\u2019s charge state. In addition, product ion formation \nis strongly influenced by the fragmentation method (Medzihradszky 2005). The most widely used fragmentation methods today \nare low-energy collision-induced dissociation (CID) (Johnson et al. 1987) and electron transfer dissociation \n(ETD) (Mikesh et al. 2006). These methods favor fragmentation along the peptide backbone and result in an N-terminal prefix \nfragment and a C-terminal suffix fragment. The standard nomenclature for the C-terminal fragments is x, y and z whereas the corresponding \nN-terminal fragments are denoted as a, b and c depending on the position where the breakage occurs at the peptide backbone level. The numbering \nof each fragment starts from the N-terminus for a,b,c series and from the C-terminus for x,y,z series (Figure 4). \nOne should keep in mind that during parent ion selection many of the same peptide ions are selected and dissociated into fragments, with the \nresulting fragment ions having different relative abundances according to the preferred fragmentation reaction. In addition to the \nfragmentation along the peptide backbone, fragment ions containing the amino acids R, K, N, or Q can lose ammonia (-17 Da) and are then \ndenoted a*, b* and y*. Fragments containing the amino acids S, T, E, or D may lose water (-18 Da) and are then denoted a\u00B0, b\u00B0 and y\u00B0. \nThese losses do not change the charge of the ions and are observable as natural losses (Forner et al. 2007, Steen and Mann 2004).\n*)\n\n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta5\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: BioFSharp.Mz, 0.1.5-beta\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen Plotly.NET\nopen BioFSharp\n\n(**\n## Simulate MS2 Fragmentation\n\nFor the simulation we first define a short peptide. The peptide we take for this example is from rbcL.\n*)\n\n// Code-Block 1\n\nlet peptide = \n    \u0022DTDILAAFR\u0022\n    |\u003E BioList.ofAminoAcidString\n\npeptide\n\n(***include-it***)\n\n(**\nIn the \u0060Mz\u0060 namespace of [BioFSharp](https://csbiology.github.io/BioFSharp/), we can find a function that can \ngenerate the theoretical series of y-ions from the given peptide. This function provides a lot of information, but we are only interested \nin the mass. Notice, that we do not know the intesity of the fragment ions and just use \u00271.\u0027 for simulation.\n*)\n\n// Code-Block 2\n\nlet ionSeriesY =\n    peptide\n    |\u003E Mz.Fragmentation.Series.yOfBioList BioItem.initMonoisoMassWithMemP\n    |\u003E List.map (fun aac -\u003E aac.MainPeak.Mass,1.)\n    \nionSeriesY\n\n(***include-it***)\n\n(**\nSimilarly, we can simulate the b-ion series.\n*)\n\n// Code-Block 3\n\nlet ionSeriesB =\n    peptide\n    |\u003E Mz.Fragmentation.Series.bOfBioList BioItem.initMonoisoMassWithMemP\n    |\u003E List.map (fun aac -\u003E aac.MainPeak.Mass,1.)\n\nionSeriesB\n\n(***include-it***)\n\n(**\nNow, we can just plot the simulated data and look at our theoretical spectrum.\n*)\n\n// Code-Block 4\n\nlet ionChart =\n    [    \n        Chart.Column (ionSeriesB, Name=\u0022b ions\u0022)\n        Chart.Column (ionSeriesY, Name=\u0022y ions\u0022)\n    ]\n    |\u003E Chart.Combine\nionChart\n(***hide***)\nionChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Questions:\n\n1. Why are ms1 spectra not sufficent for peptide identification?\n2. How can fragmentation help with this?\n3. For an oligopeptide consisting of 3 amino acids, roughly estimate the number of possible fragments if only cosidering b/y fragments or abc/xyz fragments. What advantages and disadvantages might only considering b/y fragments have?\n\n\n*)\n\n(**\n## References\n\n31. Nesvizhskii, A. I., Vitek, O. \u0026 Aebersold, R. Analysis and validation of proteomic data generated by tandem mass spectrometry. Nature methods 4, 787\u2013797; 10.1038/nmeth1088 (2007).\n32. Medzihradszky, K. F. Peptide sequence analysis. Method Enzymol 402, 209\u2013244; 10.1016/S0076-6879(05)02007-0 (2005).\n33. Johnson, R. S., Martin, S. A., Biemann, K., Stults, J. T. \u0026 Watson, J. T. Novel fragmentation process of peptides by collision-induced decomposition in a tandem mass spectrometer: differentiation of leucine and isoleucine. Anal. Chem. 59, 2621\u20132625; 10.1021/Ac00148a019 (1987).\n34. Mikesh, L. M. et al. The utility of ETD mass spectrometry in proteomic analysis. Biochimica et biophysica acta 1764, 1811\u20131822; 10.1016/j.bbapap.2006.10.003 (2006).\n35. Forner, F., Foster, L. J. \u0026 Toppo, S. Mass spectrometry data analysis in the proteomics era. Curr Bioinform 2, 63\u201393; 10.2174/157489307779314285 (2007).\n36. Steen, H. \u0026 Mann, M. The ABC\u0027s (and XYZ\u0027s) of peptide sequencing. Nat. Rev. Mol. Cell Biol. 5, 699\u2013711; 10.1038/nrm1468 (2004).\n*)\n"},{"uri":"/BIO-BTE-06-L-7/index.html","title":"BIO-BTE-06-L-7\n","content":"(**\n# BIO-BTE-06-L-7\n\u003Cbr\u003E\n## Course objective and procedure\n\nA typical modern proteomics workflow reaches from the experiment and measurement over deconvolution, identification, \nquantification, protein assembly and statistical analysis. This shows that independent from the different specialized \nworkflows at hand, the computational part in proteomics is noticeable.\n\nThe objective of this course is to provide insights in both aspects. Now, is time to start the computational proteomics part. In the following notebooks you will learn: \n\n1. How to model growth for a defined cell number to relate the findings in your proteomics experiments to a meaningful basis.\n2. Getting in-silico information about the proteome of interest to be able to make sense out of your experimental measurements.\n3. How to access and look at your measurements from an m/z perspective and what it is that we actually measure.\n4. How does peptide or protein identification work computationally?\n5. What must be done to quantify a peptide?\n\nThe most hands-on approach to provide those insights is to use a combination of explanatory text, images, interactive charts, \nand program code. This will be combined within interactive notebooks, that allow you to play around with the code examples and learn.\n\nIn this course, we want to support your coding literacy by a practical learning approach without the attempt to detail every mechanisms of the \nprogramming language. This means that the focus is on reading, understanding, and learning to manipulate the code not on coding itself.\n\nHowever, in the beginning you will get a rapid introduction into F# programming that should allow you to understand code \nand do some manipulations to achieve your desired outcome.\n\n## Schedule\n\n| Day      | Topic                                 | Notebooks        |\n|----------|---------------------------------------|------------------|\n| 15.03.21 | Getting started                       |                  |\n| 16.03.21 | Coding literacy                       | 00a; 00b         |\n| 17.03.21 | 1: Growth Model and Cell number       | 01a; 01b         |\n| 18.03.21 | 2: In-silico proteome analysis        | 02a; 02b; 02c    |\n| 19.03.21 | 3: Understanding the Data             | 03a; 03b; 03c    |\n| 22.03.21 | 4: Protein and Peptide identification | 04a; 04b         |\n| 23.03.21 | 5: Peptide quantification             | 05a              |\n| 24.03.21 | Analysing the course Experiment       | 06a              |\n| 25.03.21 | Analysing the course Experiment       | 06b              |\n| 26.03.21 | Analysing the course Experiment       | 06c              |\n\n## Getting started\n\n* Download the latest stable build for [Visual Studio Code](https://code.visualstudio.com/) and install it.\n* Download the recommended [.NET SDK](https://dotnet.microsoft.com/download) and install it.\n* Open Visual Studio Code, navigate to the \u0022Extensions\u0022 tab and install\n    * .NET Interactive Notebooks\n    * Ionide-fsharp\n    \n    ![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/CodeExtensions.png)\n\n* Download the current notebook from the page linked on the left.\n\n    ![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/DownloadNotebook.png)\n\n* In Visual Studio Code press \u0060Strg \u002B Shift \u002B P\u0060 and klick on \u0060.NET Interactive Open notebook\u0060.\n\n    ![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/OpenNotebook.png)\n\n* Navigate to the location of your notebook and open it.\n* Notebooks contain Text- and Codeblocks:\n    * Adding a new Text- or Codeblock can be done by hovering at the upper or lower border of an existing block:\n\n    ![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/AddingBlock.png)\n\n    * Working with Textblocks:\n        You can edit a Textblock by doubleklicking on it. Inside a Textblock you can write plain text or style it with [Markdown](https://en.wikipedia.org/wiki/Markdown).\n        Once you are finished you can press the \u0060Esc\u0060 button.\n    * Working with Codeblocks:\n        You can start editing any Codeblock by clicking in it. In there you can start writing your own code or edit existing code. Once you are done you can execute the Codeblock by pressing \u0060Strg \u002B Alt \u002B Enter\u0060.\n        If you want to execute all codeblocks at once, you can press on the two arrows in the upper right corner of the notebook:\n\n    ![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/ExecuteAll.png)\n*)\n"},{"uri":"/BIO-BTE-06-L-7/NB03a_Retention_time_and_scan_time.html","title":"NB03a Retention time and scan time\n","content":"(**\n# NB03a Retention time and scan time\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB03a_Retention_time_and_scan_time.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB03a_NB03b_NB03c/NB03a_Retention_time_and_scan_time.ipynb)\n\n1. Retention time and scan time\n    1. m/z calculation of the digested peptides\n    2. Determination of peptide hydrophobicity\n\n*)\n\n(**\n## Retention time and scan time\n\nIn general, peptides are separated by one or more steps of liquid chromatography (LC). The retention time (RT) is the time when the measured \npeptides were eluting from the column and is therefore influenced by the physicochemical interaction of the particular peptide with the \ncolumn material. Scan time is basically synonym to retention time, but more from the point of view of the device.\n\nThe aim of this notebook is to understand that even though peptides are roughly separated by the LC, multiple peptides elute at the same \nretention time and are recorded within one MS1 spectrum. Here, we will simulate a MS1 spectrum by random sampling from \nour previously generated peptide-mass distribution. Further, we will try to improve our simulation by incorporating information about the peptide \nhydrophobicity. It is a only a crude model, but considers the fact that less hydrophobic peptides elute faster from the 13C LC column.\n\nAs always, we start by loading our famous libraries.\n*)\n\n#r \u0022nuget: FSharp.Stats, 0.4.0\u0022\n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta5\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: BIO-BTE-06-L-7_Aux, 0.0.1\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen BioFSharp\nopen Plotly.NET\nopen BioFSharp.Elements\nopen BIO_BTE_06_L_7_Aux\nopen FS3_Aux\nopen Retention_time_and_scan_time_Aux\nopen System.IO\n\nopen FSharp.Stats\n\n(**\n## m/z calculation of the digested peptides\n\nI think you remember the protein digestion process from the privious notebook (see: *NB02b\\_Digestion\\_and\\_mass\\_calculation.ipynb* ). This time we also remember the peptide sequence, because we need it later for hydrophobicity calculation. \n*)\n\n// Code-Block 1\n\nlet directory = __SOURCE_DIRECTORY__\nlet path = Path.Combine[|directory;\u0022downloads/Chlamy_JGI5_5(Cp_Mp).fasta\u0022|]\ndownloadFile path \u0022Chlamy_JGI5_5(Cp_Mp).fasta\u0022 \u0022bio-bte-06-l-7\u0022\n// with /../ we navigate a directory \npath\n\nlet peptideAndMasses = \n    path\n    |\u003E IO.FastA.fromFile BioArray.ofAminoAcidString\n    |\u003E Seq.toArray\n    |\u003E Array.mapi (fun i fastAItem -\u003E\n        Digestion.BioArray.digest Digestion.Table.Trypsin i fastAItem.Sequence\n        |\u003E Digestion.BioArray.concernMissCleavages 0 0\n        )\n    |\u003E Array.concat\n    |\u003E Array.map (fun peptide -\u003E\n        // calculate mass for each peptide\n        peptide.PepSequence, BioSeq.toMonoisotopicMassWith (BioItem.monoisoMass ModificationInfo.Table.H2O) peptide.PepSequence\n        )\n\npeptideAndMasses |\u003E Array.head\n\n(***include-it***)\n\n(**\nCalculate the single and double charged m/z for all peptides and combine both in a single collection.\n*)\n\n// Code-Block 2\n\n// calculate m/z for each peptide z=1\nlet singleChargedPeptides =\n    peptideAndMasses\n    // we only consider peptides longer than 6 amino acids \n    |\u003E Array.filter (fun (peptide,ucMass) -\u003E peptide.Length \u003E=7)\n    |\u003E Array.map (fun (peptide,ucMass) -\u003E peptide, Mass.toMZ ucMass 1.) \n\n// calculate m/z for each peptide z=2\nlet doubleChargedPeptides =\n    peptideAndMasses\n    // we only consider peptides longer than 6 amino acids \n    |\u003E Array.filter (fun (peptide,ucMass) -\u003E peptide.Length \u003E=7)\n    |\u003E Array.map (fun (peptide,ucMass) -\u003E peptide, Mass.toMZ ucMass 2.) \n\n// combine this two    \nlet chargedPeptides =\n    Array.concat [singleChargedPeptides;doubleChargedPeptides]\n\n\nchargedPeptides.[1]\n\n(***include-it***)\n\n(**\nNow, we can sample our random \u0022MS1\u0022 spectrum from this collection of m/z.\n*)\n\n// Code-Block 3\n\n// initialze a random generator \nlet rnd = new System.Random()\n\n// sample n random peptides from all Chlamydomonas reinhardtii peptides\nlet chargedPeptideChar =\n    Array.sampleWithOutReplacement rnd chargedPeptides 100\n    // we only want the m/z\n    |\u003E Array.map (fun (peptide,mz) -\u003E mz,1.) \n    |\u003E Chart.Column\n    |\u003E Chart.withX_AxisStyle(\u0022m/z\u0022, MinMax=(0.,3000.))\n    |\u003E Chart.withY_AxisStyle (\u0022Intensity\u0022, MinMax=(0.,1.3))\n    |\u003E Chart.withSize (900.,400.)\nchargedPeptideChar\n(***hide***)\nchargedPeptideChar |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\nThis looks quite strange. I think you immediately see that we forgot about our isotopic cluster. A peptide doesn\u2019t produce a single peak, \nbut a full isotopic cluster. Therefore, we use our convenience function from the previous notebook \n(see: *NB02c\\_Isotopic\\_distribution.ipynb* ).\n\n*)\n\n// Code-Block 4\n\n// Predicts an isotopic distribution of the given formula at the given charge, \n// normalized by the sum of probabilities, using the MIDAs algorithm\nlet generateIsotopicDistribution (charge:int) (f:Formula.Formula) =\n    IsotopicDistribution.MIDA.ofFormula \n        IsotopicDistribution.MIDA.normalizeByMaxProb\n        0.01\n        0.005\n        charge\n        f\n    |\u003E List.toArray\n        \ngenerateIsotopicDistribution\n\n(**\n*)\n\n// Code-Block 5\n\nlet peptidesAndMassesChart =\n    // sample n random peptides from all Chlamydomonas reinhardtii peptides\n    Array.sampleWithOutReplacement rnd peptideAndMasses 500\n    |\u003E Array.map (fun (peptide,mz) -\u003E \n            peptide\n            |\u003E BioSeq.toFormula\n            // peptides are hydrolysed in the mass spectrometer, so we add H2O\n            |\u003E Formula.add Formula.Table.H2O\n            )\n    |\u003E Array.collect (fun formula -\u003E \n        [\n            // generate single charged iones \n            generateIsotopicDistribution 1 formula\n            // generate double charged iones \n            generateIsotopicDistribution 2 formula\n        ] |\u003E Array.concat\n        )\n    |\u003E Chart.Column\n    |\u003E Chart.withX_AxisStyle(\u0022m/z\u0022, MinMax=(0.,3000.))\n    |\u003E Chart.withY_AxisStyle (\u0022Intensity\u0022, MinMax=(0.,1.3))\n    |\u003E Chart.withSize (900.,400.)\npeptidesAndMassesChart\n// HINT: zoom in on peptides\n\n(***hide***)\npeptidesAndMassesChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Determination of peptide hydrophobicity\n\nIn a MS1 scan, peptides don\u0027t appear randomly. They elute according to their hydrophobicity and other physicochemical properties \nfrom the LC.\n\nTo more accurately represent a MS1 spectrum, we determine the hydrophobicity of each peptide. Therefore, we first need a function \nthat maps from sequence to hydrophobicity.\n*)\n\n// Code-Block 6\n\nopen BioFSharp.AminoProperties\n\n// first, define a function that maps from amino acid to hydophobicity\nlet getHydrophobicityIndex =\n    BioFSharp.AminoProperties.initGetAminoProperty AminoProperty.HydrophobicityIndex\n    \n// second, use that function to map from peptide sequence to hydophobicity\nlet toHydrophobicity (peptide:AminoAcids.AminoAcid[]) =\n    peptide\n    |\u003E Array.map AminoAcidSymbols.aminoAcidSymbol\n    |\u003E AminoProperties.ofWindowedBioArray 3 getHydrophobicityIndex\n    |\u003E Array.average\n\ntoHydrophobicity\n\n(**\n*)\n\n// Code-Block 7\n\nlet peptidesFirst200 = \n    chargedPeptides \n    // now we sort according to hydrophobicity\n    |\u003E Array.sortBy (fun (peptide,mass) -\u003E   \n        peptide\n        |\u003E Array.ofList\n        |\u003E toHydrophobicity\n        )\n    |\u003E Array.take 200\n\npeptidesFirst200 |\u003E Array.head\n\n(***include-it***)\n\n(**\nNow, we need to generate the isotopic cluster again and visualize afterwards.\n*)\n\n// Code-Block 8\n\nlet peptidesFirst200Chart =\n    peptidesFirst200\n    |\u003E Array.map (fun (peptide,mz) -\u003E \n            peptide\n            |\u003E BioSeq.toFormula\n            // peptides are hydrolysed in the mass spectrometer, so we add H2O\n            |\u003E Formula.add Formula.Table.H2O\n            )\n    |\u003E Array.collect (fun formula -\u003E \n        [\n            // generate single charged iones \n            generateIsotopicDistribution 1 formula\n            // generate double charged iones \n            generateIsotopicDistribution 2 formula\n        ] |\u003E Array.concat\n        )\n    // Display\n    |\u003E Chart.Column\n    |\u003E Chart.withX_AxisStyle(\u0022m/z\u0022, MinMax=(0.,3000.))\n    |\u003E Chart.withY_AxisStyle (\u0022Intensity\u0022, MinMax=(0.,1.3))\n    |\u003E Chart.withSize (900.,400.)\npeptidesFirst200Chart\n// HINT: zoom in on peptides\n\n(***hide***)\npeptidesFirst200Chart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Questions\n\n1. How does the gradient applied at a reverse phase LC influence the retention time?\n2. Try generating your own MS1 spectrum with peptides of similar hydrophobicity. Take a look at Codeblock 7 and 8 to see how to do that.\n3. To better compare retention times between runs with different gradients or instruments, the retention time of those runs must be aligned.\nWhat could be some ways to align the retention time of different runs?\n*)"},{"uri":"/BIO-BTE-06-L-7/NB06b_Targeted_quantification_of_photosynthetic_proteins_SDS_IGD.html","title":"NB06b Targeted quantification of photosynthetic proteins (SDS in gel digest)\n","content":"(**\n# NB06b Targeted quantification of photosynthetic proteins (SDS in gel digest)\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB06b_Targeted_quantification_of_photosynthetic_proteins_SDS_IGD.ipynb)\n\n1. Relative Quantification between rbcL and rbcS\n2. Compare 14N/15N for rbcL and rbcS\n\n*)\n\n#r \u0022nuget: FSharp.Stats, 0.4.0\u0022\n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta5\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: BIO-BTE-06-L-7_Aux, 0.0.1\u0022\n#r \u0022nuget: Deedle, 2.3.0\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen Deedle\nopen BioFSharp\nopen FSharpAux\nopen FSharp.Stats\nopen Plotly.NET\nopen FSharp.Stats.Fitting.LinearRegression.OrdinaryLeastSquares.Linear\nopen System.IO\nopen BIO_BTE_06_L_7_Aux.FS3_Aux\n\n(**\nAt start we have the output file of the QconQuantifier. We want to read the file, bind it to \u0060qConcatRawData\u0060 \nand group the rows by peptide sequence, modifcation (14N or 15N) and the charge state of the ion.\n*)\n\n// Code block 1\n\nlet directory = __SOURCE_DIRECTORY__\nlet path = Path.Combine[|directory;\u0022downloads/Group2/G2_L_4A_20myg_QuantifiedPeptides.txt\u0022|]\ndownloadFile path \u0022G2_L_4A_20myg_QuantifiedPeptides.txt\u0022 \u0022bio-bte-06-l-7/Group2\u0022\n\nlet qConcatRawData =\n    Frame.ReadCsv(path = path,separators=\u0022\\t\u0022)\n    // StringSequence is the peptide sequence\n    |\u003E Frame.indexRowsUsing (fun os -\u003E \n            os.GetAs\u003Cstring\u003E(\u0022StringSequence\u0022),\n            os.GetAs\u003Cbool\u003E(\u0022GlobalMod\u0022), \n            os.GetAs\u003Cint\u003E(\u0022Charge\u0022)\n        )\n        \nqConcatRawData\n\n(***include-it***)\n\n(**\nFrom literature we know that there are peptides with a very bad flyability (Hammel et al.). Additionally, \nthere are extreme values only due to technical artifacts. Both should be avoided in further analysis:\n*)\n\n// Code block 2\n\nlet qConcatData =\n    qConcatRawData\n    |\u003E Frame.filterRows ( fun (sequence, gmod, charge) _ -\u003E \n        sequence \u003C\u003E \u0022EVTLGFVDLMR\u0022 \u0026\u0026 sequence \u003C\u003E \u0022AFPDAYVR\u0022 \n        )\n    |\u003E Frame.mapValues (fun x -\u003E  if x \u003C 2000000. \u0026\u0026 x \u003E 1. then x else nan)\n    \nqConcatData\n\n(***include-it***)\n\n(**\nReading the sample description file provides us with a list of all measured files and additional information about \nthe experiment (mixing ratio, strain, etc.). Here you need to write ***YOUR*** filenames into the .txt file!\n*)\n\n// Code block 3\n\nlet path2 = Path.Combine[|directory;\u0022downloads/Group2/IGD_SampleDesc.txt\u0022|]\ndownloadFile path2 \u0022IGD_SampleDesc.txt\u0022 \u0022bio-bte-06-l-7/Group2\u0022\n\n//FileName CutOutBand Dilution Strain\nlet sampleDesc :Frame\u003Cstring,string\u003E= \n    Frame.ReadCsv(path = path2,separators=\u0022\\t\u0022,schema=\u0022Strain=string\u0022)\n    |\u003E Frame.indexRows \u0022RawFileName\u0022\n    \nsampleDesc\n\n(***include-it***)\n\n(**\nWe map the list of filenames and get the corresponding 14N and 15N column series. \nThis allows us to calculate the 14N/15N ratio per peptide ion per sample.\n*)\n\n// Code block 4\n\nlet ionRatios = \n    sampleDesc\n    |\u003E Frame.mapRows (fun rawFileName _ -\u003E \n        let n14 = \n            qConcatData.GetColumn\u003Cfloat\u003E(\u0022N14Quant_\u0022 \u002B rawFileName) \n            |\u003E Series.filterValues (fun x -\u003E  x \u003C 2000000. \u0026\u0026 x \u003E 1. )\n        let n15 = \n            qConcatData.GetColumn\u003Cfloat\u003E(\u0022N15Quant_\u0022 \u002B rawFileName) \n            |\u003E Series.filterValues (fun x -\u003E  x \u003C 2000000. \u0026\u0026 x \u003E 1. )\n        n14 / n15 \n        )\n    |\u003E Frame.ofColumns\n\nionRatios\n\n(***include-it***)\n\n(**\nFrom our in silico protein digest during the design of the qConCat protein, we know the peptide(s) \u0026rarr; \nprotein relationship. We read this information from the \u0022PeptideProtMap.txt\u0022 file.\n*)\n\n// Code block 5\n\nlet path3 = Path.Combine[|directory;\u0022downloads/PeptideProtMap.txt\u0022|]\ndownloadFile path3 \u0022PeptideProtMap.txt\u0022 \u0022bio-bte-06-l-7\u0022\n\nlet peptideProtMapping =\n    Frame.ReadCsv(path3,hasHeaders=true,separators=\u0022\\t\u0022)\n    |\u003E Frame.indexRowsString \u0022Peptide\u0022\n    \npeptideProtMapping\n\n(***include-it***)\n\n(**\nNext, we will aggregate the peptide ion ratios to obtain one ratio per peptide sequence despite the ion charge. For convenience, we join the protein names.\n*)\n\n// Code block 6\n\nlet peptideRatios = \n    ionRatios\n    |\u003E Frame.applyLevel (fun (sequence,globalMod,charge) -\u003E sequence) Stats.mean\n    |\u003E Frame.join JoinKind.Inner peptideProtMapping \n    |\u003E Frame.groupRowsByString \u0022Protein\u0022\n    |\u003E Frame.getNumericCols\n    |\u003E Frame.ofColumns\n    \npeptideRatios\n\n(***include-it***)\n\n(**\nNow, we join the sample description with the data. \n*)\n\n// Code block 7\n\nlet peptideRatiosWithDesc : Frame\u003C(string * string),(string * (string * float))\u003E=\n    peptideRatios\n    |\u003E Frame.mapColKeys (fun rk -\u003E\n        sampleDesc.GetColumn(\u0022CutOutBand\u0022).[rk],\n        (sampleDesc.GetColumn(\u0022Strain\u0022).[rk],\n         sampleDesc.GetColumn(\u0022Dilution\u0022).[rk])\n    )\n    \npeptideRatiosWithDesc\n\n(***include-it***)\n\n(**\n\nBy calculating the mean value per protein, we have two final tables with peptide and protein ratios:\n*)\n\n// Code block 8\n\nlet proteinRatiosWithDesc =\n    //peptideRatiosWithDesc\n    peptideRatiosWithDesc\n    |\u003E Frame.applyLevel fst Stats.mean\n    \nproteinRatiosWithDesc\n\n(**\n\nNext we want to compare the quantities between the cut-out band for rbcL and the cut-out band for rbcS. \nTherefore we divide the rbcL quantities from the rbcL cut-out by the rbcS quantities from the rbcS cut.out.\n*)\n\n// Code block 9\n\nlet calcultateRelativeQuantForCutOutsProteins (prot1) (prot2) frame =\n    let nestedFrame: Series\u003Cstring,Frame\u003C\u0027a,string\u003E\u003E =\n        frame\n        |\u003E Frame.transpose\n        |\u003E Frame.nest\n    nestedFrame.[\u0022RBCL\u0022] \n    |\u003E Frame.filterCols (fun ck cs -\u003E ck = prot1)\n    |\u003E Frame.mapCols (fun ck _ -\u003E\n        let rbclSeries =\n            nestedFrame.[\u0022RBCL\u0022].GetColumn\u003Cfloat\u003Eprot1\n        let rbcsSeries =\n            nestedFrame.[\u0022RBCS\u0022].GetColumn\u003Cfloat\u003Eprot2\n        rbclSeries / rbcsSeries\n    )\n    |\u003E Frame.mapColKeys (fun ck -\u003E prot1 \u002B \u0022/\u0022 \u002B prot2)\n    |\u003E Frame.transpose\n\nlet proteinRatiosWithDescCutOuts prot1 prot2=\n    proteinRatiosWithDesc\n    |\u003E calcultateRelativeQuantForCutOutsProteins prot1 prot2\n    \nlet rbclRBCS2 = proteinRatiosWithDescCutOuts \u0022rbcL\u0022 \u0022RBCS2\u0022\n\nrbclRBCS2\n|\u003E Frame.transpose\n\n(***include-it***)\n\n(**\nHere are functions and parameters which are used for the styling of the graphs.\n*)\n\n// Code block 10\n\nlet xAxis showGrid title titleSize tickSize = Axis.LinearAxis.init(Title=title,Showgrid=showGrid,Showline=true,Mirror=StyleParam.Mirror.All,Zeroline=false,Tickmode=StyleParam.TickMode.Auto,Ticks= StyleParam.TickOptions.Inside, Tickfont=Font.init(StyleParam.FontFamily.Arial,Size=tickSize),Titlefont=Font.init(StyleParam.FontFamily.Arial,Size=titleSize))\nlet yAxis showGrid title titleSize tickSize = Axis.LinearAxis.init(Title=title,Showgrid=showGrid,Showline=true,Mirror=StyleParam.Mirror.All,Tickmode=StyleParam.TickMode.Auto,Ticks= StyleParam.TickOptions.Inside,Tickfont=Font.init(StyleParam.FontFamily.Arial,Size=tickSize),Titlefont=Font.init(StyleParam.FontFamily.Arial,Size=titleSize))\n\nlet config = Config.init(ToImageButtonOptions = ToImageButtonOptions.init(Format = StyleParam.ImageFormat.SVG, Filename = \u0022praktikumsplot.svg\u0022), EditableAnnotations = [AnnotationEditOptions.LegendPosition])\n\n(**\n## Relative Quantification between rbcL and rbcS\nAt first we calculated the 14N/15N relative quantities for rbcL and rbcS. Then, as we normalized against the same \nQProtein we can now calculate the relation of subunits from rbcL and rbcS, both from their respective cut-out band.\n\nFirst we will access the data for rbcL and rbcS for a given strain from our Deedle frame.\n*)\n\n// Code block 11\n\n/////////////////////////////////// Chart Step 1 //////////////////////////////////////////\n\nopen FSharp.Stats.Fitting.LinearRegression.OrdinaryLeastSquares.Linear\n\n// access the data for rbcL and rbcS for a given strain\nlet meanValuesFor prot1Name prot2Name strainName=\n    let meanSeries : Series\u003C(string * float),float\u003E = rbclRBCS2.GetRow (prot1Name\u002B\u0022/\u0022\u002Bprot2Name)\n    meanSeries\n    |\u003E Series.filter (fun k t -\u003E fst k = strainName)\n    |\u003E fun x -\u003E x.Observations\n    |\u003E Seq.map (fun x -\u003E snd x.Key, x.Value)\n    |\u003E Array.ofSeq\n    \nlet testMeanValues =\n    meanValuesFor \u0022rbcL\u0022 \u0022RBCS2\u0022 \u00224A\u0022\n    \ntestMeanValues\n\n(***include-it***)\n\n(**\nIn addition we will display the pearson coefficient for all different given dilutions.\n*)\n\n// Code block 12\n\n//let prot1Coeff,prot1FitVals,prot1Determination =\nlet calculatePearson prot1Name prot2Name strainName (meanValueArray:(float*float) [])  =\n    let dilutionsSorted,strainVals =\n        meanValueArray\n        |\u003E Array.unzip\n    // RBCL Regression of relative quantification values\n    let RBCLcoeff = Univariable.coefficient (vector dilutionsSorted) (vector strainVals)\n    let RBCLfitFunc = Univariable.fit RBCLcoeff\n    let RBCLfitVals = dilutionsSorted |\u003E Array.map RBCLfitFunc\n    let RBCLdetermination = FSharp.Stats.Fitting.GoodnessOfFit.calculateDeterminationFromValue strainVals RBCLfitVals\n    let RBCLpearson = FSharp.Stats.Correlation.Seq.pearson strainVals dilutionsSorted\n    printfn \u0022%s - Pearson WholeCell %s: %f\u0022 strainName (prot1Name\u002B\u0022/\u0022\u002Bprot2Name) RBCLpearson\n    RBCLcoeff, RBCLfitVals, RBCLdetermination\n    \ntestMeanValues\n|\u003E calculatePearson \u0022rbcL\u0022 \u0022RBCS2\u0022 \u00224A\u0022\n\n(***include-it***)\n\n// Code block 13\n\nlet chartRatios prot1 prot2 strain =\n    let prot1Vals = meanValuesFor prot1 prot2 strain\n\n    let (prot1Coeff:Vector\u003Cfloat\u003E),prot1FitVals,prot1Determination =\n        calculatePearson prot1 prot2 strain prot1Vals\n\n    let dilutionsSorted,_ =\n        prot1Vals\n        |\u003E Array.unzip\n\n    [\n        Chart.Point (prot1Vals,Name = sprintf \u0022%s Quantified Ratios\u0022 (prot1\u002B\u0022/\u0022\u002Bprot2))\n        |\u003E Chart.withMarkerStyle(Size=10,Symbol = StyleParam.Symbol.Cross)\n        Chart.Line(Array.zip dilutionsSorted prot1FitVals,Name = (sprintf \u0022%s linear regression: %.2f x \u002B (%2f) ; R = %.4f\u0022 (prot1\u002B\u0022/\u0022\u002Bprot2) prot1Coeff.[1] prot1Coeff.[0] prot1Determination))\n        |\u003E Chart.withLineStyle(Color=\u0022lightblue\u0022,Dash=StyleParam.DrawingStyle.DashDot)\n    ]\n    |\u003E Chart.Combine\n    |\u003E Chart.withTitle (sprintf \u0022%s - In-Gel-Digest: Stability of %s/%s ratios between samples\u0022 strain prot1 prot2)\n    |\u003E Chart.withX_Axis (xAxis false (sprintf \u0022Cut Out 1 - %s / Cut Out 2 - %s\u0022 prot1 prot2) 20 16)\n    |\u003E Chart.withY_Axis (xAxis false \u0022relative quantification\u0022 20 16 )\n    |\u003E Chart.withConfig config\n    |\u003E Chart.withSize (1000.,400.)\n\nchartRatios \u0022rbcL\u0022 \u0022RBCS2\u0022 \u00221690\u0022\n\n(***hide***)\nchartRatios \u0022rbcL\u0022 \u0022RBCS2\u0022 \u00221690\u0022 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Compare 14N/15N for rbcL and rbcS\nTo calculate absolute quantities we need to know the relation of 14N protein to the 15N QProtein. \nWe will show these relation with the following charts.\nWe add a linear fit to the charts to allow for more precise evaluation of sample linearity.\n*)\n\n// Code block 14\n\n/////////////////////////////////// Chart Step 2 //////////////////////////////////////////\n\nlet calculateLinearFit ((amount,quant): float[]*float[]) =\n    // Calculation of the coefficients for a linear fit.\n    let coeffs =\n        Univariable.coefficient (vector amount) (vector quant)\n    // Calculation of the linear fit with the coefficients.\n    let linearFitFunc =\n        Univariable.fit coeffs\n    // Here, we apply the fitting function to our x-values (amount of loaded protein) \n    // to get the corresponding fitted values.\n    let linearFitVals =\n        amount\n        |\u003E Array.map linearFitFunc\n    // Calculation of the goodness of the fit by comparing our calculated \n    // Protein1/Protein2 ratios to the values of the fit.\n    let determination =\n        FSharp.Stats.Fitting.GoodnessOfFit.calculateDeterminationFromValue quant linearFitVals\n    {|Coefficients = coeffs; LinearFitValues = linearFitVals; Determination = determination; LoadedProtein = amount|}\n\n(***include-it***)\n\n// Code block 15\n\nlet createChartForRbcsRbclComparison prot1 prot2 strain =\n\n    let nestedFrame =\n        proteinRatiosWithDesc\n        |\u003E Frame.filterRows (fun rk rs -\u003E rk = prot1 || rk = prot2)\n        |\u003E Frame.transpose\n        |\u003E Frame.nest     \n\n    let getProtValuesFromSeries series =\n        series\n        |\u003E Series.filter (fun k t -\u003E fst k = strain)\n        |\u003E fun x -\u003E x.Observations \n        |\u003E Array.ofSeq\n        |\u003E Array.map (fun x -\u003E snd x.Key, x.Value)\n\n    let rbcLRBCLValues =\n        nestedFrame.[\u0022RBCL\u0022].GetColumn\u003Cfloat\u003Eprot1\n        |\u003E getProtValuesFromSeries\n\n    let rbcs2RBCSValues =\n        nestedFrame.[\u0022RBCS\u0022].GetColumn\u003Cfloat\u003Eprot2\n        |\u003E getProtValuesFromSeries\n\n    let rbclFit =\n        calculateLinearFit (Array.unzip rbcLRBCLValues)\n\n    let rbcsFit =\n        calculateLinearFit (Array.unzip rbcs2RBCSValues)\n\n    let fitChart =\n        [\n            Chart.Line(Array.zip rbclFit.LoadedProtein rbclFit.LinearFitValues)\n            |\u003E Chart.withTraceName (sprintf \u0022linear regression: %.2f x \u002B (%2f) ; R\u00B2 = %.4f for strain %s and %s\u0022\n                rbclFit.Coefficients.[1] rbclFit.Coefficients.[0] rbclFit.Determination strain prot1)\n            |\u003E Chart.withLineStyle(Color=\u0022#D3D3D3\u0022,Dash=StyleParam.DrawingStyle.DashDot)\n            Chart.Line(Array.zip rbcsFit.LoadedProtein rbcsFit.LinearFitValues)\n            |\u003E Chart.withTraceName (sprintf \u0022linear regression: %.2f x \u002B (%2f) ; R\u00B2 = %.4f for strain %s and %s\u0022\n                rbcsFit.Coefficients.[1] rbcsFit.Coefficients.[0] rbcsFit.Determination strain prot2)\n            |\u003E Chart.withLineStyle(Color=\u0022#D3D3D3\u0022,Dash=StyleParam.DrawingStyle.DashDot)\n        ]\n        |\u003E Chart.Combine\n\n    let dataChart =\n        [\n            Chart.Scatter(rbcLRBCLValues,mode=StyleParam.Mode.Lines_Markers, MarkerSymbol = StyleParam.Symbol.Circle, Opacity=0.8)\n            |\u003E Chart.withTraceName (sprintf \u0022Mean %s - %s\u0022 prot1 strain)\n            Chart.Scatter(rbcs2RBCSValues,mode=StyleParam.Mode.Lines_Markers, MarkerSymbol = StyleParam.Symbol.Circle, Opacity=0.8)\n            |\u003E Chart.withTraceName (sprintf \u0022Mean %s - %s\u0022 prot2 strain)\n        ]\n        |\u003E Chart.Combine\n        |\u003E Chart.withX_Axis (xAxis false \u0022Loaded protein [\u00B5g]\u0022 20 16)\n        |\u003E Chart.withY_Axis (xAxis false \u0022\u003Csup\u003E14\u003C/sup\u003EN/\u003Csup\u003E15\u003C/sup\u003EN Quantification ratio\u0022 20 16)\n\n    [fitChart;dataChart]\n    |\u003E Chart.Combine\n    |\u003E Chart.withTitle (sprintf \u0022%s/%s relative protein quantification\u0022 prot1 prot2)\n    |\u003E Chart.withSize (1200.,400.)\n\nlet prot1 = \u0022rbcL\u0022\nlet prot2 = \u0022RBCS2\u0022\n\n[|\u00224A\u0022; \u00221883\u0022;\u00221690\u0022|]\n|\u003E Array.map (createChartForRbcsRbclComparison prot1 prot2)\n\n(***hide***)\n[|\u00224A\u0022; \u00221883\u0022;\u00221690\u0022|]\n|\u003E Array.map (createChartForRbcsRbclComparison prot1 prot2 \u003E\u003E GenericChart.toChartHTML)\n(***include-it-raw***)"},{"uri":"/BIO-BTE-06-L-7/NB01a_Systems_Biology_FSharp_Introduction.html","title":"NB01a Systems Biology\n","content":"(**\n# NB01a Systems Biology\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB01a_Systems_Biology_FSharp_Introduction.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB01a_NB01b/NB01a_Systems_Biology_FSharp_Introduction.ipynb)\n\nThis notebook introduces the field of Systems Biology and explains why programming is a necessary skill to it.\n\n1. Systems Biology: A brief introduction\n\n3. References\n\n## Systems Biology: A brief introduction\n\n\nThe term \u201Csystems theory\u201D was introduced by the biologist L. von Bertalanffy. He defined a system as a set of related components that work together in a particular environment to perform whatever \nfunctions are required to achieve the system\u0027s objective (Bertalanffy 1945). The hierarchical organization orchestrating the interaction of thousands of molecules with individual \nproperties allows complex biological functions. Biological processes like cell division, biomass production, or a systemic response to perturbations are molecular physiological functions \nwhich result from a complex dynamic interplay between genes, proteins and metabolites (Figure 1). To gain a holistic understanding of a biological system, all parts of the \nsystem need to be studied simultaneously by quantitative measures (Sauer et al. 2007). The focus on a system-wide perspective lies on the quantitative understanding of the \norganizational structure, functional state, robustness and dynamics of a biological system and led to the coining of the term \u201CSystems Biology\u201D(Kitano 2002a).\n\nThe current challenges of Systems Biology approaches are mainly along four lines (Sauer et al. 2007, Joyce and Palsson 2006): \n\n - (**i**) - system-wide quantification of transcriptome, proteome (including protein modifications) and metabolome\n \n - (**ii**) - identification of physical interactions between these components\n \n - (**iii**) - inference of structure, type and quantity of found interactions\n \n - (**iv**) - analysis and integration of the resulting large amounts of heterogeneous data. It becomes obvious that an interdisciplinary effort is needed to resolve these challenges in Systems Biology (Aderem 2006). Here Biology dictates which analytical, experimental and computational methods are required.\n\nModern analytical methods to measure the identity and quantity of biomolecules system-wide, summarized under the term \u201Cquantitative omics\u201D-technologies, address the first two \nmentioned challenges of Systems Biology. Among these \u201Comics\u201D-technologies are transcriptomics based on microarrays/next generation sequencing and proteomics/metabolomics based on mass-spectrometry.\n\nTying in with the area of genome sequencing, the focus is set on the accurate profiling of gene/protein expression and metabolite concentrations, as well as on the determination of biological \nprotein modifications and of physical interactions between proteins.\n\nAddressing the abovementioned challenges three and four of Systems Biology, the development of numerous computational approaches reaches out to unravel the \nintrinsic complexity of biological systems (Kahlem and Birney 2006). These computational approaches focus on knowledge discovery and on in silico \nsimulation or modeling (Kitano 2002b). In the latter approach knowledge on a biological process is converted into a mathematical model. \nIn silico simulations based on such a model can provide predictions that may subsequently be tested experimentally. Computation-based knowledge discovery \n(also known as data mining) aims to extract hidden patterns from complex and high-dimensional data to generate hypotheses. Therefore, the first step is to describe \ninformation on a biological system such that it is sustainably stored in a format rendering it readable and manipulable for machines and humans. The second step is \nto integrate the huge amount of differently structured data, often referred to as the \u201Cbig data\u201D challenge. In a last step, statistical or machine learning methods \nare applied to extract the information or underlying principles hidden in the data.\n\nThe most flexible way of working with huge amounts of data is using a lightweight programming language with a succinct syntax. Therefore, it becomes necessary that biologist become familiar with a suitable programming language to solve real world problems in (Systems) Biology.\n\n![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/OmicSpace.png)\n\n***Figure 1: A conceptual view of the omic space.***\n\nThe omics space comprises of genomic, transcriptomic, proteomic, metabolomic and phenomic systems level represented as a plane. Complex biological function is the result of the interplay between molecules of one and/or different systems level.\n*)\n\n(**\n\n## References\n\n1. Bertalanffy, L. von. Zu einer allgemeinen Systemlehre. Bl\u00E4tter f\u00FCr deutsche Philosophie 18 (1945).\n2. Sauer, U., Heinemann, M. \u0026 Zamboni, N. Genetics. Getting closer to the whole picture. Science 316, 550\u2013551; 10.1126/science.1142502 (2007).\n3. Kitano, H. Systems biology. a brief overview. Science 295, 1662\u20131664; 10.1126/science.1069492 (2002).\n4. Joyce, A. R. \u0026 Palsson, B. O. The model organism as a system. integrating \u0027omics\u0027 data sets. Nat Rev Mol Cell Bio 7, 198\u2013210; 10.1038/Nrm1857 (2006).\n5. Aderem, A. Systems biology. Its practice and challenges. Cell 121, 511\u2013513; 10.1016/j.cell.2005.04.020 (2005).\n6. Kahlem, P. \u0026 Birney, E. Dry work in a wet world. computation in systems biology. Mol Syst Biol 2 (2006).\n7. Kitano, H. Computational systems biology. Nature 420, 206\u2013210; 10.1038/nature01254 (2002).\n*)"},{"uri":"/BIO-BTE-06-L-7/NB05a_Quantification.html","title":"NB05a Quantification\n","content":"(**\n# NB05a Quantification\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB05a_Quantification.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB05a/NB05a_Quantification.ipynb)\n\n1. Quantification Theory\n    1. Targeted quantification\n    2. (i) Targeted acquisition at peptide\n    3. (ii) Targeted data analysis at peptide ion level\n2. References\n\n*)\n\n(**\n## Quantification Theory\n\nTo estimate the amount of individual proteins in complex mixtures, all peptide signals corresponding to a common protein serve as a \nproxy for their abundance. Peptide information needs to be obtained from multidimensional signal data detected by the mass spectrometer. \nAll signals generated from one peptide ion species, often referred to as peptide feature, need to be grouped to form a three-dimensional peak \nalong the m/z, ion intensity, and retention time dimension. This process is generally defined as peak detection or feature detection. \nPeak detection algorithms are a set of rules defining how neighboring signal points are joined. Whether noise filtering is done before or after \npeak detection strongly depends on the peak detection algorithm. Traditional approaches mainly focused on signal amplitude neglecting \ncharacteristic peak shapes as a common feature of chromatographic or spectroscopic peaks. These algorithms are prone to miss detection of low \nintensity peaks with a signal strength close to the noise level. To overcome these issues, techniques like smoothing, shape-matching and curve \nfitting are often implemented and applied. At the time, the most promising approach to do shape-matching and noise reduction in one step uses the \ncontinuous wavelet transformation (CWT).\n\nIn general, a CWT based approach describes a family of time-frequency-transformations often used in data compression and feature detection. \nThe term is coined by the use of a wavelet, as a basis function which is \u201Ccompared\u201D to the signal. The point of highest correlation between the \nbasis function and the signal reflects the location of the peak present. Due to the fact that MS derived peaks often follow the shape of a \ngaussian distribution, the *Mexican Hat* wavelet as the negative normalized second derivative of the Gaussian distribution is perfectly \nsuited to find the peptide feature.\n\n![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/Wavelets.png)\n\n**Figure 5: Schematic representation of the \u2018Haar\u2019-wavelet (blue) and the \u2018Mexican Hat\u2019- wavelet (green). **\nThe \u2018Haar\u2019-wavelet is named after its discoverer Alfred Haar and represents the first wavelet ever to be described. The \u2018Mexican Hat\u2019- or \u2018Ricker\u2019-wavelet is \nfrequently used in the fields of signal detection and compression.\n\nDepending on the quantification approach, the peptide features used for protein quantification might differ. In case of isotopic labeling, \nquantification means pairing features with the proper mass shift according to the utilized label. It is essential to account for the frequency \nof label incorporation when calculating the mass shift for the utilized label. Taking the ICAT method as an example, by which a heavy/light \ndifference of 9 Dalton per cysteine is incorporated, the total mass shift is 9 Dalton times the number of cysteine within the sequence. \nConsequently, pairing peptide features for 15N labeling is even more challenging, as the mass shift is less discrete. Using stable \nisotope labeling, different peptide feature pairs belonging to the same protein can be treated as technical replicates and averaged to gain \nprotein quantification. In contrast, the sum of all extracted peptide signals results in a label-free protein quanti\uFB01cation. Spectral counting \ncomputes abundance values from the number of times a peptide was successfully identi\uFB01ed by tandem mass spectrometry (MS/MS) and combines all \nthese events per protein. The spectral counting values can be normalized by the number of peptides theoretically expected from the particular \nprotein. \n\n![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/ComputationalProteinQuantification.png)\n\n**Figure 6: Computational strategy of peptide and protein quanti\uFB01cation on based on stable isotope labeling or by label-free quanti\uFB01cation.**\n(A) Label-free methods compare corresponding peptide abundances over different MS runs. The abundance is either \nestimated by the elution pro\uFB01le les of the pep de ions or (B) in case of spectral counting, by the number of times a peptide was \nsuccessfully identi\uFB01ed (MS2). In contrast, methods based on differential stable isotope labeling analyze peptides pairs detected by \ntheir characteristic mass di\uFB00erence \u0394m/z. The abundance is estimated by the ratio of their corresponding elution pro\uFB01les (C). Isobaric \ntagging methods (D) compare the reporter ion abundances in the fragmentation spectrum.\n*)\n\n(**\n### Targeted quantification\n\nTargeted proteomics has gained significant popularity in mass spectrometry\u2010based protein quantification as a method to detect proteins of \ninterest with high sensitivity, quantitative accuracy and reproducibility. The two major strategies of (i) targeted acquisition at peptide, \nand (ii) targeted data analysis at peptide ion level need to be distinguished.\n*)\n\n(**\n###(i) Targeted acquisition at peptide\n\nIn multiple reaction monitoring (MRM or SRM for single/selected reaction monitoring) simply predefined transitions are recorded. \nKnowledge about the targeted transitions from precursor to their corresponding fragment ions are needed and predefined in the mass \nspectrometer. MRM can be performed rapidly and is highly specific even for low abundant peptide ions in complex mixtures, but with the \ndrawback of a necessary bias in the sense that only predefined peptides are measured.\n*)\n\n(**\n### (ii) Targeted data analysis at peptide ion level\n\nData\u2010independent acquisition at the peptide level makes it possible to acquire peptide data for virtually all peptide ions present in a sample. \nIn this strategy, a high\u2010resolution mass analyzer\u2014such as an orbitrap or a time\u2010of\u2010flight\u2014is used to constantly sample the full mass range \nat the peptide level during the entire chromatographic gradient. In a subsequent step, precursor ion chromatograms can be extracted by targeted \ndata analysis. Those extracted-ion chromatogram (XIC) can be obtained to calculate the area under the curve and used for peptide quantification.\n\nLet\u2019s start and extract a XIC\u2026\n*)\n\n#r \u0022nuget: FSharp.Stats, 0.4.0\u0022\n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta5\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: System.Data.SQLite, 1.0.113.7\u0022\n#r \u0022nuget: BioFSharp.Mz, 0.1.5-beta\u0022\n#r \u0022nuget: MzIO, 0.1.0-beta\u0022\n#r \u0022nuget: MzIO.SQL, 0.1.0-beta\u0022\n#r \u0022nuget: MzIO.Processing, 0.1.0-beta\u0022\n#r \u0022nuget: BIO-BTE-06-L-7_Aux, 0.0.1\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen Plotly.NET\nopen FSharp.Stats\nopen BioFSharp\nopen System.IO\nopen System.Data.SQLite\nopen BIO_BTE_06_L_7_Aux.FS3_Aux\n\n(**\nWe now want to extract the XIC for the peptide where we previously calculated the matching score.\n\nSince we need several mass spectrometry scans to quantify over the retention time, we connect to our database \nand index the entries according to their retention time.\n*)\n\n// Code-Block 1\nlet directory = __SOURCE_DIRECTORY__\nlet path = Path.Combine[|directory;\u0022downloads/sample.mzlite\u0022|]\ndownloadFile path \u0022sample.mzlite\u0022 \u0022bio-bte-06-l-7\u0022\nlet runID = \u0022sample=0\u0022\n\nlet mzReader = new MzIO.MzSQL.MzSQL(path)\nlet cn = mzReader.Open()\nlet transaction = mzReader.BeginTransaction()\n\n// Indexes all spectra of the related sample run\nlet idx = MzIO.Processing.Query.getMS1RTIdx mzReader runID\nidx\n\n(***include-it***)\n\n(**\n**We know from the MS2 measurement, that our peptide had its match at a retention of around 51.95 min**. We create a query \nto the database to extract the intensities of all peaks that are \u002B/-5 min of our retention time and within 0.04 m/z of our peptide of interest. \nAfter we are done, we close the connection to the database.\n*)\n\n// Code-Block 2\n\nlet retentionTime = 51.95\nlet mzAtCharge2   = 511.2691141\n\nlet rtQuery = MzIO.Processing.Query.createRangeQuery retentionTime 5.\n\nlet mzQuery = MzIO.Processing.Query.createRangeQuery mzAtCharge2 0.04\n\nlet xic = \n    MzIO.Processing.Query.getXIC mzReader idx rtQuery mzQuery  \n    |\u003E Array.map (fun p -\u003E p.Rt , p.Intensity)\n    \ntransaction.Dispose()\n\nlet xicChart =\n    xic\n    |\u003E Chart.Point\n    |\u003E Chart.withX_AxisStyle \u0022Retention Time\u0022\n    |\u003E Chart.withY_AxisStyle \u0022Intensity/Score\u0022\n    |\u003E Chart.withSize (900.,900.)\nxicChart\n(***hide***)\nxicChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\nWe have now the XIC in our hands and can use the second derivative to identify peaks with our trace.\n*)\n\n// Code-Block 3\n\n// get all peaks\nlet peaks = \n    xic\n    |\u003E Array.unzip\n    |\u003E (fun (ret, intensity) -\u003E\n        FSharp.Stats.Signal.PeakDetection.SecondDerivative.getPeaks 0.1 2 13 ret intensity\n        )\n\npeaks |\u003E Array.head\n\n(***include-it***)\n\n(**\nThe peak model includes numerus information. Therefore we can mark the apices of the peaks we identified.\n*)\n\n// Code-Block 4\n\nlet apices =\n    peaks\n    |\u003E Array.map (fun peak -\u003E peak.Apex.XVal,peak.Apex.YVal)\n\nlet apicesChart=\n    [    \n        Chart.Point(apices, Name=\u0022apices\u0022)\n        |\u003E Chart.withMarkerStyle(Size=15)\n        Chart.Point(xic, Name = \u0022XIC\u0022)\n\n    ]\n    |\u003E Chart.Combine\n    |\u003E Chart.withX_AxisStyle \u0022Retention Time\u0022\n    |\u003E Chart.withY_AxisStyle \u0022Intensity\u0022\n    |\u003E Chart.withSize (900.,900.)\napicesChart\n(***hide***)\napicesChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\nWe can then go ahead and characterize our peak and quantify the area under the fitted curve.\n*)\n\n// Code-Block 5\n\n// get peak at \u0022ret=51.95\u0022 from all peaks \u0022peaks\u0022\nlet quantifiedXIC = \n    BioFSharp.Mz.Quantification.HULQ.getPeakBy peaks retentionTime\n    // quantify peak of interest\n    |\u003E BioFSharp.Mz.Quantification.HULQ.quantifyPeak \n    \nquantifiedXIC.Area\n\n(***include-it***)\n\n(**\nThe peak model gives us all the information we need for our peptide of interest. If we want to see what we quantified, we can take an \nexponential modified gaussian function using the parameters given by the peak model and plot it together with the previously extracted XIC.\n*)\n\n// Code-Block 6\n\nlet eval x = \n    Fitting.NonLinearRegression.Table.emgModel.GetFunctionValue (vector quantifiedXIC.EstimatedParams) x\n\neval\n\n(**\n*)\n\n// Code-Block 7\n\nlet quantifiedArea =\n    xic \n    |\u003E Array.map (fun (rt,i) -\u003E rt, eval rt)\n\nlet quantifiedAreaChart =\n    [\n        Chart.Point(xic,Name=\u0022XIC\u0022)\n        Chart.SplineArea(quantifiedArea,Name=\u0022quantified XIC\u0022)\n    ]\n    |\u003E Chart.Combine\n    |\u003E Chart.withX_AxisStyle (title = \u0022Retention Time\u0022, MinMax = (51.,58.))\n    |\u003E Chart.withY_AxisStyle \u0022Intensity\u0022\n    |\u003E Chart.withSize (900.,900.)\nquantifiedAreaChart\n(***hide***)\nquantifiedAreaChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\n## Questions\n\n1. How does the Chart created by Code-Block 2 change, when you change the value of \u0027retentionTime\u0027 to 53.95? What does this parameter specify?\n2. How does the Chart created by Code-Block 2 change, when you change the value of the parameter \u0027offset\u0027 from 5 to 10 or 20?\n3. How does the Chart created by Code-Block 4 change, when you change the value of the parameter snr from 0.1 to 2.1? \nWhat does this parameter specify, what does the abbreviation snr stand for?\n4. How does the Chart created by Code-Block 7 change, when you change the value of the parameter retentionTime in CodeBlock 5 to 55.15?\n5. Have a look at the peaks, how are the peaks shaped, are the shapes symmetric?\n6. What does the term \u0022peak tailing\u0022 imply. \n7. What factors determine peak shape? Think of explanations (e.g. biochemical-interactions, detection method) for different peak shapes. \n8. How many parameters does the model have (see quantifiedXIC.EstimatedParams, Code-Block 6), what does the abbreviation \u0022EMG\u0022 stand for and \nhow is this function different from a gaussian function?\n9. How could the fit created by the change in Code-Block 5, 6 and 8 profit from baseline correction?\n*)"},{"uri":"/BIO-BTE-06-L-7/NB00a_FSharp_Coding_literacy_Part_I.html","title":"NB00a FSharp Coding literacy part I\n","content":"(**\n# NB00a FSharp Coding literacy part I\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB00a_FSharp_Coding_literacy_Part_I.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB00a/NB00a_FSharp_Coding_literacy_Part_I.ipynb)\n\n1. Getting things done and understand values\n    1. Numeric types\n    2. String or character types\n    3. F# handles your types.\n2. Functions and operators: Do some operations\n    1. Operations and types\n    2. Functions\n3. Namespace and modules\n4. Control flow expressions\n\n\n## Getting things done \n\nThe purpose of this first part is to present the use of F# (pronounced \u201CF Sharp\u201D) programming language to facilitate and automate a wide variety of data manipulation\ntasks typically faced in life science research. Here, we want to support your coding literacy by a practical programming approach without the attempt to detail every \npossible variation of the mechanisms. This offers a rapid introduction to F# programming that should allow you to understand code and do some manipulation to achieve \nyour desired outcome.\n\nThere are many kinds of programming languages, with different purposes, styles, intended uses, etc. However, F# is particularly nice as it is easy to learn in the beginning \nbut also extremely powerful for professional use cases. Simply put, F# is a beautiful language. It is effective for everything from teaching new programmers to advanced\ncomputer science study, from simple scripts to sophisticated advanced applications. Therefore, it is extremely well suited for bioinformatics programming and \napplication in live science.\n\n### Numeric types\n\nDefinitely, F# can be a good friend in your daily work even when you are doing simple calculations, e.g. in the lab. Let\u2019s jump right in and some stuff done:\n*)\n// Define numerical values\nlet co2Oxygens = 2\nlet co2Carbon  = 1\nlet oxygenMass = 15.9994\nlet carbonMass = 12.0107\nlet avogadro = 6.023e23\n(**\nFirst things first: Any text on a line that follows \u0060//\u0060 is handled as a comment and is ignored by the F# interpreter. Comments help to write organized code with documentation \nand are therefore not executed as part of your program or script. Additionally, there is also the possibility to write comments that span multiple lines by putting text between \nparenthesis and asterisk \u0060(* \u2026 *)\u0060.\n\nThe example shows the two most common types of numbers used in F#:\n\n* integer (\u0060int\u0060): co2Oxygens = 1\n* floating point numbers (\u0060float\u0060): let oxygenMass = 15.9994\n\nOne of the most important action in programming is naming things, which is called binding. Binding is the naming process that associates an identifier (name) to a value or function. \nIn F#, the \u0060let\u0060 keyword is used to do such a binding and bind a name to a value in our example. We can use \u0060let\u0060 binding at various level. It might be worth noting here that this \nprocess is often referred as declaring variables, but using the term \u201Cbinding\u201D is much nicer.\nBindings are case sensitive names and can contain letters, numbers as well as the underscore character. They cannot start with a number however and they cannot contain spaces. \n\nThis makes the following three different bindings: \n*)\nlet myvariable = 1\nlet MyVariable = 3.172\nlet MYVARIABLE = \u0022Undefined\u0022\n\n(** \n*But what is a value?*\n\nIn general, computer programs manipulate data. An individual item of data is called a value. F# is a statically typed language and every value has a type that identifies the kind of value it is. \nFor example, the type of \u0060co2Oxygens\u0060 is \u0060int\u0060. Each value can be seen an instance of a particular type, later we will complete this point of view by recognizing that each object is an \ninstance of a particular class (type).\n\n### String or character types\n\nSimilar to declaring numbers in F#, we also can bind text (aka. \u0060string\u0060) or characters to names just by enclosing the declared value in double or single quotes.\n*)\n// Define string or character values\nlet buffer = \u0022Tris\u0022\nlet hydrogenMass = \u00221.00794\u0022\nlet nucleotide = \u0027A\u0027\n(**\nHere, single quotes are used for single character (\u0060char\u0060), while double quotes indicate a string. Importantly, if you would like to use quotes (or other special characters) in a string, you must \nquote the quotes with a backslash \u0060\\\u0060. \n\nOne more way to declare strings in F# that allows you to even include line breaks in the strings. It\u2019s useful, for example, for declaring paragraphs of text as strings. To use it, you have to enclose\nthe string itself in triple quotes.\n*)\nlet poem = \u0022\u0022\u0022\n    Nature\u0027s first green is gold,\n    Her hardest hue to hold.\n    Her early leaf\u0027s a flower;\n    But only so an hour.\n\u0022\u0022\u0022\n(**\nThere are many different specialized primitive types available in F#, [see here](https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/literals) for the full overview. However, covering \nBoolean (\u0060bool\u0060) values in the following, we now covered the most common primitive types.\n*)\n\nlet yes = true\nlet no  = false\n\n(**\nVery often, in programming, you will need a data type that can only have one of two values, like: *Yes/No, On/Off or TRUE/FALSE*. A boolean type is declared with the bool keyword and can only take the values \n\u0060true\u0060 or \u0060false\u0060.\n\n### F# handles your types.\nThe F# interpreter needs to always know the type of your value. Luckily, this does not mean, that you need to specify the type all the time explicitly by yourself. In the process of type inference, the \nF# compiler infers the types of values, variables, parameters and return values.\nThe compiler infers the type based on the context. If the type is not otherwise specified, it is inferred to be generic. If the code uses a value inconsistently, in such a way that there is no single \ninferred type that satisfies all the uses of a value, the compiler reports an error. \n\nWe have seen this happen through all the examples so far, but how does it work and what can you do if it goes wrong?\nIn that case, you can apply explicit type annotations using \u0060: type name\u0060, as shown in the following examples: \n*)\n// Explicitly define the type of on as bool. Brackets () are not necessary\nlet (on : bool) = true\n\n(**\n\n## Functions and operators: Do some operations\n\nIn the beginning, I introduced F# as your friendly pal. Let\u2019s dive into a quick example, that actually does some operations.\n*)\n\nlet co2Oxygens\u0027 = 2\nlet co2Carbon\u0027  = 1\nlet oxygenMass\u0027 = 15.9994\nlet carbonMass\u0027 = 12.0107\n\nlet co2Mass = float co2Oxygens\u0027 * oxygenMass\u0027 \u002B float co2Carbon\u0027 * carbonMass\u0027\n\nprintfn \u0022Molecular weight of CO2 = %f\u0022 co2Mass\n\n\n(**\nHere we use the bindings we did before to calculate the mass of a CO2 molecule and bind the result to the name co2Mass. In the next line \u0060printfn\u0060 is used to output the result to the F# console which is the \ndefault stream for any output from the code. \nIf you run this code into your interactive notebook and saw the output, you just ran your first, small F# program!\n\n### Operations and types\n\nThe F# type system makes sure that you can not mix types during calculation. While it is possible to concatenate two string using the \u0060\u002B\u0060 operator. However, using two different types will cause the compiler \nto point out the error.  \n\nIt is worth to notice, that because \u0060int\u0060 and \u0060float\u0060 are different types even though they are both numbers. Therefore, to calculate the example above it is necessary to explicitly cast between \u0060int\u0060 and \u0060float\u0060 for \noperations such as multiplication.\n\n### Functions \n   \n\nAt this point we have our first functionality, meaning a small F# program that can perform a calculation. In most cases you want to organize the functionalities your code provides into nice building blocks that \ncan be reused and applied multiple times. You can think of functions as exactly those kinds of self-contained building blocks of code that accomplish a specific task. Functions usually consume input data called \nparameter, process it in their function body, and return a result. Once you have a function defined, it can be used over and over and over again. \nThe best way to understand an F# function is to see it in action. Let\u2019s dive into it:\n*)\n\n// Example of indented code\nlet explainIndentedCode () =\n    printfn \u0022This indented line is part of the function\u0022\n    printfn \u0022So is this one\u0022\nprintfn \u0022This unindented line is not a part of the function\u0022\n\n(**\nThis code exemplifies two important point. First, indentation is syntactically meaningful in F# and not just for comfortable reading. It is used to show which particular block of code belongs together. Therefore, \nall code inside a function must be indented to define it as belonging to the function.\n\nSecondly, functions can be called from the inside of other functions. Here, we use the \u0060printfn\u0060 function you already know inside the outer function.  The function \u0060printfn\u0060 is a build in function and is already \ndefined in the core of F#. Thus, we do not need to define it ourselves and can call it as we desire.\n\nWith this knowledge we can do a more meaningful example:\n*)\n\n//A simple function to calculate molar volumes\nlet calculateGasDensity molarMass pressure temperatureK =\n    let gasConstant = 0.082057\n    let density : float = (molarMass * pressure) / (gasConstant * temperatureK)\n    density\n\nlet co2MolarVolume = calculateGasDensity co2Mass 4. 546.\nprintfn \u0022The density of carbon dioxide at 546 K and 4.00 atmospheres pressure is %f g/L\u0022 co2MolarVolume\n\n(**\nAs the biochemistry textbooks tell us, the density of 1 mole of CO2 at 546 Kelvin and 4.00 atmospheres pressure is indeed 3.93 g/L. We make use of the \u0060let\u0060 keyword and define or declare our function, followed by the function call where the result is \nbound to the name \u0060co2MolarVolume\u0060.\n\n*Side note:* Signature of a function\n\nA function signature shows the function prototype. It tells you name, input type(s) and output type of a function. You will later learn that the type defines the kind of the value for functions to act upon (input) \nand return (output). Just by examining a function\u2019s signature, you can often get some idea of what it does.\n\n*Side note:* Lambda expressions\n\nIn F# it is possible to use function without giving them a name and use the keyword \u0060fun\u0060 instead and the \u0060=\u0060 becomes \u0060-\u003E\u0060. This is called anonymous function or referring to lambda calculus lambda expression. \nThis kind of functions are often used for convenience. To write \u0027add1\u0027 as lambda expression \u0060fun x -\u003E x \u002B 1\u0060\n\n## Namespace and modules\n\nSometimes it can be necessary to go a little bit further in terms of code organization. For example, to ship code in a library to other users. Namespaces und Modules are top-level and low-level constructs to \norganize code. You can think of namespaces and modules as containers and sub containers, respectively, in which you can put function and type definitions. The hierarchy is defined that you can have multiple \nmodules in one namespace, also nested modules in a module, but no namespace in another namespace. \n\nThe most important bit is, that you can access namespaces and modules with the \u0060.\u0060 operator. This is also how you find functionality in libraries which you can load from other sources.  This is required because \nit means you do not need to write all code and functionality by yourself.\nIn the following you can see how you can profit from the amazing F# community efforts to provide you with various libraries. It seems obvious that for our example we load BioFSharp.\n*)\n\n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\n\n// Access adenine without \u0027open\u0027\nBioFSharp.Nucleotides.A\n\n// Access adenine with \u0027open\u0027\nopen BioFSharp\nNucleotides.A\n\n(**\nThe first line automatically pulls the necessary files from the internet and allows you to use the library in your scripting environment. Due to the \u0060open\u0060 statement you can shorten the path to access the modules \nand functions in the library. This just saves you the effort to always type \u0060BioFSharp.\u0060 in front of everything\u2026 \n\n## Control flow expressions\n\nEverything you have seen so far has consisted of sequential execution, in which expressions are always evaluated one after the next, in exactly the order specified. But the world is often more complicated than that. \nFrequently, a program needs to skip over or choose between alternate sets of paths to execute.\nThat is where control structures come in. A control structure directs the order of evaluation of expressions in a program (referred to as the program\u2019s control flow).\n*)\n\n//Function for calculating buffer recipes that uses if-conditionals \nlet bufferRecipe buffer molarity =\n    let grams = \n        if buffer = \u0022Tris\u0022 then\n            121.14\n        elif buffer = \u0022MES\u0022 then\n            217.22 \n        elif buffer = \u0022HEPES\u0022 then\n            238.30 \n        else\n            failwith \u0022Huh???\u0022\n    let gramsPerLiter = grams * molarity \n    gramsPerLiter\n\n(**\nThe function \u0060bufferRecipe\u0060 takes two arguments that specify the name of the \u0060buffer\u0060 and \u0060molarity\u0060 of the stock solution you want to make. Based upon the buffer name that you provide; it then binds the appropriate value \nto the name grams and returns the required weight of buffer (in grams) to make up a 1 L solution.\n\nAs with other programming languages, the equality operator in F# is just one of a bunch of comparison you can do:\n\n* \u0060=\u0060  equals \n* \u0060\u003C\u003E\u0060 not equals\n* \u0060\u003E\u0060 greater than \n* \u0060\u003C\u0060 less than \n* \u0060\u003E=\u0060 greater than OR equals \n* \u0060\u003C=\u0060 less than OR equals\n\nHowever, there is a more powerful control flow construct called Matching expression. You can write the \u0060bufferRecipe\u0060 example from above as follows:\n*)\n\n//Function for calculating buffer recipes that uses match-conditions \nlet bufferRecipe\u0027 buffer molarity =\n    let grams =\n        match buffer with\n        | \u0022Tris\u0022  -\u003E 121.14\n        | \u0022MES\u0022   -\u003E 217.22 \n        | \u0022HEPES\u0022 -\u003E 238.30 \n        | _       -\u003E failwith \u0022Huh???\u0022\n    grams * molarity \n    \n\n(**\nEach \u0060|\u0060defines a condition, the \u0060-\u003E\u0060 means \u0022if the condition is true, follow this path...\u0022. The \u0060_\u0060 is the default pattern, meaning that it matches anything, sort of like a wildcard. Occasionally, it\u0027s not enough to \nmatch an input against a particular value; we can add filters, or guards, to patterns using the \u0060when\u0060 keyword. We can rewrite out \u0060 bufferRecipe\u0060 function once again. \n*)\n\n//Function for calculating buffer recipes that uses match-conditions with guards\nlet bufferRecipe\u0027\u0027 buffer molarity =\n    let grams =\n        match buffer with\n        | x when x = \u0022Tris\u0022  -\u003E 121.14\n        | x when x = \u0022MES\u0022   -\u003E 217.22 \n        | x when x = \u0022HEPES\u0022 -\u003E 238.30 \n        | _       -\u003E failwith \u0022Huh???\u0022\n    grams * molarity \n    \n(**\nMaybe we should notice, that in this function we use the function \u0060failwith\u0060 to throw an error, if we do not know the buffer. This is not particular nice, however necessary in our example. \n*)"},{"uri":"/BIO-BTE-06-L-7/NB04b_Peptide_Identification.html","title":"NB04b Peptide Identification\n","content":"(**\n# NB04b Peptide Identification\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB04b_Peptide_Identification.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB04a_NB04b/NB04b_Peptide_Identification.ipynb)\n\n1. Understanding peptide identification from MS2 spectra\n2. Matching and scoring of Tandem MS peptide identification\n    3. Step 1: Data acquisition and preprocessing\n    4. Step 2: Preselecting the peptides of interest\n    5. Step 3\u002B4: Matching and Scoring\n\n*)\n\n(**\n## Understanding peptide identification from MS2 spectra\n\nUnder low-energy fragmentation conditions, peptide fragment patterns are reproducible and, in general, predictable, which allows for an \namino acid sequence identification according to a fragmentation expectation. Algorithms for peptide identification perform in principle \nthree basic tasks:\n\n**(i)** a raw data preprocessing step is applied to the MS/MS spectra to obtain clean peak information. The same signal filtering \nand background subtraction methods are used as discussed in the section of low-level processing. Peak detection, however, may be performed \ndifferently. Preprocessing of MS/MS spectra focuses on the extraction of the precise m/z of the peak rather than the accurate peak areas. \nThe conversion of a peak profile into the corresponding m/z and intensity values reduces the complexity, its representation is termed centroiding. \nTo extract the masses for identification in a simple and fast way, peak fitting approaches are used. These approaches take either the most intense \npoint of the peak profile, fit a Lorentzian distribution to the profile, or use a quadratic fit. \n\n**(ii)** Spectrum information and possible amino acid sequences assignments are evaluated. \n\n**(iii)** The quality of the match between spectrum and possible sequences is scored.\n\nEven though the three steps roughly describe the basic principle of algorithms used for peptide sequence identification, most implementations \nshow differences in individual steps which can lead to major changes in the outcome. Therefore, it has been proven useful to utilize more than \none algorithm for a robust and thorough identification. Due to their major difference in identification strategies and prerequisites, \nidentification algorithms are normally classified into three categories: (i) *de novo* peptide sequencing, (ii) peptide sequence-tag (PST) \nsearching, and (iii) uninterpreted sequence searching. However, in this notebook we focus on the explanation of (iii) uninterpreted sequence \nsearching, the most frequently used methods.\n*)\n\n(**\n## Matching and scoring of Tandem MS peptide identification\n\n![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/ComputationalProteinIdentification.png)\n\n**Figure 5: Process of computational identification of peptides from their fragment spectra**\n\nPreviously we learned, that peptides fragment to create patterns characteristic of a specific amino acid sequence. These patterns are reproducible and, in general, \npredictable taking the applied fragmentation method into account. This can be used for computational identification of peptides from their fragment spectra. \nThis process can be subdivided into 5 main steps: spectrum preprocessing, selection of possible sequences, generating theoretical spectra, matching and scoring \n(Figure 5). The first step is a preprocessing of the experimental spectra and is done to reduce noise. Secondly, all possible amino acid \nsequences are selected which match the particular precursor peptide mass. The possible peptides can but do not need to be restricted to a particular organism. \nA theoretical spectrum is predicted for each of these amino acid sequences. Matching and scoring is performed by comparing experimental spectra to their predicted \ncorresponding theoretical spectra. The score function measures the closeness of fit between the experimental acquired and theoretical spectrum. There are many \ndifferent score functions, which can be considered as the main reason of different identifications considering different identification algorithm. The most \nnatural score function is the cross correlation score (xcorr) used by the commercially available search tool SEQUEST. One of the reasons the xcorr is so \nsensitive is because it involves a correction factor that assesses the background correlation for each acquired spectrum and the theoretically predicted \nspectrum from sequences within a database. To compute this correction factor, a measure of similarity is calculated at different offsets between a preprocessed \nmass spectrum and a theoretical spectrum. The final xcorr is then the correlation at zero offset minus the mean correlation from all the individual offsets.\n\nThus, the correlation function measures the coherence of two signals by, in effect, translating one signal across the other. This can be mathematically \nachieved using the formula for cross-correlation in the form for discrete input signals:\n\n***Equation 5***\n\n![](https://latex.codecogs.com/png.latex?\\large\u0026space;R_{\\tau}\u0026space;=\u0026space;\\sum_{i=0}^{n-1}x_{i}\\cdot y_{i\u0026plus;\\tau})\n\nwhere x(i) is a peak of the reconstructed spectrum at position i and y(i) is a peak of the experimental spectrum. The displacement value \uD835\uDF0F \nis the amount by which the signal is offset during the translation and is varied over a range of values. If two signals are the same, the correlation \nfunction should have its maxima at \uD835\uDF0F=0, where there is no offset. The average of the offset-correlation is seen as the average background correlation \nand needs to be subtracted from the correlation at \uD835\uDF0F=0. It follows: \n\n***Equation 6***\n\n![](https://latex.codecogs.com/png.latex?xcorr\u0026space;=\u0026space;R_{0}\u0026space;-\u0026space;\\frac{(\\sum\u0026space;\\begin{matrix}\u0026space;\\tau=\u0026plus;offeset\\\\\u0026space;\\tau=-offeset\\end{matrix}R_{\\tau})}{2*offset\u0026plus;1})\n\nIn practice many theoretical spectra have to be matched again a single experimental spectrum. Therefore, the calculation can be speed up by reformulating Equation 5 and Equation 6 and introduce a preprocessing step, which is independent of the predicted spectra.\n\n***Equation 7***\n\n![](https://latex.codecogs.com/png.latex?xcorr\u0026space;=\u0026space;x_{0}\\cdot\u0026space;y_{0}\u0026space;-\u0026space;\\frac{(\\sum\u0026space;\\begin{matrix}\u0026space;\\tau=\u0026plus;offeset\\\\\u0026space;\\tau=-offeset\\end{matrix}x_{0}\\cdot\u0026space;y_{\\tau})}{2*offset\u0026plus;1})\n\nFor the preprocessed experimental spectrum y\u0027 it follows:\n\n***Equation 8***\n\n![](https://latex.codecogs.com/png.latex?xcorr\u0026space;=\u0026space;x_{0}\\cdot\u0026space;y\u0060)\n\nwhere:\n\n***Equation 9***\n\n![](https://latex.codecogs.com/png.latex?y\u0027\u0026space;=\u0026space;y_{0}\u0026space;-\u0026space;\\frac{(\\sum\u0026space;\\begin{matrix}\u0026space;\\tau=\u0026plus;offeset\\\\\u0026space;\\tau=-offeset\\end{matrix}x_{0}\\cdot\u0026space;y_{\\tau})}{2*offset\u0026plus;1})\n\nMatching a measured spectrum against chlamy database\n*)\n\n#r \u0022nuget: BioFSharp, 2.0.0-beta4\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta4\u0022\n#r \u0022nuget: BioFSharp.Mz, 0.1.5-beta\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: BIO-BTE-06-L-7_Aux, 0.0.1\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen Plotly.NET\nopen BioFSharp\nopen BioFSharp.Mz\nopen BIO_BTE_06_L_7_Aux.FS3_Aux\nopen System.IO\n\n(**\n### Step 1: Data acquisition and preprocessing\n\nWe load a single MS2 spectrum that is saved in a mgf file.\n*)\n\n// Code-Block 1\nlet directory = __SOURCE_DIRECTORY__\nlet path = Path.Combine[|directory;\u0022downloads/ms2sample.mgf\u0022|]\ndownloadFile path \u0022ms2sample.mgf\u0022 \u0022bio-bte-06-l-7\u0022\n\nlet ms2 = \n    BioFSharp.IO.Mgf.readMgf path\n    |\u003E List.head\n    \nms2\n\n(***include-it***)\n\n(**\nHere, the spectrum is already centroidized as shown in *NB03c\\_Centroidisation.ipynb* using the function \n\u0060msPeakPicking\u0060. So we just visualize mass and intensity:\n*)\n\n// Code-Block 2\n\nlet ms2Chart = Chart.Column(ms2.Mass, ms2.Intensity)\nms2Chart\n(***hide***)\nms2Chart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\nNow, we will preprocess the experimental spectrum from our example. This is on the one hand to reduce noise, but also to make \nthe measured spectrum more like the once we are able to simulate. \n*)\n\n// Code-Block 3\n\nlet lowerScanLimit = 150.\nlet upperScanLimit = 1000.\n\nlet preprocessedIntesities =\n    Mz.PeakArray.zip ms2.Mass ms2.Intensity\n    |\u003E (fun pa -\u003E Mz.PeakArray.peaksToNearestUnitDaltonBinVector pa lowerScanLimit upperScanLimit)\n    |\u003E (fun pa -\u003E Mz.SequestLike.windowNormalizeIntensities pa 10)\n    \nlet intensityChart = Chart.Column([lowerScanLimit .. upperScanLimit], preprocessedIntesities)\nintensityChart\n(***hide***)\nintensityChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n### Step 2: Preselecting the peptides of interest\n\nEvery MS2 spectrum is accompanied by a m/z ratio reported by the instrument. Additionally, we can estimate the charge looking \nat the isotopic cluster. We take the peptide \u0022DTDILAAFR\u0022 from our previous notebook again. Our example has a measured m/z = 511.2691141 and \na charge of z=2.\n*)\n\nlet peptideMass = \n    Mass.ofMZ 511.2691141 2.\n\npeptideMass\n\n(***include-it***)\n\n(**\nFrom our previos notebook *NB02b\\_Digestion\\_and\\_mass\\_calculation.ipynb*, we know how to \ncalculate all peptide masses that we can expect to be present in *Chlamydomonas reinhardtii*.\n*)\n\n// Code-Block 4\nlet path2 = Path.Combine[|directory;\u0022downloads/Chlamy_JGI5_5(Cp_Mp).fasta\u0022|]\ndownloadFile path2 \u0022Chlamy_JGI5_5(Cp_Mp).fasta\u0022 \u0022bio-bte-06-l-7\u0022\n\nlet peptideAndMasses = \n    path2\n    |\u003E IO.FastA.fromFile BioArray.ofAminoAcidString\n    |\u003E Seq.toArray\n    |\u003E Array.mapi (fun i fastAItem -\u003E\n        Digestion.BioArray.digest Digestion.Table.Trypsin i fastAItem.Sequence\n        |\u003E Digestion.BioArray.concernMissCleavages 0 0\n        )\n    |\u003E Array.concat\n    |\u003E Array.map (fun peptide -\u003E\n        // calculate mass for each peptide\n        peptide.PepSequence, BioSeq.toMonoisotopicMassWith (BioItem.monoisoMass ModificationInfo.Table.H2O) peptide.PepSequence\n        )\n\npeptideAndMasses |\u003E Array.head\n\n(***include-it***)\n\n(**\nHowever, we are only interest in possible amino acid sequences, that match the particular precursor peptide mass of our example spectrum \nwith 1020.523675 Da. Additionaly, we should also consider a small measurement error.\n*)\n\n// Code-Block 5\n\npeptideAndMasses\n|\u003E Array.filter (fun (sequence,mass) -\u003E mass \u003E 1020.52  \u0026\u0026 mass \u003C 1020.53)\n\n(***include-it***)\n\n(**\nIn the previous notebook *NB04a\\_Fragmentation\\_for\\_peptide\\_identification.ipynb*, \nwe used functions that generate the theoretical series of b- and y-ions from the given peptide. Combined with the function \n\u0060Mz.SequestLike.predictOf\u0060 that generates theoretical spectra that fit the Sequest scoring algorithm.\n*)\n\n// Code-Block 6\n\nlet predictFromSequence peptide =\n    [\n        peptide\n        |\u003E Mz.Fragmentation.Series. yOfBioList BioItem.initMonoisoMassWithMemP\n        peptide\n        |\u003E Mz.Fragmentation.Series.bOfBioList BioItem.initMonoisoMassWithMemP\n    ]\n    |\u003E List.concat\n    |\u003E Mz.SequestLike.predictOf (lowerScanLimit,upperScanLimit) 2.\n\n\n(**\n### Step 3\u002B4: Matching and Scoring\n\nIn the matching step, we compare theoretical spectra of peptides within our precursor peptide mass range with our measured spectra. \nWe get a score which tells us how well the theoretical spectrum fits the given experimental spectrum.\n*)\n\n// Code-Block 7\nlet sortedScores = \n    peptideAndMasses\n    |\u003E Array.filter (fun (sequence,mass) -\u003E\n        mass \u003E 1020.52  \u0026\u0026 mass \u003C 1020.53\n    )\n    |\u003E Array.map (fun (sequence,mass)    -\u003E\n        sequence,predictFromSequence sequence\n    )\n    |\u003E Array.map (fun (sequence,theoSpectrum) -\u003E \n        sequence,BioFSharp.Mz.SequestLike.scoreSingle theoSpectrum preprocessedIntesities\n    )\n    |\u003E Array.sortByDescending (fun (sequence,score) -\u003E score)\n\nsortedScores \n\n(***include-it***)\n\n(**\nFinally, we pick the sequence with the best score and are done for now. Notice however, that in a real world we would need to \nrelate our score to the complete data set to get an idea of the overall quality and which numerical value we could trust. \n*)\n\n(**\n## Questions\n\n1. How does the Chart change, when you change the value of \u0027numberofwindows\u0027 from 10 to 20?\n  What does this parameter specify? (Code-Block 3)\n2. What is the rational behind the normalization of measured spectra?\n3. Why are we adding the mass of water to the peptide sequence? (BioItem.monoisoMass ModificationInfo.Table.H2O) (Code-Block 4)\n4. In code block 6 you get a raw estimate on how many peptide sequences are candidates for a match, when given a certain mz.\nGiven that one MS run can consist of up to 120.000 ms2 spectra, how many peptide spectrum matches do you have to perform?\nWhat does that mean for the performance of the application? Which parameters influence the size of the \u0022search space\u0022? (Code-Block 6)\n5. What happens when you choose different lower and upper scan limits?\n6. Visualize the distribution of scores using a histogram. (Code-Block 7)\n*)"},{"uri":"/BIO-BTE-06-L-7/NB00b_FSharp_Coding_literacy_Part_II.html","title":"NB00b FSharp Coding literacy part II\n","content":"(**\n# NB00b FSharp Coding literacy part II\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB00b_FSharp_Coding_literacy_Part_II.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB00b/NB00b_FSharp_Coding_literacy_Part_II.ipynb)\n\n1. Making sense of sequences\n    1. Strings have their own module \n    2. Bio-collections are F# collections\n    3. All collections have their modules\n    4. Seq module contains the skeleton key functions\n    5. Build a map to associate values with a key \n2. Higher-order functions     \n    1. Functions can consume other functions\n    2. Pipe-forward operator |\u003E \n3. More interesting types \n    1. Tuples are ad hoc data structures \n    2. Record types provide more organization\n\n## Making sense of sequences\n\nSequences are a key part of biology, and therefore, storing, searching, and analyzing protein and nucleic sequences plays an important role in computational biology. \nIn many languages, biological sequences are simply represented as strings. \n\nHere\u2019s a very simple DNA sequence: \n*)\n\nlet mySequence = \u0022atcg\u0022 \n\n(**\nIn F# there are a lot of functions available by default to manipulate strings all of which can be found in the String module. \n\n### Strings have their own module \n\nWe learned previously that modules are simply a container to organize your functionality. To make use of that functionality you need to know the name of the respective \nmodule and be aware that you can access everything with the \u0060.\u0060 operator. The name of the module for \u2018string\u2019 types is \u2018String\u2019 with a capital to distinguish the module \nfrom its type. *- FYI -* this is true for all core types in F#.\n*)\n\nString.length \u0022atcg\u0022\n\n(**\nHere, the \u0060 String.Length \u0060 returns the length of the string sequence. If you are using a nice text editor with more sophisticated code completion (intelliSense), you can \nexplore the functionality provided within a module by pressing \u0060Strg \u002B Space\u0060. Otherwise, you need to look it up in one of many [documentations.](https://fsharp.github.io/fsharp-core-docs/reference/fsharp-core-stringmodule.html)\n\nAnother interesting feature of strings is that their characters can also be accessed according to their numerical position, starting from 0 up to 1 minus the length of the \nstring. You can also slice strings up using a [from .. to] syntax:\n*)\n\n\u0022atcg\u0022.[2]\n\u0022atcg\u0022.[1..2]\n\n(**\nTechnically, strings are specialized collection of characters and we have seen how to represent a nucleotide sequence.\n\n### Bio-collections are F# collections\n\nIn contrast to the alphabet of letters we use in natural language, biological nucleotide and amino acid alphabets have a smaller set of valid characters. This allows us to \nrepresent biological sequence data that encode DNA and proteins more efficiently using BioFSharp.\n*)\n// Get BioFSharp from nuget \n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\nopen BioFSharp \n\nlet adenine = Nucleotides.A\nlet alanine = AminoAcids.Ala\n\n(**\nSequence types or collection types are a series of any items or values rather than only characters. There are different variations of collection types with different properties \nregarding there manipulation and efficiency. To cover all different kinds and their methods to manipulate them would go far beyond the scope of this introduction. So, we will \nfocus on the most important types and methods of manipulation. Collections provide a more flexible way to work with groups of items. In the case of our Bio-collections from \nBioFSharp the items of the biological alphabets. Here is an example of a list of nucleotides: \n*)\nopen BioFSharp.Nucleotides \n\nlet nucs = [ A; T; C; G; ]\n\n(**\nNotice here that we have stored the exact same sequence as in our previous string example, but this time in list format. Notice how the items are separated by a semicolon and\nenclosed in square brackets instead of quotes. Analogously, we can access each item by its index, however, in case of lists this is not very efficient. \n*)\n\n// Accessing position 3 (remember index start at 0)\nnucs.[2]\n// Add elongates the list (very efficient operation on lists)\nlet nucs\u0027 = G::A::nucs\n\n(**\nIf you need a collection type with the opposite properties, meaning fast random access but very inefficient adding or deleting elements an array is what you want to use instead. \nJust add the additional \u0060|\u0060 and you have an array.\n*)\n// The same sequence but as an array\nlet nucsArr = [| A; T; C; G; |]\n\n(**\n### All collections have their modules \n\nWhenever you need functions to manipulate bio-collections, you might find them in the respective module. You can either use intelliSense to browse the available functions or you \ncan have a look at the documentation [here.](https://csbiology.github.io/BioFSharp)\n\nWith functions you find in the Bio-collection modules you can easily compute for example the complementary mRNA sequence or translate it into the corresponding peptide sequence.\n*)\n\n// Reverse complement of a sequence as a BioArray\nBioArray.reverseComplement nucsArr\n\n// Translate to peptide \nBioList.translate 0 [A; U; C; G; C; G]\n\n// Use the Array module to find the index of the first occurring cytosine\nArray.findIndex (fun n -\u003E n = C)  [| A; T; C; G; |]\n\n(**\nHowever, it is worth noticing that the bio-collections are normal F# collections. The Bio* modules just enhance the functionalities of the default modules. In the example, we \napply the \u0060Array.findIndex\u0060 functions from the default array module to a BioArray to find the index of the first occurring cytosine. \n\nA full overview of the default collections and their respective modules can be found [here.](https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/fsharp-collection-types)\n\n\nThere is one module that you might see quite often when working with collections in F#. It is more generic compared to the others previously discussed as it is able to manipulate \nall enumerable collections. The \u0060Seq.\u0060  module contains functions that can take list collections as well as array collections as input\n (or others that are [enumerable).]( https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/fsharp-collection-types).\nIn the following example we apply the same functions to a list and on an array. \n\n### Seq module contains the skeleton key functions\n\nIt is worth mentioning that in the module of F# collections you will find functions to convert from one collection type to another. I believe that you can imagine the reason \nfor such an operation. You know by now that depending on the use case one collection might be advantages compared to the other. For example, if you know that you need to access \nyour sequence multiple times at different position, you want to convert it from a list into an array.\n*)\n\n// Returns the length of the array\nSeq.length [| A; T; C; G; |]\n// Returns the length of the list  \nSeq.length [ A; T; C; G; ]\n// The input is a list type the output an array type \nList.toArray [ A; T; C; G; ]\n\n(**\nDue to those performance issues, certain functionality is only offered on particular collection types and you need to do the conversion first before you can apply this function.\n\n### Build a map to associate values with a key\n\nWe learned that you can access the elements within collections by its numerical position index. To build more complex examples, it might be necessary to have a more sophisticated \nway to associate values with a key. A map is built from a list of key-value pairs using the so-called Map constructor. \n\nThis just means you need to write \u0060Map\u0060 in front of that key-value pair list:\n*)\n\nlet mass = Map [\u0022Hydrogen\u0022,1.0079; \u0022Carbon\u0022, 12.001]\n\n(**\nExtracting a value from a Map work similar to accessing an array using the key instead of the index. \n*)\n\nmass.[\u0022Carbon\u0022]\n\nMap.find \u0022Cabon\u0022 mass\n\n(**\nAnalogously to the List and Array module there is a Map module. \nA full overview of all map function can be found [here]( https://fsharp.github.io/fsharp-core-docs/reference/fsharp-collections-fsharpmap-2.html).\n\n\n## Higher-order functions     \nIn F# as a functional programming language, you should be able to do with a function whatever you can do with values of the other types and be\n able to do so with a comparable degree of effort. This includes the following:\n* You can bind functions to identifiers and give them names.\n* You can store functions in data structures, e.g. such as in a list.\n* You can pass a function as an argument in a function call. \n* You can return a function from a function call.\nThe last two define what are known as higher-order operations or higher-order functions. A higher-order function is a function that takes another function as a parameter. \nThis is simple but leads to one of the most important concepts of functional programming: *mapping and folding*. \n\n### Functions can consume other functions\n\nMapping is when a function applies computation working on an inner space and then returns the outer space as a result. This sounds complicated, but let\u2019s dive right into it \nand see how this works. We first need a function that will later be the function working on the inner space. The function \u0060monoisoMass\u0060 from the \u0060AminoAcids\u0060 module in \nBioFSharp returns the monoisotopic mass of the given amino acid as the name suggests: \n*)\n\n// Function working on the inner space \nAminoAcids.monoisoMass AminoAcids.Ser\n// Outer or elevated space\nopen AminoAcids\n\nlet peptide = [ Pro; Glu; Pro; Thr; Ile; Asp; Glu; ]\n\n(**\nNow, we want to apply the function \u0060monoisoMass\u0060 to each amino acid in the peptide list. For that we can make use of the \u0060List.map\u0060 function. This is very convenient as the \nrecursive process that steps through the list and builds a list of the results to return. That part is captured in the mapping function. \n*)\n\nList.map AminoAcids.monoisoMass peptide\n\n(**\nThe higher-order function map applies a function working on the normal space to an elevated space. This concept is so important that all collection types (lists, arrays, ...) \nhave a build in map function.  \nIf your higher-order function applies a function to the inner space and the return value is not the outer space, you are folding aka. aggregating. Just to build on the example \nabove, we can compute the sum of all amino acids being elements of the peptide list. \n*)\n\nList.sumBy AminoAcids.monoisoMass peptide\n\n(**\nMaybe it is worth noticing that the mass of water needs to be added to calculate the correct peptide mass.\n\n### Pipe-forward operator |\u003E \n\nF# is all about readability. Here, pipe operators are used to pass parameters to a function in a simple and elegant way. It allows to eliminate intermediate values and \nmake function calls easier to read. It possible to chain function calls and feed the return value of each function to the next using the forward type operator which looks \nlike this: |\u003E . We can literally read it as \u201Cpipe forward\u201D.\n*)\n\n[ Pro; Glu; Pro; Thr; Ile; Asp; Glu; ]\n|\u003E List.map AminoAcids.monoisoMass \n|\u003E List.sum\n\n(**\n\n## More interesting types \n\nWe already learned about type annotation that it defines the kind of the value you and the compiler have to deal with. Therefore, you can think of type annotation as a sort of \ndata modelling tool that allows you to represent a real-world domain in your code. The better the type definitions reflect the real-world domain, the better they will statically  \nencode the rules. This means you will always be warned if you violate the rules you defined. That will help you to avoid mistakes within your code. In practice, if you try to  \nsum binding x \u002B y and x is bound to the number 5 (datatype = int) whereas y is bound to the word \u201CPEPTIDE\u201D (datatype = string) the compiler will not allow it, while if y is \nbound to number 7 you will get 12 as a valid result. \n\nHowever, using only literal or primitive types may be not enough. You most probably want to do something more interesting that is not based solely on numbers or letters. To do \nso you need to be able to produce your own types.   \n\nThe key to understanding the power of types in F# is that most new types are constructed from other types just combing types that already exist. You can think of your own type \ndefinition as an organization or grouping of other types. To do so, every type definition is similar, even though the specific details may vary. All type definitions start with \na \u0022type\u0022 keyword, followed by an name or identifier for the type, which then is followed by any existing type(s). \n\nFor example, here are some type definitions for a variety of types:\n*)\n\ntype A = int * int\n\ntype B = {AminoAcidName:string; Mass:float}\n\n(**\n### Tuples are ad hoc data structures \nTuples have several advantages over other more complex types. They can be used on the fly because they are always available without being defined, and thus are perfect for small, \ntemporary, lightweight structures. Some people think of tuples as small list with a fixed length and different types. If you look at the way to create a list and compare it to a \ntuple, you will see why:\n*)\n// Creating a list\n[ 1.1; 3.5; 2.0 ]\n\n// Creating a tuple by changing the semicolon to a comma and the square brackets to curved brackets\n(  1.1, 3.5, 2.0 )\n\n// Creating another tuple\n( 115.026943, \u0022asp\u0022 )\n\n(**\nHowever, while collections can only contain elements of the same type, with tuples you can combine different types in the same tuple type. Also accessing values from a tuple is quite \ndifferent compared to a collection type. \n\n*)\n// Accessing the value at position 2 of a list\n[ 1.1; 3.5; 2.0 ].[1]\n\n// Accessing the value at position 2 of a tuple\nlet monoMass, threeLetterCode = ( 115.026943, \u0022asp\u0022 )\nthreeLetterCode\n\n(**\nYou notice that accessing a value from a tuple means create a named binding that has the same structure (a process called deconstruction). After this, the individual values have their \nown names and can be used separately. Therefore, it is easy to define functions that can access individual positions of tuple types. \n\nLet\u0027s define a function that returns the three-letter:\n*)\nlet getThreeLetterCode (monoMass, threeLetterCode) =\n    threeLetterCode\n\ngetThreeLetterCode ( 115.026943, \u0022asp\u0022 )\n\n(**\nTuples are also very useful in the common scenario when you want to return multiple values from a function rather than just one.\n*)\n\nlet returnTwoValues () =\n    (\u0027A\u0027,100)\n\n(**\n\n### Record types provide more organization\n\nTuples are useful in many cases. But they have some disadvantages too. Because all tuple types are pre-defined, you can\u0027t distinguish between a string and a float used for an \namino acid mass with one-letter-code say, vs. a similar tuple used for nucleotide. \n\nAnd when tuples have more than a few elements, it is easy to get confused about which element is in which place. In these situations, what you would like to do is label each \nslot in the tuple, which will both document what each element is for and force a distinction between tuples made from the same types. A record type is exactly that: A tuple \nwhere each element is labeled.\n*)\n// Define a record type amino acid\ntype AminoAcidMass = { OneLetterCode: char; Mass: float }\n// Define a record type nucleotide\ntype NucleotideMass = { Symbol: char; Mass: float }\n\n// Bind an amino acid value to a name binding\nlet asp = { OneLetterCode = \u0027D\u0027; Mass = 115.026943 }\n\n(**\nA record type has the standard preamble: \u0060type\u0060 typename = followed by curly braces. Inside the curly braces is a list of label: type pairs, separated by semicolons (notice: We \nwill see later that all lists in F# use semicolon separators -- commas are for tuples).\n\nLet\u0027s compare the \u0022type syntax\u0022 for a record type with a tuple type:\n*)\n\n// Definition of a record type \ntype AminoAcidMassRecord = { OneLetterCode: char; Mass: float }\n// Definition of a tuple type \ntype AminoAcidMassTuple = char * float\n\n(**\nYou see that record types have named fields that make them easily accessible. A Field of a record type can be accessed individually with the dot operator \u0060.Fieldname\u0060\n*)\n\n//Create cysteine  \nlet cys = { OneLetterCode = \u0027C\u0027; Mass = 103.0091848 }\n// Access the one-letter-code of cysteine\ncys.OneLetterCode\n// Access the monoisotopic mass of cysteine and multiply it times 3\ncys.Mass * 3.\n"},{"uri":"/BIO-BTE-06-L-7/NB03b_Signal_detection_and_quantification.html","title":"NB03b Signal detection and quantification\n","content":"(**\n# NB03b Signal detection and quantification\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB03b_Signal_detection_and_quantification.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB03a_NB03b_NB03c/NB03b_Signal_detection_and_quantification.ipynb)\n\n1. Signal detection and quantification\n\n*)\n\n(**\n## Signal detection and quantification\n\nSignals detected during a LC-MS measurement are pairs of m/z value and ion intensity in time. All signals recorded at a particular retention \ntime in a given mass range compose a spectrum. Thus, in its most raw form, a generic spectrum contains the following information: (i) scan \n(spectra) number; (ii) retention time; (iii) vector of m/z values; (iv) vector of ion intensities; (v) scan mode. The scan number is a simple \nenumeration over the measurements. The retention time is the time when the measured peptides were eluting from the column. The m/z values \nrepresent the mass over charge values of the ions and ion intensity values are the corresponding ion abundances. The scan mode denotes the \noperational mode used to record the spectrum. It is either a full scan or the number of the fragmentation scan.\n\n![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/MSDerivedDataSpaces.PNG)\n\n**Figure 3: A conceptual view of different spaces of MS derived data sets.**\n(i) The metadata-space serves as a descriptive layer to order, assign and integrate spectra information. (ii) \nThe MS1-space and the (iii) MS2-space represent two independent entities that differ in signal shape, resolution and their \ninformation content (\u2018features\u2019).\n*)\n\n\n(**\n## Questions\n\n1. How can it be benefitial to store meta data and peak data separated from each other? \n2. A raw ms1 spectrum measured in profile mode can contain up to 150.000 data points. Each \ndata point is given by a value pair: mz and intensity. Lets say you want to encode both values\nat a very high precision using 64 bit float numbers, how much memory do you need to store one \nspectrum? How much for a file consisting of 60.000 spectra. \n3. Can you store the data more efficiently?\n*)"},{"uri":"/BIO-BTE-06-L-7/NB06b_Data_Access_And_Quality_Control.html","title":"NB06a Data Access and Quality Control\n","content":"#r \u0022nuget: FSharp.Stats, 0.4.0\u0022\n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta5\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: BIO-BTE-06-L-7_Aux, 0.0.6\u0022\n#r \u0022nuget: Deedle, 2.3.0\u0022\n#r \u0022nuget: ISADotNet, 0.2.4\u0022\n#r \u0022nuget: ISADotNet.XLSX, 0.2.4\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen System.IO\nopen ISADotNet\nopen ISADotNet.API\nopen Deedle\nopen BioFSharp\nopen FSharpAux\nopen FSharp.Stats\nopen Plotly.NET\nopen FSharp.Stats.Fitting.LinearRegression.OrdinaryLeastSquares.Linear\nopen System.IO\nopen BIO_BTE_06_L_7_Aux.FS3_Aux\nopen BIO_BTE_06_L_7_Aux.Deedle_Aux\n\n(**\n# NB06a Data Access and Quality Control\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB06b_Data_Access_And_Quality_Control.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB06b/NB06b_Data_Access_And_Quality_Control.ipynb)\n\nWith this notebook we want converge the threads of computational and experimental proteomics by analyzing the data measured by you during the practical course.\nBehind the scenes there was already a lot going on! While your were going through the hands-on tutorials addressing single steps of the computation proteomics pipeline, we executed\na pipeline combining all the steps. In this tutorial, we will provide you with the output of the pipeline, your sample description and a lot of code, which should help you explore the \ndata set generated by you! Since the experiment is of a non neglectable depth - so is the code needed to analyze it. Do not hesitate if you do not understand every step right away, this is no\ntrivial task and nontrivial are the means to achieve it! We included some questions along the way, the questions aim to check your understanding, but they can also serve as food-for-thought.\n\nFor the explorative data analysis, we are using [Deedle](http://bluemountaincapital.github.io/Deedle/tutorial.html).\nDeedle is an easy to use library for data and time series manipulation and for scientific programming. \nIt supports working with structured data frames, ordered and unordered data, as well as time series. Deedle is designed to work well for exploratory programming using F#.\n\n## Reading the sample description\n\nBefore we analyze our data, we will download and read the sample description provided by the experimentalist.\n*)\nlet directory = __SOURCE_DIRECTORY__\nlet path2 = Path.Combine[|directory;\u0022downloads/alle_Gruppen_V7_SWATE.xlsx\u0022|]\ndownloadFile path2 \u0022alle_Gruppen_V7_SWATE.xlsx\u0022 \u0022bio-bte-06-l-7\u0022\n\nlet _,_,_,myAssayFile = XLSX.AssayFile.AssayFile.fromFile path2\nlet inOutMap = BIO_BTE_06_L_7_Aux.ISA_Aux.createInOutMap myAssayFile\n\n(**\nNext, we will prepare functions that given a file name look up parameters which might be needed for further calculations. \n*)\n\nlet normalizeFileName (f:string) = if Path.HasExtension f then f else Path.ChangeExtension(f, \u0022wiff\u0022)\n\n//        \nlet getStrain (fileName:string) =\n    let fN = fileName |\u003E normalizeFileName\n    BIO_BTE_06_L_7_Aux.ISA_Aux.tryGetCharacteristic inOutMap \u0022Cultivation -Sample preparation\u0022 \u0022strain\u0022 fN myAssayFile\n    |\u003E Option.defaultValue \u0022\u0022\n\n//\nlet getExpressionLevel (fileName:string) =\n    let fN = fileName |\u003E normalizeFileName \n    BIO_BTE_06_L_7_Aux.ISA_Aux.tryGetCharacteristic inOutMap \u0022Cultivation -Sample preparation\u0022 \u0022gene expression\u0022 fN myAssayFile \n    |\u003E Option.defaultValue \u0022Wt-Like\u0022\n\n//  \nlet get15N_CBC_Amount (fileName:string) =\n    let fN = fileName |\u003E normalizeFileName\n    BIO_BTE_06_L_7_Aux.ISA_Aux.tryGetCharacteristic inOutMap \u0022Extraction\u0022 \u0022gram\u0022 fN myAssayFile |\u003E Option.defaultValue \u0022\u0022\n    |\u003E String.split \u0027 \u0027\n    |\u003E Array.head\n    |\u003E float \n//\nlet get15N_PS_Amount (fileName:string) =\n    let fN = fileName |\u003E normalizeFileName\n    BIO_BTE_06_L_7_Aux.ISA_Aux.tryGetCharacteristic inOutMap \u0022Extraction\u0022 \u0022gram #2\u0022 fN myAssayFile |\u003E Option.defaultValue \u0022\u0022\n    |\u003E String.split \u0027 \u0027\n    |\u003E Array.head\n    |\u003E float \n//\nlet getGroupID (fileName:string) =\n    let fN = fileName |\u003E normalizeFileName\n    BIO_BTE_06_L_7_Aux.ISA_Aux.tryGetParameter inOutMap \u0022Extraction\u0022 \u0022Group name\u0022 fN myAssayFile |\u003E Option.defaultValue \u0022\u0022\n    |\u003E int    \n\n(**\nA quick execution to assure that all values can be retrieved from the isa sample table:\n*)\ngetStrain \u0022WCGr2_U1.wiff\u0022\ngetExpressionLevel \u0022WCGr2_U1.wiff\u0022\nget15N_CBC_Amount \u0022WCGr2_U1.wiff\u0022\nget15N_PS_Amount \u0022WCGr2_U1.wiff\u0022\ngetGroupID \u0022WCGr2_U1.wiff\u0022\n\n(**\nNow that we have the sample sheet, all that is missing is the data to be analyzed:\n*)\n\nlet path = Path.Combine[|directory;\u0022downloads/Quantifications_wc_annotated.txt\u0022|]\ndownloadFile path \u0022Quantifications_wc_annotated.txt\u0022 \u0022bio-bte-06-l-7\u0022\n\n(**\n## Raw data access using Deedle:\nAs teasered in the primer, we want to work with our tabular data using Deedle. Luckily Deedle does nonly deliver data frame and series\nmanipulation, but also allows us to quickly read the recently downloaded data into the memory:\n*)\n\nlet rawData = Frame.ReadCsv(path,separators=\u0022\\t\u0022)\n\n(**\nTo visualize the data we can call the \u0022formatAsTable\u0022 function. The preview of visual studio code does not allow\nfor the charts to be scrollable so we pipe the output into \u0022Chart.Show\u0022, to visualize the data in your browser.\n*)\n\n(***condition:ipynb***)\n#if IPYNB\nrawData\n|\u003E Frame.take 10\n|\u003E formatAsTable \n|\u003E Chart.Show\n#endif // IPYNB\n(***hide***)\nrawData |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n(**\nLooking at the raw data, we can see, that each row contains a different quantifiction of a peptide ion, with the columns containing \na single ion feature each, such as peptide ion charge, sequence or a quantification value reported for a file (e.g. light, heavy or ratio).\nSince the columns ProteinGroup, StringSequence, PepSequenceID and Charge uniquely identify a row, we can use these to index the rows.\nFor this we use a language feature called [\u0022anonymous record type\u0022](https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/anonymous-records). \nHere we create a tuple like structure, with the additional feature, that each element of the tuple is named (e.g.: Proteingroup).\n*)\nlet indexedData =\n    rawData\n    // StringSequence is the peptide sequence\n    |\u003E Frame.indexRowsUsing (fun os -\u003E \n            {|\n                ProteinGroup    = os.GetAs\u003Cstring\u003E(\u0022ProteinGroup\u0022); \n                Synonyms        = os.GetAs\u003Cstring\u003E(\u0022Synonyms\u0022)\n                StringSequence  = os.GetAs\u003Cstring\u003E(\u0022StringSequence\u0022);\n                PepSequenceID   = os.GetAs\u003Cint\u003E(\u0022PepSequenceID\u0022);\n                Charge          = os.GetAs\u003Cint\u003E(\u0022Charge\u0022)\n            |}\n        )\n\n\n(***condition:ipynb***)\n#if IPYNB\n// The effect of our frame manipulation can be observed:\nindexedData\n|\u003E Frame.take 10\n|\u003E formatAsTable \n|\u003E Chart.Show\n#endif // IPYNB\n(***hide***)\nindexedData |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n(**\n## Augmenting and filtering the data frame \nThe data frame already contains all information needed to perform the analysis, but it could still benefit from \nsome quality-of-life upgrades. For this we want to encode the specific qConcat protein as a separate feature:\n*)\n// Why does it make sense to model Qprots using this type, why do we not simply use a string?\ntype Qprot = \n    | CBB\n    | PS \n\nlet finalRaw = \n    indexedData\n    |\u003E Frame.mapRowKeys (fun k -\u003E\n        let qprot = \n            match k.ProteinGroup |\u003E String.contains \u0022QProt_newCBB\u0022, k.ProteinGroup |\u003E String.contains \u0022QProt_newPS\u0022 with \n            | true, false  -\u003E Some CBB\n            | false, true  -\u003E Some PS \n            | _ -\u003E None  \n        {|k with QProt = qprot|}\n        )\n    // What does this line filter for? Why does this make sense for our analysis?\n    // How many peptide ions did the filter remove? \n    |\u003E Frame.filterRows (fun k s -\u003E k.QProt.IsSome)\n    |\u003E Frame.mapRowKeys (fun k -\u003E {|k with QProt = k.QProt.Value|})\n\n// Finally we want to define a function that given a distinct Qprot,\n// returns the correct ISA lookup. (See: \u0027Reading the sample description\u0027)\nlet initGetQProtAmount qProt =\n    match qProt with \n    | CBB -\u003E get15N_CBC_Amount\n    | PS  -\u003E get15N_PS_Amount\n\n(***condition:ipynb***)\n#if IPYNB\nfinalRaw\n|\u003E Frame.take 10\n|\u003E formatAsTable \n|\u003E Chart.Show\n#endif // IPYNB\n(***hide***)\nfinalRaw |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n\n(**\n## Global quality control.\n\nWith our data frame prepared, we want to see on a global scale if our experiment worked.\nFor this we plot the overall mean of the 14N and 15N quantifications and observe if we can recover our dilution series (15N),\nwhile keeping the analyte to be quantified at a constant level (14N).\n\nSince it comes in handy to simplify the data frame, in this code we will only keep columns that contain a specific identifier, \nsuch as, \u0022Ratio\u0022, \u0022Light\u0022, or \u0022Heavy\u0022. \n*)\nlet sliceQuantColumns quantColID frame = \n    frame\n    |\u003E Frame.filterCols (fun ck os -\u003E ck |\u003E String.contains (\u0022.\u0022\u002BquantColID))\n    |\u003E Frame.mapColKeys (fun ck -\u003E ck.Split(\u0027.\u0027) |\u003E Array.item 0)\n\n// How did the data frame change, how did the column headers change?\nlet ratios = sliceQuantColumns \u0022Ratio\u0022 finalRaw\nlet light  = sliceQuantColumns \u0022Light\u0022 finalRaw\nlet heavy  = sliceQuantColumns \u0022Heavy\u0022 finalRaw\n\n(***condition:ipynb***)\n#if IPYNB\nratios\n|\u003E Frame.take 10\n|\u003E formatAsTable \n|\u003E Chart.Show\n#endif // IPYNB\n(***hide***)\nratios |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n\n(**\nA nice tool to explore and compare distributions of different populations is the representation as a boxplot!\nTo use this tool, we will define a function, which creates a boxplot for every column (file) of our data set:\n*)\nlet createBoxPlot f = \n    f\n    |\u003E Frame.getNumericCols\n    |\u003E Series.map (fun k s -\u003E \n         let x,y =\n            s\n            |\u003E Series.values \n            |\u003E Seq.map (fun values -\u003E k,values)\n            |\u003E Seq.unzip\n         Chart.BoxPlot(x,y,Orientation=StyleParam.Orientation.Vertical)         \n         )\n    |\u003E Series.values\n    |\u003E Chart.Combine\n    |\u003E Chart.withY_AxisStyle \u0022Ion intensity\u0022\n\n(**\nThe function applied to the n14 values: \n*)\n// How is the data distributed?\nlight\n|\u003E createBoxPlot\n\n(***hide***)\nlight |\u003E createBoxPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n(**\nThe function applied to the n15 values:\n*)\n\n// Can you recover the dilution series?\nheavy\n|\u003E createBoxPlot\n\n(***hide***)\nheavy |\u003E createBoxPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n(**\nThe following function performs a normalization which accounts for a specific effect. Can you \ndetermine what the function accounts for?\n*)\nlet normalizePeptides f =\n    f\n    |\u003E Frame.transpose\n    |\u003E Frame.getNumericCols\n    |\u003E Series.mapValues (fun s -\u003E \n        let m = Stats.median s\n        s / m \n        )\n    |\u003E Frame.ofColumns\n    |\u003E Frame.transpose\n(**\n*)\n// How does the distribution of the date change, when the normalization is applied? \nlight \n|\u003E normalizePeptides\n|\u003E createBoxPlot\n\n(***hide***)\nlight |\u003E normalizePeptides |\u003E createBoxPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n(**\n*)\nheavy\n|\u003E normalizePeptides\n|\u003E createBoxPlot \n(***hide***)\nheavy |\u003E normalizePeptides |\u003E createBoxPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n(**\nFinally we have a look at the ratios. \n*)\n\n// Does it make sense to normalize the ratios the same way?\nratios\n|\u003E createBoxPlot \n\n(**\n## V. Local quality control. \n\nNow that we know on a global scale how our experiment worked it might be time to have a look at the details.\nFirst, we want to write a function that allows us to plot all peptides of a protein vs. the dilution used. This way we can identify peptides that\nwe want to use and those, that seem to be prone to error and should thus be discarded. \nTo keep things simple, we apply a filter step at the beginning, which only keeps peptides belonging to one protein and samples measured by one group\nin the data frame. What are sources of error? Which peptides do you think should be discarded and why? Which proteins need to be analyzed with extra care?\nHint: you can hover over the data points to get insight into the file name and gene expression pattern of the corresponding strain.\n*)\n\n// With this type we create an alias to our row key, this allows us to write functions, which operate on data frames such as \u0027plotPeptidesOf\u0027,\u0027discardPeptideIonInFile\u0027 and \u0027discardPeptideIon\u0027\ntype PeptideIon = \n    {|\n        ProteinGroup    : string  \n        Synonyms        : string\n        StringSequence  : string\n        PepSequenceID   : int\n        Charge          : int\n        QProt           : Qprot\n    |}\n\n\n// Given a frame, a prot-ID and a group-ID this function creates an xy plot for every peptide ion belonging to the protein/proteingroup.\n// The parameter \u0027prot\u0027 can either be given a valid Cre-ID or a synonym.\n// What is the unit of the x-Axis? How is the ratio calculated? \nlet plotPeptidesOf (ratios:Frame\u003CPeptideIon,string\u003E) (prot:string) (groupID:int) = \n    ratios\n    |\u003E Frame.filterRows (fun k s -\u003E k.Synonyms.Contains prot || k.ProteinGroup.Contains prot )\n    |\u003E Frame.filterCols (fun k s -\u003E getGroupID k = groupID)    \n    |\u003E Frame.transpose\n    |\u003E Frame.getNumericCols\n    |\u003E Series.map (fun pep (values) -\u003E \n        let getQProtAmount = initGetQProtAmount pep.QProt\n        let qprotAmounts,ratios,fileLabel =\n            values\n            |\u003E Series.map (fun fileName (ratio) -\u003E \n                    let qProtAmount =  getQProtAmount fileName\n                    let expressionLevel = getExpressionLevel fileName\n                    qProtAmount, ratio, (sprintf \u0022%s %s\u0022 fileName expressionLevel)         \n                )\n            |\u003E Series.values\n            |\u003E Seq.unzip3\n        Chart.Point(qprotAmounts,ratios,Labels=fileLabel)\n        |\u003E Chart.withTraceName (sprintf \u0022S:%s_C:%i\u0022 pep.StringSequence pep.Charge)\n        |\u003E Chart.withX_AxisStyle(\u0022qProt Amount\u0022)\n        |\u003E Chart.withY_AxisStyle(\u0022Ratio\u0022)\n        )\n    |\u003E Series.values\n    |\u003E Chart.Combine\n\n(**\nFirst we get an overview of available protein ids.\n*)\n\nratios.RowKeys\n|\u003E Array.ofSeq \n|\u003E Array.map (fun k -\u003E k.Synonyms)\n|\u003E Array.distinct\n\n(**\nThen we can start to visualizes our results:\n*)\nplotPeptidesOf ratios \u0022rbcL\u0022 1\n(***hide***)\nplotPeptidesOf ratios \u0022rbcL\u0022 1 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n(**\n*)\nplotPeptidesOf ratios \u0022RBCS2;RBCS1\u0022 2\n(***hide***)\nplotPeptidesOf ratios \u0022RBCS2;RBCS1\u0022 2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n(**\n*)\nplotPeptidesOf ratios \u0022FBP1\u0022 2\n(***hide***)\nplotPeptidesOf ratios \u0022FBP1\u0022 2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n(**\n*)\nplotPeptidesOf ratios \u0022FBP2\u0022 2\n(***hide***)\nplotPeptidesOf ratios \u0022FBP2\u0022 2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n(**\n*)\nplotPeptidesOf ratios \u0022SEBP1\u0022 2\n(***hide***)\nplotPeptidesOf ratios \u0022SEBP1\u0022 2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n(**\nWith the plots at hand we can use the following functions to manipulate the data frame and discard peptides and/or whole files which we do not want to use for \na absolute protein quantification e.g.:\n*)\nlet discardPeptideIonInFile stringsequence charge filename (ratios:Frame\u003CPeptideIon,string\u003E) = \n    ratios\n    |\u003E Frame.map (fun r c value -\u003E if r.StringSequence = stringsequence \u0026\u0026 r.Charge = charge \u0026\u0026 c=filename then nan else value)\n\nlet discardPeptideIon stringsequence charge (ratios:Frame\u003CPeptideIon,string\u003E) = \n    ratios\n    |\u003E Frame.filterRows (fun r s -\u003E (r.StringSequence = stringsequence \u0026\u0026 r.Charge = charge) |\u003E not)\n(**\nThese functions can then be used to create an updated version of the frame, containing only the values we want to use for quantification e.g.:\n*)\nlet filtered = \n    ratios \n    |\u003E discardPeptideIonInFile \u0022IYSFNEGNYGLWDDSVK\u0022 3 \u0022WCGr2_UF_1\u0022 \n    |\u003E discardPeptideIon \u0022IYSFNEGNYGLWDDSVK\u0022 2\n\n// Plotting the updated frame again, we see that the exemplary filtering worked just fine.\nplotPeptidesOf filtered \u0022FBP2\u0022 2\n(***hide***)\nplotPeptidesOf filtered \u0022FBP2\u0022 2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\nOf course it is possible to apply very strict additional filters onto the previously filtered frame:\n*)\nlet ratiosFiltered = \n    filtered\n    |\u003E Frame.filterCols (fun k s -\u003E get15N_CBC_Amount k \u003E 0.1 )\n\n(**\nSince we want to save our result and use it for the next notebook, where we will have a look on the isotopic labeling efficiency and finally calculate absolute protein amounts, we \nneed to save the filtered frame. Additionally we want to keep information which was dropped along the way: isotopic patterns. In order to do so, we perform a join operation, which keeps only those rows \npresent in both files:\n\n*)\n//  Are there redundant columns in the result frame? Why?\nlet frameToSave = \n    Frame.join JoinKind.Inner finalRaw ratiosFiltered \n    |\u003E Frame.indexRowsOrdinally\n\n(**\nThis frame can then be saved locally using the following pattern:    \n*)    \n\nframeToSave.SaveCsv(@\u0022C:\\YourPath\\testOut.txt\u0022,separator=\u0027\\t\u0027,includeRowKeys=false)"},{"uri":"/BIO-BTE-06-L-7/NB06a_Targeted_quantification_of_photosynthetic_proteins_WC.html","title":"NB06a Targeted quantification of photosynthetic proteins (Whole Cell)\n","content":"(**\n# NB06a Targeted quantification of photosynthetic proteins (Whole Cell)\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB06a_Targeted_quantification_of_photosynthetic_proteins_WC.ipynb)\n\n1. General steps for targeted quantification\n2. Peptide Ratio Visualization\n3. Sample stability\n\n*)\n\n(**\n## General steps for targeted quantification\n\n\n1. Read the output file of the QconQuantifier containing the raw peptide ion quantification.\n2. Performing a first data cleaning step\n3. Calculating the 14N/15N ratio per peptide ion per sample\n4. Aggregating the peptide ions to their corresponding peptide\n5. Calculating the average of the peptide quantification value for protein quantification\n6. Visually inspect the peptide/protein quantification\n\nFor the explorative data analysis, we are using \n[Deedle](http://bluemountaincapital.github.io/Deedle/tutorial.html).\nDeedle is an easy to use library for data and time series manipulation and for scientific programming. \nIt supports working with structured data frames, ordered and unordered data, as well as time series. Deedle is designed to work well for exploratory programming using F#.\n*)\n\n\n#r \u0022nuget: FSharp.Stats, 0.4.0\u0022\n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta5\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: BIO-BTE-06-L-7_Aux, 0.0.5\u0022\n#r \u0022nuget: Deedle, 2.3.0\u0022\n#r \u0022nuget: ISADotNet, 0.2.3\u0022\n#r \u0022nuget: ISADotNet.XLSX, 0.2.3\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen ISADotNet\nopen ISADotNet.API\nopen Deedle\nopen BioFSharp\nopen FSharpAux\nopen FSharp.Stats\nopen Plotly.NET\nopen FSharp.Stats.Fitting.LinearRegression.OrdinaryLeastSquares.Linear\nopen System.IO\nopen BIO_BTE_06_L_7_Aux.FS3_Aux\n\n(**\nAt the start we have the output file of the QconQuantifier. We want to read the file, bind it to \n\u0060qConcatRawData\u0060 and group the rows by peptide sequence, modifcation (14N or 15N) and the charge state of the ion.\n*)\n\n// Code block 1\n\nlet directory = __SOURCE_DIRECTORY__\nlet path = Path.Combine[|directory;\u0022downloads/Sample.tab\u0022|]\ndownloadFile path \u0022Sample.tab\u0022 \u0022bio-bte-06-l-7\u0022\n\nlet qConcatRawData =\n    Frame.ReadCsv(path,separators=\u0022\\t\u0022)\n    // StringSequence is the peptide sequence\n    |\u003E Frame.indexRowsUsing (fun os -\u003E \n            os.GetAs\u003Cint\u003E(\u0022ModSequenceID\u0022),\n            os.GetAs\u003Cint\u003E(\u0022PepSequenceID\u0022),\n            os.GetAs\u003Cstring\u003E(\u0022StringSequence\u0022),\n            os.GetAs\u003Cstring\u003E(\u0022Proteingroup\u0022), \n            os.GetAs\u003Cint\u003E(\u0022Charge\u0022)\n        )\n        \nqConcatRawData.Print()\n\n(***include-fsi-merged-output***)\n\n(**\nFrom literature we know that there are peptides with a very bad flyability \n(Hammel et al.). Additionally, there are extreme values only due to technical artifacts. Both should be avoided in further analysis.\nWe also only want to keep the peptides that also appear in a QProtein:\n*)\n\n// Code block 2\n\nlet qConcatData =\n    qConcatRawData\n    |\u003E Frame.filterRows ( fun (modID, pepID, sequence, protGroup, charge) _ -\u003E \n        sequence \u003C\u003E \u0022EVTLGFVDLMR\u0022 \u0026\u0026 sequence \u003C\u003E \u0022AFPDAYVR\u0022 \u0026\u0026 (protGroup |\u003E String.contains \u0022Qprot_\u0022)\n        )\n    |\u003E Frame.mapValues (fun x -\u003E  if x \u003C 2000000. \u0026\u0026 x \u003E 0. then x else nan)\n\nqConcatData.Print()\n\n(**\nReading the sample description file provides us with a list of all measured files and additional information about the experiment (mixing ratio, strain, etc.) \n*)\n\n// Code block 3\n\n//FileName Experiment Content ProteinAmount[ug] Replicate\n\nlet path2 = Path.Combine[|directory;\u0022downloads/alle_Gruppen_V3_SWATE.xlsx\u0022|]\ndownloadFile path2 \u0022alle_Gruppen_V3_SWATE.xlsx\u0022 \u0022bio-bte-06-l-7\u0022\n\nlet _,_,_,myAssayFile = XLSX.AssayFile.AssayFile.fromFile path2\n\nlet inOutMap = BIO_BTE_06_L_7_Aux.ISA_Aux.createInOutMap myAssayFile\n\nlet fileNames =\n    myAssayFile.ProcessSequence.Value\n    |\u003E ProcessSequence.filterByProtocolName \u0022Measurement\u0022\n    |\u003E List.collect (fun p -\u003E \n        p.Outputs.Value\n        |\u003E List.map (fun po -\u003E\n            ProcessOutput.getName po\n        )\n    )\n    |\u003E List.choose id\n    |\u003E List.filter (fun x -\u003E x |\u003E String.contains \u0022WC\u0022)\n\nlet characteristicsOfInterest = \n    [\n        \u0022Cultivation -Sample preparation\u0022,\u0022gene expression\u0022\n        \u0022Extraction\u0022,\u0022gram #2\u0022\n        \u0022Extraction\u0022,\u0022gram\u0022\n        \u0022Cultivation -Sample preparation\u0022,\u0022concentration #3\u0022\n        \u0022Cultivation -Sample preparation\u0022,\u0022concentration #2\u0022\n        \u0022Cultivation -Sample preparation\u0022,\u0022concentration #5\u0022\n    ]\n\nlet parametersOfInterest = \n    [\n        \u0022Cultivation -Sample preparation\u0022,\u0022concentration #4\u0022\n        \u0022Cultivation -Sample preparation\u0022,\u0022concentration\u0022\n    ]\n\nlet sampleDesc =\n    let characteristics =\n        characteristicsOfInterest\n        |\u003E List.map (fun (prot,char) -\u003E\n            prot\u002B\u0022: \u0022\u002Bchar,\n            fileNames\n            |\u003E List.map (fun fn -\u003E\n                fn,       \n                BIO_BTE_06_L_7_Aux.ISA_Aux.tryGetCharacteristic inOutMap prot char fn myAssayFile    \n                |\u003E Option.defaultValue \u0022\u0022\n            )\n            |\u003E series\n        )\n        |\u003E frame\n    let param =\n        parametersOfInterest\n        |\u003E List.map (fun (prot,char) -\u003E\n            prot\u002B\u0022: \u0022\u002Bchar,\n            fileNames\n            |\u003E List.map (fun fn -\u003E\n                fn,       \n                BIO_BTE_06_L_7_Aux.ISA_Aux.tryGetParameter inOutMap prot char fn myAssayFile    \n                |\u003E Option.defaultValue \u0022\u0022\n            )\n            |\u003E series\n        )\n        |\u003E frame\n    Frame.mergeAll [characteristics; param]\n    |\u003E Frame.mapRowKeys (fun r -\u003E r |\u003E String.replace \u0022.wiff\u0022 \u0022\u0022)\n    \nsampleDesc.Print()\n\n(***include-fsi-merged-output***)\n\n(**\nFrom our in silico protein digest during the design of the qConCat protein, \nwe know the peptide(s) \u0026rarr; protein relationship. We read this information from the \u0022PeptideProtMap.txt\u0022 file.\n*)\n\n// Code block 5\n\nlet path3 = Path.Combine[|directory;\u0022downloads/PeptideProtMap.txt\u0022|]\ndownloadFile path3 \u0022PeptideProtMap.txt\u0022 \u0022bio-bte-06-l-7\u0022\n\nlet peptideProtMapping =\n    Frame.ReadCsv(path3,hasHeaders=true,separators=\u0022\\t\u0022)\n    |\u003E Frame.indexRowsString \u0022Peptide\u0022\n    \npeptideProtMapping.Print()\n\n(***include-fsi-merged-output***)\n\n(**\nNext, we will aggregate the peptide value of choice (e.g. Ratio, Quant light, Quant heavy) to obtain one value per peptide sequence despite the ion charge. For convenience, we join the protein names.\n*)\n\n// Code block 6\n\ntype QuantificationValue =\n    | Ratio\n    | N14Quant\n    | N15Quant\n\nlet quantificationValueToString (quantVal: QuantificationValue) =\n    match quantVal with\n    | Ratio    -\u003E \u0022Ratio\u0022\n    | N14Quant -\u003E \u0022MeasuredApex_Light\u0022\n    | N15Quant -\u003E \u0022MeasuredApex_Heavy\u0022\n\n\nlet aggregatePepValue frame (quantificationValue: QuantificationValue) = \n    frame\n    |\u003E Frame.applyLevel (fun (modID, pepID, sequence, protGroup, charge) -\u003E sequence) Stats.mean\n    |\u003E Frame.filterCols (fun ck os -\u003E ck |\u003E String.contains (quantificationValueToString quantificationValue))\n    |\u003E Frame.mapColKeys (fun ck -\u003E ck.Replace(\u0022.\u0022 \u002B (quantificationValueToString quantificationValue), \u0022\u0022))\n    |\u003E Frame.join JoinKind.Inner peptideProtMapping \n    |\u003E Frame.groupRowsByString \u0022Protein\u0022\n    |\u003E Frame.getNumericCols\n    |\u003E Frame.ofColumns\n    \n(aggregatePepValue qConcatData QuantificationValue.Ratio).Print()\n\n(***include-fsi-merged-output***)\n\n(**\nNow, we join the sample description with the data.\n*)\n\n// Code block 7\n\nlet peptideValuesWithDesc frame (quantificationValue: QuantificationValue) = \n    aggregatePepValue frame quantificationValue\n    |\u003E Frame.nest\n    |\u003E Series.map (fun k v -\u003E \n        v\n        |\u003E Frame.transpose\n        |\u003E Frame.join JoinKind.Right sampleDesc\n        |\u003E Frame.indexRowsUsing (fun os -\u003E \n                os.GetAs\u003Cstring\u003E(\u0022Strain\u0022),\n                os.GetAs\u003Cfloat\u003E(\u0022Dilution\u0022)\n            )\n        |\u003E Frame.filterCols (fun ck cs -\u003E v.RowKeys |\u003E Seq.contains ck)\n        |\u003E Frame.transpose\n        )\n    |\u003E Frame.unnest\n    \n(peptideValuesWithDesc qConcatData QuantificationValue.Ratio).Print()\n\n(***include-fsi-merged-output***)\n\n(**\nBy calculating the mean value per protein, we have two final tables with peptide and protein values:\n*)\n\n// Code block 8\n\nlet proteinValuesWithDesc frame (quantificationValue: QuantificationValue) =\n    //peptideRatiosWithDesc\n    peptideValuesWithDesc frame quantificationValue\n    |\u003E Frame.applyLevel fst Stats.mean\n    \n(proteinValuesWithDesc qConcatData QuantificationValue.Ratio).Print()\n\n(***include-fsi-merged-output***)\n\n(**\nHere are functions and parameters which are used for the styling of the graphs.\n*)\n\n// Code block 9\n\nlet xAxis showGrid title titleSize tickSize = Axis.LinearAxis.init(Title=title,Showgrid=showGrid,Showline=true,Mirror=StyleParam.Mirror.All,Zeroline=false,Tickmode=StyleParam.TickMode.Auto,Ticks= StyleParam.TickOptions.Inside, Tickfont=Font.init(StyleParam.FontFamily.Arial,Size=tickSize),Titlefont=Font.init(StyleParam.FontFamily.Arial,Size=titleSize))\nlet yAxis showGrid title titleSize tickSize = Axis.LinearAxis.init(Title=title,Showgrid=showGrid,Showline=true,Mirror=StyleParam.Mirror.All,Tickmode=StyleParam.TickMode.Auto,Ticks= StyleParam.TickOptions.Inside,Tickfont=Font.init(StyleParam.FontFamily.Arial,Size=tickSize),Titlefont=Font.init(StyleParam.FontFamily.Arial,Size=titleSize))\n\nlet config = Config.init(ToImageButtonOptions = ToImageButtonOptions.init(Format = StyleParam.ImageFormat.SVG, Filename = \u0022praktikumsplot.svg\u0022), EditableAnnotations = [AnnotationEditOptions.LegendPosition])\n\n(**\n## Peptide Ratio Visualization\n\n\u0060createChartForPeptideComparison\u0060 creates a chart for the given protein comparing the ratios for each given strain. \nIt generates a chart for each strain showing the individual peptide ratios and their mean (protein ratio). It also compares the protein ratios for each strain.\n*)\n\n// Code block 10\nlet peptideRatiosWithDesc = peptideValuesWithDesc qConcatData QuantificationValue.Ratio\nlet proteinRatiosWithDesc = proteinValuesWithDesc qConcatData QuantificationValue.Ratio\n\n// create charts to compare rel quant per dilution in strains\nlet createChartForPeptideComparison (protString:string) (strainStrings:string []) =\n    \n    let protFrame =\n        peptideRatiosWithDesc.Nest()\n        |\u003E fun x -\u003E x.Get(protString)\n\n    let peptideStrings =\n        protFrame.RowKeys\n        |\u003E Array.ofSeq\n\n    let peptideRows : Series\u003Cstring,Series\u003C(string * float),float\u003E\u003E =\n        protFrame\n        |\u003E Frame.getRows\n\n    let protMeanFrame : Series\u003C(string * float),float\u003E =\n        proteinRatiosWithDesc.GetRow protString\n\n    let xyMean =\n        strainStrings\n        |\u003E Array.map (fun strain -\u003E\n            strain,\n            protMeanFrame\n            |\u003E Series.filter (fun k t -\u003E fst k = strain)\n            |\u003E fun x -\u003E x.Observations\n            |\u003E Seq.map (fun x -\u003E 1./snd x.Key, x.Value)\n            |\u003E Array.ofSeq\n        )\n\n    let xyMeanChart =\n        xyMean\n        |\u003E Array.map (fun (strain,xyMean) -\u003E\n            Chart.Scatter(xyMean,mode=StyleParam.Mode.Lines_Markers, MarkerSymbol = StyleParam.Symbol.Circle, Opacity=0.8)\n            |\u003E Chart.withTraceName (sprintf \u0022%s - %s\u0022 protString strain )\n        )\n        |\u003E Chart.Combine\n        |\u003E Chart.withX_Axis (xAxis false \u0022Means: \u003Csup\u003E14\u003C/sup\u003EN Sample/\u003Csup\u003E15\u003C/sup\u003EN QProtein ratio\u0022 20 16)\n        |\u003E Chart.withY_Axis (yAxis false \u0022\u003Csup\u003E14\u003C/sup\u003EN/\u003Csup\u003E15\u003C/sup\u003EN Quantification ratio\u0022 20 16)\n\n    strainStrings\n    |\u003E Array.map (fun strain -\u003E\n        let peptideCharts =\n            peptideStrings\n            |\u003E Array.map (fun peptide -\u003E\n                let strainValueSeries = \n                    peptideRows.[peptide] \n                    |\u003E Series.filter (fun k t -\u003E fst k = strain)\n                let xy =\n                    strainValueSeries.Observations\n                    |\u003E Seq.map (fun x -\u003E 1./snd x.Key, x.Value)\n                    |\u003E Array.ofSeq\n                Chart.Scatter(xy,mode=StyleParam.Mode.Markers, MarkerSymbol = StyleParam.Symbol.Cross)\n                |\u003E Chart.withTraceName (sprintf \u0022%s -  %s - %s\u0022 strain protString peptide)\n            )\n        let relMeanChart = \n            let xyMeanVals = Array.find (fun (x,y) -\u003E x = strain) xyMean |\u003E snd\n            Chart.Scatter(xyMeanVals,mode=StyleParam.Mode.Lines_Markers, MarkerSymbol = StyleParam.Symbol.Circle, Color=\u0022#366F8E\u0022, Opacity=0.8)\n            |\u003E Chart.withTraceName (sprintf \u0022Mean %s - %s\u0022 protString strain)\n        Array.append peptideCharts [|relMeanChart|]\n        |\u003E Chart.Combine\n        |\u003E Chart.withX_Axis (xAxis false (strain \u002B \u0022: \u003Csup\u003E14\u003C/sup\u003EN Sample/\u003Csup\u003E15\u003C/sup\u003EN QProtein ratio\u0022) 20 16)\n        |\u003E Chart.withY_Axis (yAxis false \u0022\u003Csup\u003E14\u003C/sup\u003EN/\u003Csup\u003E15\u003C/sup\u003EN Quantification ratio\u0022 20 16)\n    )\n    |\u003E Array.append [|xyMeanChart|]\n    |\u003E Chart.Stack(2,Space=0.2)\n    |\u003E Chart.withSize (1200.,900.)\n    |\u003E Chart.withTitle (sprintf \u0022Relative Quantification of %s\u0022 protString)\n    |\u003E Chart.withConfig config\n\n(**\n\u0060rbclChart\u0060 executes \u0060createChartForPeptideComparison\u0060 for rbcL and the strains 4A, 1690 and 1883. \nWith \u0060allCharts\u0060 you can generate charts for all proteins and strains ( ***Warning! This displays a lot of charts*** ).\n*)\n\n// Code block 11\n\nlet rbclChart = createChartForPeptideComparison \u0022rbcL\u0022 [|\u00224A\u0022;\u00221690\u0022;\u00221883\u0022|]\n\nrbclChart\n\n(***hide***)\nrbclChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n\n//let allCharts =\n//    let strains = \n//        peptideRatiosWithDesc.ColumnKeys\n//        |\u003E Seq.map fst\n//        |\u003E Seq.distinct\n//        |\u003E Array.ofSeq\n//        \n//    peptideRatiosWithDesc.RowKeys\n//    |\u003E Seq.map (fun (prot,pep) -\u003E\n//        createChartForPeptideComparison prot strains\n//    )\n//allCharts\n\n(**\n## Sample stability\n\nNext, we do a quality assessment for the whole-cell sample preparation. \nFor that we will do a linear regression of the RuBisCO subunits relative quantification (14N/15N) protein ratio in whole-cell samples.\n\nNext we need two peptides (in this case rbcl and rbcs) for the assessment. You can exchange them for other proteins if you want to.\n*)\n\n(**\nHere, we fit a linear function to our mean peptide ratios and dilution series for the first protein. The  x-values are our different dilutions and the y-values our ratios. We calculate the [goodness\n of the fit](https://en.wikipedia.org/wiki/Goodness_of_fit) (discrepancy between predicted and observed values) for each fit and and also the [pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) (measure of the linear correlation between our ratios and dilution) for our values.\n*)\n\n// Code block 12\n\nlet calculateFit protName strainName (meanValueArray:(float*float) [])  =\n    let dilutionsSorted,strainVals =\n        meanValueArray\n        |\u003E Array.unzip\n    // RBCL Regression of relative quantification values\n    let RBCLcoeff = Univariable.coefficient (vector dilutionsSorted) (vector strainVals)\n    let RBCLfitFunc = Univariable.fit RBCLcoeff\n    let RBCLfitVals = dilutionsSorted |\u003E Array.map RBCLfitFunc\n    let RBCLdetermination = FSharp.Stats.Fitting.GoodnessOfFit.calculateDeterminationFromValue strainVals RBCLfitVals\n    let RBCLpearson = FSharp.Stats.Correlation.Seq.pearson strainVals dilutionsSorted\n    printfn \u0022%s - Pearson WholeCell %s: %f\u0022 strainName protName RBCLpearson\n    RBCLcoeff, RBCLfitVals, RBCLdetermination\n\nlet meanValuesFor protName strainName=\n    let meanSeries : Series\u003C(string * float),float\u003E = proteinRatiosWithDesc.GetRow protName\n    meanSeries\n    |\u003E Series.filter (fun k t -\u003E fst k = strainName)\n    |\u003E fun x -\u003E x.Observations\n    |\u003E Seq.map (fun x -\u003E 1./snd x.Key, x.Value)\n    |\u003E Array.ofSeq\n\nmeanValuesFor \u0022rbcL\u0022 \u00224A\u0022\n//|\u003E calculateFit \u0022rbcL\u0022 \u00224A\u0022\n\n(**\n\u0060chartRatios\u0060 generates charts for each given strain and our chosen proteins. \nEach chart contains a comparison of the two proteins, showing their mean data points, the linear fit and the goodness of the fit.\n*)\n\n// Code block 13\n\nlet chartRatios prot1 prot2 strain =\n    let prot1Vals = meanValuesFor prot1 strain\n    let prot2Vals = meanValuesFor prot2 strain\n\n    let (prot1Coeff:Vector\u003Cfloat\u003E),prot1FitVals,prot1Determination =\n        calculateFit prot1 strain prot1Vals\n\n    let (prot2Coeff:Vector\u003Cfloat\u003E),prot2FitVals,prot2Determination =\n        calculateFit prot2 strain prot2Vals\n\n    let dilutionsSorted,_ =\n        prot1Vals // or prot2Vals, does not matter, as we only want x-axis\n        |\u003E Array.unzip\n    [\n        Chart.Point (prot1Vals,Name = sprintf \u0022%s Quantified Ratios\u0022 prot1)\n        |\u003E Chart.withMarkerStyle(Size=10,Symbol = StyleParam.Symbol.Cross)\n        Chart.Line(Array.zip dilutionsSorted prot1FitVals,Name = (sprintf \u0022%s linear regression: %.2f x \u002B (%2f) ; R = %.4f\u0022 prot1 prot1Coeff.[1] prot1Coeff.[0] prot1Determination))\n        |\u003E Chart.withLineStyle(Color=\u0022lightblue\u0022,Dash=StyleParam.DrawingStyle.DashDot)\n\n        Chart.Point (prot2Vals,Name = sprintf \u0022%s Quantified Ratios\u0022 prot2,MarkerSymbol = StyleParam.Symbol.Cross)\n        |\u003E Chart.withMarkerStyle(Size=10,Symbol = StyleParam.Symbol.Cross)\n        Chart.Line(Array.zip dilutionsSorted prot2FitVals,Name = (sprintf \u0022%s linear regression: %.2f x \u002B (%2f) ; R = %.4f\u0022 prot2 prot2Coeff.[1] prot2Coeff.[0] prot2Determination))\n        |\u003E Chart.withLineStyle(Color=\u0022LightGreen\u0022,Dash=StyleParam.DrawingStyle.DashDot)\n    ]\n    |\u003E Chart.Combine\n    |\u003E Chart.withTitle (sprintf \u0022%s - Whole cell extracts: Stability of %s/%s ratios between samples\u0022 strain prot1 prot2)\n    |\u003E Chart.withX_Axis (yAxis false \u0022\u003Csup\u003E14\u003C/sup\u003EN Sample/\u003Csup\u003E15\u003C/sup\u003EN QProtein ratio\u0022 20 16)\n    |\u003E Chart.withY_Axis (xAxis false \u0022relative quantification\u0022 20 16 )\n    |\u003E Chart.withConfig config\n    |\u003E Chart.withSize (1200.,500.)\n\n(**\nHere we display the chart of rbcl and rbcs for the strain 4A.\n*)\n\n// Code block 14\n\nchartRatios \u0022rbcL\u0022 \u0022RCA1\u0022 \u0022Test\u0022\n\n(***hide***)\nchartRatios \u0022rbcL\u0022 \u0022RCA1\u0022 \u0022Test\u0022 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Abundance of 14N and 15N samples\n\nHere we will take a look at the 14N and 15N quantifications without calculating their ratios to see wether they are stable along the dilutions.\nWe will do this once on the peptide and once on the protein level.\n*)\n\n\nlet chartDilutionBoxplot (frame : Frame\u003C\u0027T,string*float\u003E) (strains: string[]) (labeling: int) (proteins: bool) =\n    let protOrPep =\n        if proteins then \u0022protein\u0022\n        else \u0022peptide\u0022\n    frame.ColumnKeys\n    |\u003E Seq.toArray\n    |\u003E Array.groupBy fst\n    |\u003E Array.filter (fun (strain,_) -\u003E strains |\u003E Array.contains strain)\n    |\u003E Array.map (fun (strain,sd) -\u003E \n        sd\n        |\u003E Array.sortBy snd\n        |\u003E Array.map (fun (str,dil) -\u003E         \n            frame.GetColumn\u003Cfloat\u003E((str,dil))\n            |\u003E Series.values\n            |\u003E fun values -\u003E Chart.BoxPlot(y = values, Name = string dil)\n        )\n        |\u003E Chart.Combine\n        |\u003E Chart.withX_Axis (yAxis false \u0022Dilution Series\u0022 20 16)\n        |\u003E Chart.withY_Axis (xAxis false \u0022Intensity\u0022 20 16 )\n        |\u003E Chart.withTitle (sprintf \u0022%s - Whole cell extracts: \u003Csup\u003E%i\u003C/sup\u003EN %s intensities over the dilution series\u0022 strain labeling protOrPep)\n        |\u003E Chart.withConfig config\n        |\u003E Chart.withSize (1200.,700.)\n    )\n\n\nlet peptideN14QuantsWithDesc = peptideValuesWithDesc qConcatData QuantificationValue.N14Quant\nlet proteinN14QuantsWithDesc = proteinValuesWithDesc qConcatData QuantificationValue.N14Quant\n\nchartDilutionBoxplot peptideN14QuantsWithDesc [|\u0022Test\u0022|] 14 false\n\n(***hide***)\nchartDilutionBoxplot peptideN14QuantsWithDesc [|\u0022Test\u0022|] 14 false |\u003E Array.map GenericChart.toChartHTML\n(***include-it-raw***)\n\nchartDilutionBoxplot proteinN14QuantsWithDesc [|\u0022Test\u0022|] 14 true\n\n(***hide***)\nchartDilutionBoxplot proteinN14QuantsWithDesc [|\u0022Test\u0022|] 14 true |\u003E Array.map GenericChart.toChartHTML\n(***include-it-raw***)\n\nlet peptideN15QuantsWithDesc = peptideValuesWithDesc qConcatData QuantificationValue.N15Quant\nlet proteinN15QuantsWithDesc = proteinValuesWithDesc qConcatData QuantificationValue.N15Quant\n\nchartDilutionBoxplot peptideN15QuantsWithDesc [|\u0022Test\u0022|] 15 false\n\n(***hide***)\nchartDilutionBoxplot peptideN15QuantsWithDesc [|\u0022Test\u0022|] 15 false |\u003E Array.map GenericChart.toChartHTML\n(***include-it-raw***)\n\nchartDilutionBoxplot proteinN15QuantsWithDesc [|\u0022Test\u0022|] 15 true\n\n(***hide***)\nchartDilutionBoxplot proteinN15QuantsWithDesc [|\u0022Test\u0022|] 15 true |\u003E Array.map GenericChart.toChartHTML\n(***include-it-raw***)"},{"uri":"/BIO-BTE-06-L-7/NB02b_Digestion_and_mass_calculation.html","title":"NB02b Digestion and mass calculation\n","content":"(** \n# NB02b Digestion and mass calculation\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB02b_Digestion_and_mass_calculation.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB02a_NB02b_NB02c/NB02b_Digestion_and_mass_calculation.ipynb)\n\n1. Digestion and mass calculation\n    2. Accessing the protein sequences of *Chlamydomonas reinhardtii*\n    3. Amino acid distribution for *C. reinhardtii*\n4. Calculating the molecular weight for peptides\n    5. *In silico* digestion of FASTA proteins with trypsin\n    6. Calculating peptide masses\n    7. Calculating peptide masses for charge 2\n6. References\n7. Questions\n\n*)\n\n(** \n## Digestion and mass calculation\n\nThe most widely applied method for protein digestion involves the use of enzymes. Many proteases are available for this purpose, \neach having their own characteristics in terms of specificity, efficiency and optimum digestion conditions. Trypsin is most widely \napplied in bottom-up proteomics and and has a very high degree of specificity, cleaving the peptide bonds C-terminal to the basic residues \nLys and Arg, except when followed by Pro (Burkhart et al. 2012). In general, Lys and Arg are relatively abundant amino acids and are \nusually well distributed throughout a protein (Switzar et al. 2013). This leads to tryptic peptides with an average length of \u223C14 amino \nacids that carry at least two positive charges, which is ideally suited for CID-MS analysis (Burkhart et al. 2012).\n\nUsing *in silico* analysis, we want to confirm that the general properties of trypsin digestion also apply for the \nproteome of *Chlamydomonas reinhardtii* . First, we load the proteome of *Chlamydomonas* in standard fastA format. \nAmino acid composition of the proteome is simply counting each amino acid occurrence and can be visualized by a histogram:\n*)\n\n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta5\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: BIO-BTE-06-L-7_Aux, 0.0.1\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen Plotly.NET\nopen BioFSharp\nopen BIO_BTE_06_L_7_Aux.FS3_Aux\nopen System.IO\n\n(**\n## Accessing the protein sequences of *Chlamydomonas reinhardtii*\n\nFASTA is a standardized text format, containing gene or protein sequence information. Such FASTAs can be donwloaded \nfrom [UniProt](https://www.uniprot.org/proteomes/UP000006906) for example.\n\nTo gain informations about the amino acid composition of *C. reinhardtii*, we need information about the proteome \nof *Chlamydomonas*, which is saved in the .fasta file we are accessing below.\n*)\n\n// __SOURCE_DIRECTORY__ returns the directory in which the current notebook is located\nlet directory = __SOURCE_DIRECTORY__\nlet path = Path.Combine[|directory;\u0022downloads/Chlamy_JGI5_5(Cp_Mp).fasta\u0022|]\ndownloadFile path \u0022Chlamy_JGI5_5(Cp_Mp).fasta\u0022 \u0022bio-bte-06-l-7\u0022\n// with /../ we navigate a directory \npath\n\n(*** include-it ***)\n\n(**\nFunctions to read information from FASTA files exist in the [BioFSharp](https://csbiology.github.io/BioFSharp/) library.\n*)\n\nlet sequences = \n    path\n    |\u003E IO.FastA.fromFile BioArray.ofAminoAcidString\n    |\u003E Seq.toArray\n    \n// Display the first element in the array collection\nsequences |\u003E Array.head\n\n(*** include-it ***)\n\n(**\n\n## Amino acid distribution for *C. reinhardtii*\n\nTo count the amino acid composition, we take the sequence of every protein and count the occurences of each amino acid\n*)\n\nlet aminoAcidDistribution =\n    sequences\n    // only access Sequence from each array element.\n    |\u003E Array.collect (fun fastAItem -\u003E fastAItem.Sequence)\n    // count each occurence of all amino acids. \n    |\u003E Array.countBy id\n    \naminoAcidDistribution\n\nlet aaDistributionHis =\n    aminoAcidDistribution\n    |\u003E Array.map (fun (name,count) -\u003E string name, count)\n    // sort by number of occurences\n    |\u003E Array.sortBy fst\n    // create chart\n    |\u003E Chart.Column\n    // style chart\n    |\u003E Chart.withY_AxisStyle \u0022Count\u0022\n    |\u003E Chart.withTitle \u0022Amino Acid composition of the \u003Ci\u003EChlamydomonas reinhardtii\u003C/i\u003E proteome\u0022\n\naaDistributionHis\n\n(***hide***)\naaDistributionHis |\u003E GenericChart.toChartHTML\n(***include-it-raw***)    \n\n(**\n\n## Calculating the molecular weight for peptides\n\nThe molecular weight M of a peptide may be estimated by calculating the equation for the molecular weight of a peptide: \n\n![](https://latex.codecogs.com/png.latex?M\u0026space;=\u0026space;M_{N}\u0026plus;M_{C}\\sum_{i=0}^{n}N_{i}M_{i})\n\nwhere N(i) are the number, and M(i) the average residue molecular weights, of the amino acids. M(N) \u002B M(C) \nare added to the total in order to account for the termini: H at the N-terminus and OH at the C-terminus. (Remark: if the termini are modified, \nthese additions are replaced by those of the modifiers.)\n\nThe distribution of all molecular weights for the peptides resulting from the previous proteome digest can be calculated and visualized using a histogram chart:\n*)\n\n(**\n## *In silico* digestion of FASTA proteins with trypsin\n\nTo gain information about the peptide sequences of each protein, we have to compute the digested sequence, A digest function with \nvariable protease exists in BioFSharp.\n*)\n\nlet digestedProteins =\n    // sequences is the fasta data\n    sequences\n    |\u003E Array.mapi (fun i fastAItem -\u003E\n        // in silico digestion\n        Digestion.BioArray.digest Digestion.Table.Trypsin i fastAItem.Sequence\n        |\u003E Digestion.BioArray.concernMissCleavages 0 1\n    )\n    |\u003E Array.concat\n    \ndigestedProteins |\u003E Array.head\n\n(*** include-it ***)\n\n(**\n## Calculating peptide masses\n\nWe calculate the mass of each peptide by calculating the monoisotopic mass of each amino acid and adding the weight \nof an H(2)O to each peptide weight.\n*)\n\nlet chartDigestedProteins =\n    digestedProteins\n    |\u003E Array.map (fun peptide -\u003E\n        // calculate mass for each peptide\n        BioSeq.toMonoisotopicMassWith (BioItem.monoisoMass ModificationInfo.Table.H2O) peptide.PepSequence\n        )\n    |\u003E Array.filter (fun x -\u003E x\u003C3000.)\n    // visualize distribution of all peptide masses \u003C 5000 Da\n    |\u003E fun masses -\u003E Chart.Histogram(data=masses,nBinsx=100)\n    |\u003E Chart.withX_AxisStyle (title = \u0022Mass [Da]\u0022,MinMax=(0.,3000.))\n    |\u003E Chart.withY_AxisStyle \u0022Count\u0022\n\nchartDigestedProteins\n(***hide***)\nchartDigestedProteins |\u003E GenericChart.toChartHTML\n(***include-it-raw***) \n(**\n## Calculating peptide masses for charge 2\n\nHowever, in mass spectrometry we are only able to detect ions. Therefore, the measurements report the mass-to-charge ratio. \nThe abbreviation m/z (m = mass; z = charge) is used to denote the dimensionless quantity formed by dividing the molecular weight \nof an ion (M\u002BnH(\u002B)) by its charge number (n).\n\n![](https://latex.codecogs.com/png.latex?M_{z}=\\frac{(M\u0026plus;nH^{\u0026plus;})}{n})\n\nIn the following, we will convert the uncharged peptide masses to the m/z ratio with charge two by applaying the Mass.toMZ \nfunction from the BioFSharp library and displax its distribution again. Note that m/z ratio with a charge of two represents \nthe predominant charge species.\n*)\n\nlet digestedPeptideMasses =\n    digestedProteins\n    |\u003E Array.map (fun peptide -\u003E\n        BioSeq.toMonoisotopicMassWith (BioItem.monoisoMass ModificationInfo.Table.H2O) peptide.PepSequence\n    )\n\nlet chartDigestedPeptideMasses =\n    digestedPeptideMasses\n    |\u003E Array.map (fun ucMass -\u003E Mass.toMZ ucMass 2.)\n    |\u003E Array.filter (fun x -\u003E x\u003C3000.)\n    |\u003E fun masses -\u003E Chart.Histogram(data=masses,nBinsx=100)\n    |\u003E Chart.withX_AxisStyle (title = \u0022m/z\u0022,MinMax=(0.,3000.))\n    |\u003E Chart.withY_AxisStyle \u0022Count\u0022\n    \nchartDigestedPeptideMasses\n\n(***hide***)\nchartDigestedPeptideMasses |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Questions\n\n1. When trypsin is used for digestion in a MS experiment, it is often combined with another protease (e.g. Lys-C). Why can it be beneficial to combine trypsin?\n2. A peptide with a charge of 2 has a m/z of 414. What is the m/z of the same peptide with a charge of 3? Visualize the m/z of the peptides from the fastA with a charge of 3\nlike done above.\n3. Peptides can occur at different charge states during a MS run. Do the different charge states of an peptide usually possess similar intensities?\n*)\n\n\n(**\n## References\n\n23. Burkhart, J. M., Schumbrutzki, C., Wortelkamp, S., Sickmann, A. \u0026 Zahedi, R. P. Systematic and quantitative comparison of digest efficiency and specificity reveals the impact of trypsin quality on MS-based proteomics. Journal of proteomics 75, 1454\u20131462; 10.1016/j.jprot.2011.11.016 (2012).\n24. Switzar, L., Giera, M. \u0026 Niessen, W. M. A. Protein digestion: an overview of the available techniques and recent developments. J. Proteome Res. 12, 1067\u20131077; 10.1021/pr301201x (2013).\n*)\n"},{"uri":"/BIO-BTE-06-L-7/NB03c_Centroidisation.html","title":"NB03c Centroidisation\n","content":"(**\n# NB03c Centroidisation\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB03c_Centroidisation.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB03a_NB03b_NB03c/NB03c_Centroidisation.ipynb)\n\n1. Centroidisation\n2. Peak fitting and picking functions\n3. Application of the peak picking function\n4. Questions\n\n*)\n\n(**\n## Centroidisation\n\nIn reality, a peak is represented by a collection of signals from a peptide or fragment ion species that are measured by the \nspecific detector. Due to imperfections of the measurement, there is a scatter around the accurate mass. This distribution \nalong the m/z axis of signals from ion species is termed profile peak. The conversion of a peak profile into the corresponding m/z and \nintensity values reduces the complexity, its representation is termed centroiding. To extract the masses for identification in a simple \nand fast way, peak fitting approaches are used. Further, peak fitting algorithms are also needed to extract ion abundancies and therefore \nexplained under quantification in the following section.\n*)\n\n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta5\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: BioFSharp.Mz, 0.1.5-beta\u0022\n#r \u0022nuget: BIO-BTE-06-L-7_Aux, 0.0.1\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen Plotly.NET\nopen BioFSharp.Mz\nopen BIO_BTE_06_L_7_Aux.FS3_Aux\nopen System.IO\n\n(**\n## Peak fitting and picking functions\n\nWe declare a function which centroids the given m/z and intensity data. In the scope of the function the m/z and intensity data \nare padded for the wavelet (You will read more about wavelet functions later in *NB05a\\_Quantification.ipynb* ) \nand the centroided. For the centroidisation, we use a Ricker 2D wavelet.\n*)\n\n// Code-Block 1\n\nlet ms1PeakPicking (mzData:float []) (intensityData: float []) = \n    if mzData.Length \u003C 3 then \n        [||],[||]\n    else\n        let paddYValue = Array.min intensityData\n        // we need to define some padding and wavelet parameters\n        let paddingParams = \n            SignalDetection.Padding.createPaddingParameters paddYValue (Some 7) 0.05 150 95.\n        let waveletParameters = \n            SignalDetection.Wavelet.createWaveletParameters 10 paddYValue 0.1 90. 1. false false\n        \n        let paddedMz,paddedIntensity = \n            SignalDetection.Padding.paddDataBy paddingParams mzData intensityData\n        \n        BioFSharp.Mz.SignalDetection.Wavelet.toCentroidWithRicker2D waveletParameters paddedMz paddedIntensity \n\n\n(**\nWe load a sample MS1 from a mgf file.\n*)\n\n// Code-Block 2\nlet directory = __SOURCE_DIRECTORY__\nlet path = Path.Combine[|directory;\u0022downloads/ms1MGF.mgf\u0022|]\ndownloadFile path \u0022ms1MGF.mgf\u0022 \u0022bio-bte-06-l-7\u0022\n\nlet ms1 = \n    BioFSharp.IO.Mgf.readMgf (path)\n    |\u003E List.head\n\nms1\n\n(***include-it***)\n\n(**\n## Application of the peak picking function\n\nWe centroid the MS2 data using the function declared beforehand:\n*)\n\n// Code-Block 3\n\nlet centroidedMs1 = \n    ms1PeakPicking ms1.Mass ms1.Intensity\n\n(**\n*)\n\n// Code-Block 4\n\n//removes low intensity data points for charting\nlet filteredMs1Mass, filteredMs1Intensity =\n    Array.zip ms1.Mass ms1.Intensity\n    |\u003E Array.filter (fun (mass, intensity) -\u003E\n        intensity \u003E 400.\n    )\n    |\u003E Array.unzip\n\nlet filteredChart =\n    [\n        Chart.Point(filteredMs1Mass,filteredMs1Intensity)\n        |\u003E Chart.withTraceName \u0022Uncentroided MS1\u0022\n        Chart.Point(fst centroidedMs1,snd centroidedMs1)\n        |\u003E Chart.withTraceName \u0022Centroided MS1\u0022\n    ]\n    |\u003E Chart.Combine\n    |\u003E Chart.withY_AxisStyle \u0022Intensity\u0022\n    |\u003E Chart.withX_AxisStyle (title = \u0022m/z\u0022, MinMax = (400., 800.))\n    |\u003E Chart.withSize (900.,900.)\nfilteredChart\n(***hide***)\nfilteredChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Questions:\n\n1. The aim of centroidization is finding the m/z for each profile peak. How can this improve the performance and quality of the following steps?\n2. In the result plot, a single ms1 spectrum is shown. Naively describe the differences between the uncentroided and the centroided spectrums.\n3. Taking into consideration your answer for question 1, do your findings of question 2 meet your expectations? If yes, why? If no, why?\n\n*)"},{"uri":"/BIO-BTE-06-L-7/NB01b_Plant_Systems_Biology.html","title":"NB01b Plant Systems Biology\n","content":"(** \n# NB01b Plant Systems Biology\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB01b_Plant_Systems_Biology.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB01a_NB01b/NB01b_Plant_Systems_Biology.ipynb)\n\n1. Plant Systems Biology\n2. Modeling growth\n1. Insert growth data and display as chart\n2. Calculation of growth rate and doubling time for cell cultures\n3. Fitting biological growth curves\n    1. Theory\n    2. Model selection\n4. Calculate cell doubling time\n5. Questions\n6. References\n\n*)\n\n(** \n## Plant Systems Biology\n\nThe general paradigm of Systems Biology clearly applies to plants, as they represent complex biological systems. \nThe functioning of a plant as a biological system is the result of a combination of multiple intertwined and dynamic interactions between its components. \nIn addition, most plants are sessile systems that have to face fluctuating environmental conditions, including biotic and abiotic stresses (Ruffel et al. 2010).\nThe process of a biological system responding to changes in environmental conditions is termed acclimation. These molecular physiological responses represent a complex \ndynamic adjustment of the interplay between genes, proteins and metabolites that allows the organism to acclimate to the changing environment. \nThe ability to acclimate ensures the survival of all living organisms and is therefore fundamental for the understanding of biological systems. \nDetailed knowledge about how plants acclimate to a changing environment is crucial especially in times of global climate changes, \nas plants are of great importance for our quality of life as a key source of food, shelter, fiber, medicine, and fuel (Minorsky 2003).\n\nThe prominent model plant *Arabidopsis thaliana* is well suited for plant Systems Biology studies because sophisticated experimental tools and extensive data \ncollections are readily available (Van Norman et al. 2009). However, the importance of a model organism is not only coined by the availability of molecular \ntools to manipulate the organism, but also by its agricultural and economic impact like in the cases of tobacco, rice, maize or \nbarley (P\u00E3curar 2009). Also microalgae are of special economic interest due to their potential as biofuel producers (Cagnon et al. 2013). \nAdditionally, the use of organisms with lower biological complexity facilitates the feasibility of System Biology studies and is an important factor to consider \nfor the choice of a suitable model organism in Systems Biology.\n\nThe eukaryotic green alga *Chlamydomonas reinhardtii* is particularly well suited for plant Systems Biology approaches. \nThis unicellular freshwater and soil-dwelling alga has a single, cup-shaped chloroplast with a photosynthetic apparatus that is similar to \nthat of higher plants (Eberhard et al. 2008, Merchant et al. 2007). Hence, results gained on photosynthesis processes in *Chlamydomonas* \nare likely to be transferable to higher plants. The nuclear, mitochondrial, and chloroplast genomes have been sequenced and tools for manipulating them \nare available (Merchant et al. 2007). *Chlamydomonas* cells have a size of ~10 \u00B5m and grow under photo-, mixo-, and heterotrophic conditions \nwith a generation time of ~5-8 h (Harris, 2008). *Chlamydomonas* can be maintained under controlled conditions and environmental \nchanges can be applied homogeneously and rapidly to all cells in a liquid culture. In contrast to multicellular organisms there are no influences by \ntissue heterogeneity. Even the influence of different cell cycle stages may be ruled out by performing experiments with asynchronous cell cultures \n(Bruggeman and Westerhoff 2007, Harris 2001). Finally, gene families in *Chlamydomonas* have fewer members than those in higher plants thus facilitating the \ninterpretation of results involving many genes/proteins (Merchant et al. 2007).\n*)\n\n(** \n## Modeling growth\n\nIn order to solve real world tasks more convenient, F# provides a huge collection of additional programming libraries. \nAnything that extends beyond the basics must be written by a user. If the chunk of code is useful to multiple different users, \nit\u0027s often put into a library to make it easily reusable. A library is a collection of related pieces of code that have been compiled \nand stored together in a single file and can than be used an included. The most important libraries in F# for bioinformatics are:\n\n\n* [BioFSharp](https://csbiology.github.io/BioFSharp/): Open source bioinformatics and computational biology toolbox written in F#\n* [FSharp.Stats](https://github.com/fslaborg/FSharp.Stats): F# project for statistical computing\n* [Plotly.NET](https://github.com/plotly/Plotly.NET): .NET interface for plotly.js written in F# \uD83D\uDCC8\n\n\nThe first real world use case of F# in Systems Biology is to model growth for a defined cell number to see possible overexpression effects. \nBiologists often utilize growth experiments to analyze basic properties of a given organism or cellular model. For a solid comparison of data \nobtained from different experiments and to investigate the speci\uFB01c effect of a given experimental set up, modeling the growth is needed after recording the data. \n\nThis notebook introduces the most classical way to model growth of *Chlamydomonas reinhardtii* or any other growth data using F#.\n\nNow, let\u0027s get started by loading the required libraries first.\n*)\n\n#r \u0022nuget: FSharp.Stats, 0.4.0\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen System\nopen Plotly.NET\nopen FSharp.Stats\n\n(** \n## Insert growth data and display as chart\n\nA standard cell culture experiment with cell count measurements will result in data like the following.\nMultiple cell counts (\u0060y_Count\u0060), each related to a specific timepoint (\u0060x_Hours\u0060).\n*)\n// Code-Block 1\n\nlet exmp_x_Hours = [|0.; 19.5; 25.5; 43.; 48.5; 67.75|]\nlet exmp_y_Count = [|1659000.; 4169000.; 6585400.; 16608400.; 17257800.; 18041000.|]\n\n// Such data can easily be display with the following code block.\n// Chart.Point takes a sequence of x-axis-points and a series of y-axis-points as input\nlet example_Chart_1 = \n    Chart.Point(exmp_x_Hours,exmp_y_Count)\n    // some minor styling with title and axis-titles.\n    |\u003E Chart.withTitle \u0022Growth curve of Chlamydomonas reinhardtii cell cultures\u0022\n    |\u003E Chart.withY_AxisStyle (\u0022Number of cells\u0022)\n    |\u003E Chart.withX_AxisStyle (\u0022Time [hours]\u0022)\n\nexample_Chart_1\n(***hide***)\nexample_Chart_1 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n\n## Calculation of growth rate and doubling time for cell cultures\n\nThe standard growth of an in vitro cell culture is defined by three phases. The lag phase in which the cells still acclimate to the growth conditions, the exponential growth, \nalso called log phase, during which cell growth is exponential due to the iterative proliferation of cells into two daughter cells, and the stationary phase in which the growth rate and the \ndeath rate are equal. The stationary phase is typically initiated due to limitations in growth conditions, e.g. depletion of essential nutrients or accumulation of toxic/inhibitory \nexcretions/products. The doubling time (or generation time) defines a time interval in which the quantity of cells doubles.\n\n![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/growthCurve.png)\n\nGrowth data always should be visualized in log space. Therefore the count data must be log transformed. When a log2 transform is applied, \na doubling of the original counts is achieved, when the value increase 1 unit. \nKeeping that in mind, the slope of the growth function can be used to calculate the time it takes for the log transformed data to increase 1 unit.\n\nThe corresponding chart of the log transformed count data looks like this:\n\n*)\n// Code-Block 2\n\n// log transform the count data with a base of 2\nlet exmp_y_Count_Log = exmp_y_Count |\u003E Array.map log2\n\nlet example_Chart_2 = \n    Chart.Point(exmp_x_Hours,exmp_y_Count_Log)\n    |\u003E Chart.withTitle \u0022Growth curve of Chlamydomonas reinhardtii cell cultures\u0022\n    |\u003E Chart.withY_AxisStyle (\u0022Number of cells [log2]\u0022)\n    |\u003E Chart.withX_AxisStyle (\u0022Time [hours]\u0022)\n\nexample_Chart_2\n(***hide***)\nexample_Chart_2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)  \n\n(**\n\nAfter the log transform the exponential phase becomes linear. Since a y axis difference of 1 corresponds to a doubling of the cells the generation time can simply be estimated by determination of how many hours are required for the data to span one y axis unit.\nIn this case it seems, that the time required to get from y=22 to y=23 takes approximately 10 hours. \n\nAs you may noticed we just determined the cell doubling time per eye. \nThe formalization of this process is trivial. \n\n  - The y-value increment that is required for doubling can be calculated by log_x(2) where x defines the used base. So for log2 transformed data it is 1 (log2(2)).\n\n  - The generation time is calculated by dividing this y-value increment by the growth rate which is the steepest slope of the log transformed data (approximately 0.1 in the given data). The steepest slope in growth curves always occurs at the inflection point of the sigmoidal function shape.\n\nSo all we have to know is the performed log transform and the slope of the function at its steepest point and afterwards apply the following equation.\n\n\n*Equation 1: Calculation of the doubling time. Growth rate is the steepest slope of the log transformed count data.*\n\n![](https://latex.codecogs.com/png.latex?doubling\u0026space;Time\u0026space;=\u0026space;\\frac{log_x(2)}{growthRate})\n\nFor a log2 transform the numerator is 1.\n\n*)\n\n(** \n## Fitting biological growth curves\n\n\u003Cbr\u003E\n### Theory\n\nTo derive the slope required for the doubling time calculation, the measured growth data points have to be modelled. \nIn order to obtain a continuous function with known coefficients, a suitable model function is fitted onto the existing data. \nMany models exist, each one of them optimized for a specific task (Kaplan et al. 2018).\n\nLinear model function example: ![](https://latex.codecogs.com/png.latex?f(x)\u0026space;=\u0026space;mx\u0026space;\u0026plus;\u0026space;b)\n \nWhen a model function is fitted onto the data, there are endless possibilities to choose coefficients of the model function. \nIn the case above there are two coefficients to be identified: The slope m and the y-intercept b. But how can the best fitting coefficients be determined?\n\nTherefore a quality measure called ***Residual Sum of Squares (RSS)*** is used. It describes the discrepancy of the measured points \nand the corresponding estimation model. If the discrepancy is small, the RSS is small too.\n\nIn regression analysis the optimal set of coefficients (m and b) that [minimizes the RSS is searched](https://mathworld.wolfram.com/LeastSquaresFitting.html).\n\nIf there is no straightforward way to identify the RSS-minimizing coefficient set, then the problem is part of nonlinear regression. \nHere, initial coefficients are guessed and the RSS is calculated. Thereafter, the coefficients are modified in tiny steps. \nIf the RSS decreases, the direction of the coefficient change seems to be correct. \nBy [iteratively changing coefficients](https://books.google.de/books?id=rs51DwAAQBAJ\u0026pg=PA422\u0026lpg=PA422\u0026dq=rss\u002Bminimizing\u002Bsolver\u0026source=bl\u0026ots=qZ0Y4cYtM-\u0026sig=ACfU3U0rHGWCmTo_kv5wqYMmSo8ZKyj5Pg\u0026hl=de\u0026sa=X\u0026ved=2ahUKEwjKtdf-oaHoAhUUwsQBHX07DTwQ6AEwBHoECAkQAQ#v=onepage\u0026q=rss%20minimizing%20solver\u0026f=false)\n, the optimal coefficient set is determined when no further change leads to an decrease in RSS. \nAlgorithms, that perform such a \u0027gradient descent\u0027 methods to solve nonlinear regression tasks are called ***solver*** \n(e.g. Gauss-Newton algorithm or Levenberg\u2013Marquardt algorithm). [Introduction to RSS and optimization problems.](https://www.youtube.com/watch?v=sDv4f4s2SB8)\n\n### Model selection\n\nDepending on the given problem, different models can be fitted to the data. Several growth models exist, each is specialized for a particular problem. See [Types of growth curve](http://www.pisces-conservation.com/growthhelp/index.html) or [FSharp.Stats - Growth Curve](https://fslab.org/FSharp.Stats/GrowthCurve.html) for more information.\n\nThe selected model should match the theoretical (time) course of the studied signal, but under \nconsideration of Occams razor principle. It states, that a approriate model with a low number of coefficients should be preferred over a \nmodel with many coefficients, since the excessive use of coefficients leads to overfitting.\n\nA often used growth curve model is the four parameter [Gompertz model](https://en.wikipedia.org/wiki/Gompertz_function). \n\nThe function has the form: ![](https://latex.codecogs.com/png.latex?A\u002BCe^{-e^{-B(t-M)}}) [Gibson et al. 1988](https://www.sciencedirect.com/science/article/pii/0168160588900517?via%3Dihub). \n\nwhere:\n\n  - A = curve minimum\n\n  - B = relative growth rate (not to be confused with absolute)\n\n  - C = curve maximum - curve minimum (y range)\n\n  - M = x position of inflection point\n\n  - t = time point\n\nIn the following, we will go through the necessary steps to calculate the generation time with the help of a Gompertz model.\nWhile the curve minimum and maximum are easy to define by eye, to estimate the remaining coefficients is a nontrivial task.\n\nFSharp.Stats provides a function, that estimates the model coefficients from the data and a guess of the expected generation time. For Chlamydomonas the initial guess would be 8 hours.\n\n\n*)\n// Code-Block 3\n\n// open module in FSharp.Stats to perform nonlinear regression\nopen FSharp.Stats.Fitting.NonLinearRegression\n\n// The model we need already exists in FSharp.Stats and can be taken from the \u0022Table\u0022 module.\nlet modelGompertz = Table.GrowthModels.gompertz\n\n// The solver, that iteratively optimizes the coefficients requires an initial guess of the coefficients.\n// The following function was specifically designed to estimate gompertz model coefficients from the data\n// You have to provide the time data, the log transformed count data, the expected generation time, and the used log transform\nlet solverOptions = Table.GrowthModels.getSolverOptionsGompertz exmp_x_Hours exmp_y_Count_Log 8. log2\n\n// sequence of initial guess coefficients\nsolverOptions.InitialParamGuess\n\n(***hide***)\nsolverOptions.InitialParamGuess\n(***include-it-raw***)  \n\n(** \nThe initial coefficient estimations match the expectations. \n\n  - A = 20.7\n  - B = 0.099\n  - C = 3.4\n  - M = 19.5\n  \n*)\n// Code-Block 4\n\n// By solving the nonlinear fitting problem, the optimal model coefficients are determined. \n// The solver iteratively changes the coefficients until the model function fits the data best.\nlet gompertzParams =\n    LevenbergMarquardt.estimatedParams // The Levenberg Marquardt is used as solver\n        modelGompertz    // The gompertz model is used as growth model\n        solverOptions    // The initial guess of the coefficients\n        0.1              // Parameter required from the solver\n        10.              // Parameter required from the solver\n        exmp_x_Hours     // The time data\n        exmp_y_Count_Log // The transformed count data\n\ngompertzParams\n(***hide***)\ngompertzParams\n(***include-it-raw***)\n\n(**\nThe model coefficients were determined to be:\n\n- A = 20.66\n- B = 0.107\n- C = 3.52\n- M = 19.63\n\nThey are pretty close to the initial estimations that were determined in Code-Block 3 With the coefficients at hand, the model function can be filled with coefficients and can be used to create a fit to the data.\n\n*)\n// Code-Block 4\n\n// Create fitting function from optimal coefficients\nlet fittingFunction = modelGompertz.GetFunctionValue gompertzParams\n\n// Fit the optimized model function to all x values from 0 to 70 hours.\nlet fittedValuesGompertz =\n    [0. .. 0.1 .. 70.]\n    |\u003E Seq.map (fun x -\u003E x,fittingFunction x) \n    |\u003E Chart.Line\n    \n\n// combine the raw data and the fit into one chart\nlet fittedChartGompertz = \n    [\n        example_Chart_2      |\u003E Chart.withTraceName \u0022raw data\u0022\n        fittedValuesGompertz |\u003E Chart.withTraceName \u0022gompertz model\u0022\n    ]\n    |\u003E Chart.Combine\n\nfittedChartGompertz\n(***hide***)\nfittedChartGompertz |\u003E GenericChart.toChartHTML\n(***include-it-raw***)  \n\n(**\n    \n## Calculate cell doubling time\n\nTo calculate the doubling time it is necessary to determine the growth rate (gr) for *equation 1*.\nAs discussed above the growth rate is the maximal slope of the model function. It always occurs at the inflection point, which we know is at x=19.628. \nAfter calculating the first derivative of the model function, we would be able to calculate the growth rate as the slope at the inflection point.\nLuckily, there is a short cut when using the Gompertz model. It allows the determination of generation times from its parameters (see Gibson et al. 1988 for details).\n\n\n*)\n\nlet getGenTimeFromGompertz (parametervector:vector) (logTransform:float -\u003E float) =\n    logTransform 2. * Math.E / (parametervector.[1] * parametervector.[2])\n\nlet genTime = getGenTimeFromGompertz gompertzParams log2\n\nlet gt = sprintf \u0022The generation time is %.2f hours.\u0022 genTime\n\n(***hide***)\ngt\n(***include-it-raw***)\n\n\n(**\n\n\u003Cbr\u003E\n## Questions:\n\n1. Why is it useful to use a log2 transform rather than a ln, log10, or any other log transform?\nHint: Define your own exponentially growing cell counts with a generation time of 1 and transform them using different log transforms.\n\n2. Why is it not sufficient to fit the (raw or transformed) data using the possibilities Excel offers? \nHint: Which models are available and why are these not always appropriate?\n\n3. Calculate the generation time of the following data. Compare the time points of maximal slope of the raw data and the transformed data by eye. Without the log transform you are blind for the actual point of maximal growth.\n\n*)\nlet rawX_hours = [|0. .. 12.|]\nlet rawY_count = [|2.;2.2;2.9;5.;9.5;19.;38.;65.;85.;90.;91.;91.;91.;|]\n(**\n\n\n## References\n\n8. Ruffel, S., Krouk, G. \u0026 Coruzzi, G. M. A systems view of responses to nutritional cues in Arabidopsis: toward a paradigm shift for predictive network modeling. Plant physiology 152, 445\u2013452; 10.1104/pp.109.148502 (2010).\n9. Minorsky, P. V. Achieving the in Silico Plant. Systems Biology and the Future of Plant Biological Research. Plant physiology 132, 404\u2013409; 10.1104/pp.900076 (2003).\n10. Van Norman, Jaimie M \u0026 Benfey, P. N. Arabidopsis thaliana as a model organism in systems biology. Wiley interdisciplinary reviews. Systems biology and medicine 1, 372\u2013379; 10.1002/wsbm.25 (2009).\n11. P\u00E3curar, D. I. Model organisms - a journey from the dawn of biological research to the post-genomic era. Romanian Society of Biological Sciences, 4087\u20134094 (2009).\n12. Cagnon, C. et al. Development of a forward genetic screen to isolate oil mutants in the green microalga Chlamydomonas reinhardtii. Biotechnology for biofuels 6, 178; 10.1186/1754-6834-6-178 (2013).\n13. Eberhard, S., Finazzi, G. \u0026 Wollman, F.-A. The dynamics of photosynthesis. Annual review of genetics 42, 463\u2013515; 10.1146/annurev.genet.42.110807.091452 (2008).\n14. Merchant, S. S. et al. The Chlamydomonas genome reveals the evolution of key animal and plant functions. Science (New York, N.Y.) 318, 245\u2013250; 10.1126/science.1143609 (2007).\n15. Harris, E. H. The chlamydomonas sourcebook. 2nd ed. (Academic, London, 2008).\n16. Bruggeman, F. J. \u0026 Westerhoff, H. V. The nature of systems biology. Trends in microbiology 15, 45\u201350; 10.1016/j.tim.2006.11.003 (2007).\n17. Harris, E. H. CHLAMYDOMONAS AS A MODEL ORGANISM. Annual review of plant physiology and plant molecular biology 52, 363\u2013406; 10.1146/annurev.arplant.52.1.363 (2001).\n18. Kaplan, S. et al. Comparison of growth curves using non-linear regression function in Japanese squail. Journal of Applied Animal Research 46, 112-117; 10.1080/09712119.2016.1268965 (2018).\n19. Gibson, A., Bratchell, N., Roberts, T.A., Predicting microbial growth: growth responses of salmonellae in a laboratory medium as affected by pH, sodium chloride and storage temperature, International Journal of Food Microbiology, Volume 6, Issue 2,  https://doi.org/10.1016/0168-1605(88)90051-7 (1988).\n*)"},{"uri":"/BIO-BTE-06-L-7/NB02c_Isotopic_distribution.html","title":"NB02c Isotopic Distribution\n","content":"(**\n# NB02c Isotopic Distribution\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB02c_Isotopic_distribution.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB02a_NB02b_NB02c/NB02c_Isotopic_distribution.ipynb)\n\n1. Isotopic Distribution\n    1. Simulating Isotopic Clusters for peptides\n    2. Simulating Isotopic Clusters for peptides with stable isotope labeled variant\n2. References\n\n*)\n(**\n## Isotopic Distribution\n\nPeptide signals exhibit a characteristic shape in the mass spectrum that depend on their isotopic profile, which is defined by \nthe number of naturally occurring isotopes in the peptide. The occurrence probabilities of natural isotopes are reflected in the mass \nspectrum by the relative heights of the peak series belonging to the respective peptide. The frequency at which natural isotopes occur \nis known and can be used to compute the isotope distribution of a molecule. The isotopic distribution for a given peptide molecule \nC(v)H(w)N(x)O(y)S(z) is described by the following product of polynomials:\n\n![](https://latex.codecogs.com/png.latex?\\large\u0026space;\\newline(\u0026space;{}^{12}\\textrm{C}\u0026space;\u0026plus;\u0026space;{}^{13}\\textrm{C})^{v}\u0026space;\\times\u0026space;({}^{1}\\textrm{H}\u0026plus;{}^{2}\\textrm{H})^{w}\u0026space;\\times\u0026space;({}^{14}\\textrm{N}\u0026plus;{}^{15}\\textrm{N})^{x}\\times({}^{16}\\textrm{O}\u0026plus;{}^{17}\\textrm{O}\u0026space;\u0026plus;\u0026space;{}^{18}\\textrm{O})^{y}\\newline\\times({}^{32}\\textrm{S}\u0026plus;{}^{33}\\textrm{S}\u0026plus;{}^{34}\\textrm{S}\u0026plus;{}^{36}\\textrm{S})^{z})\n\nSymbolic expansion of the polynomials results in many product terms, which correspond to different isotopic variants of a molecule. \nEven for molecules of a medium size, the straightforward expansion of the polynomials leads to an explosion regarding the number of product terms. \nDue to this complexity, there was a need to develop algorithms for efficient computation. The different strategies comprise pruning the \npolynomials to discard terms with coefficients below a threshold (Yergey 1983) combined with a recursive \ncomputation (Claesen et al. 2012), and Fourier Transformation for a more efficient convolution of the isotope distributions of \nindividual elements (Rockwood et al. 1995), or rely on dynamic programming (Snider 2007).\n\n\u003E MIDAs (Alves and Yu 2005) is one of the more elaborate algorithms to predict an isotope cluster based on a given peptide sequence. \n\u003E Simulate the isotopic cluster of the peptide sequence \u2018PEPTIDES\u2019 and \u2018PEPTIDEPEPTIDEPEPTIDEPEPTIDES\u2019 with natural occurring isotope abundances.\n\n*)\n\n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta5\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen Plotly.NET\nopen BioFSharp\n(**\n\n## Simulating Isotopic Clusters for peptides\n\nWe will use two artificial peptide sequences and translate them into their elemental composition to simulate their isotopic clusters. \nTherefore, we first define a function that maps from a peptide sequence to its formula:\n*)\n\n// Code-Block 1\n\n// create chemical formula for amino acid and add water to reflect hydrolysed state in mass spectrometer\nlet toFormula bioseq =  \n    bioseq\n    |\u003E BioSeq.toFormula\n    // peptides are hydrolysed in the mass spectrometer, so we add H2O\n    |\u003E Formula.add Formula.Table.H2O\n\n(**\nNext, we will apply our function to receive the elemental composition or chemical formula of the peptides.\n*)\n\n// Code-Block 2\n\n// translate single letter code into amino acids and create chemical formula of it.\nlet peptide_short = \n    \u0022PEPTIDES\u0022 \n    |\u003E BioSeq.ofAminoAcidString\n    |\u003E toFormula\n    \nlet peptide_long  = \n    \u0022PEPTIDEPEPTIDEPEPTIDEPEPTIDES\u0022 \n    |\u003E BioSeq.ofAminoAcidString\n    |\u003E toFormula\n    \nlet peptide_shortString =\n    peptide_short \n    |\u003E Formula.toString\n\n\nlet peptide_longString =\n    peptide_long \n    |\u003E Formula.toString\n\n(*** include-value:peptide_shortString ***)\n\n(*** include-value:peptide_longString ***)\n\n(**\nAdditionally, we need a function that maps from Formula (and charge) to the isotopic distribution. Here, we \ncan use \u0060IsotopicDistribution.MIDA.ofFormula\u0060 from the BioFSharp library. However, for convenience \n(to use the same parameter twice), we define our function \u0060generateIsotopicDistribution\u0060:\n*)\n\n// Code-Block 3\n\n// Predicts an isotopic distribution of the given formula at the given charge, \n// normalized by the sum of probabilities, using the MIDAs algorithm\nlet generateIsotopicDistribution (charge:int) (f:Formula.Formula) =\n    IsotopicDistribution.MIDA.ofFormula \n        IsotopicDistribution.MIDA.normalizeByMaxProb\n        0.01\n        0.005\n        charge\n        f\n        \n// create pattern for peptide_short\nlet isoPattern_peptide_short = \n    generateIsotopicDistribution 1 peptide_short\n\n// create pattern for peptide_long\nlet isoPattern_peptide_long = \n    generateIsotopicDistribution 1 peptide_long\n    \nisoPattern_peptide_long\n\n(*** include-it ***)\n\n\n// Code-Block 4\n\n// create one chart for both, short and long peptide isotopic patterns.     \nlet isoPatternChart = \n    [\n        Chart.Column(isoPattern_peptide_short,Name= \u0022peptide_short\u0022 )\n        |\u003E Chart.withX_AxisStyle (\u0022m/z\u0022,MinMax=(885.,895.))\n        Chart.Column(isoPattern_peptide_long,Name= \u0022peptide_long\u0022 )\n        |\u003E Chart.withX_AxisStyle (\u0022m/z\u0022,MinMax=(3230., 3240.))\n    ]\n    |\u003E Chart.Stack 2\n    |\u003E Chart.withSize (900.,600.)\n    |\u003E Chart.withTitle \u0022Isotopeclusters\u0022\n    |\u003E Chart.withY_AxisStyle \u0022intensity\u0022\nisoPatternChart\n\n(***hide***)\nisoPatternChart |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Simulating Isotopic Clusters for peptides with stable isotope labeled variant\n\nIn addition to the natural occurring isotopic distribution, the field of proteomics has benefited greatly from the ability to \nintroduce stable isotopes into peptide sequences. So called isotopic labeling refers to the introduction of a naturally low-abundance \nisotope of carbon, nitrogen, hydrogen and, in some cases, oxygen, into a peptide sequence. The isotopes commonly used are 13C, \n15N, 2H (deuterium) and 18O with natural abundances of 1.10%, 0.366%, 0.015% and 0.200%, \nrespectively (Becker 2008). Therefore, the introduction of these isotopes into a peptide sequence can be detected by \nmost modern mass spectrometers leading to a respective mass shift and the ability to separate the same peptide species within the same run.\n\n\u003E MIDAs (Alves and Yu 2005) is also able to predict isotope clusters with altered isotope abundances. Simulate the isotopic cluster \n\u003E of the peptide sequence \u2018PEPTIDES\u2019 and \u2018PEPTIDEPEPTIDEPEPTIDEPEPTIDES\u2019 with stable isotopes 15N labeling. \n\nTherefore, we define a function called \u0060label\u0060. The function maps from a formula to a formula with exchangen nitrogen isotopes. \n(Attention: Don\u0027t get confused a formula is just a FSharpMap.) \n*)\n\n// Code-Block 5\n\n/// returns a function that replaces the nitrogen atoms in a formula\n/// with the 15N isotope\nlet label formula =\n    Formula.replaceElement formula Elements.Table.N Elements.Table.Heavy.N15\n\n// Code-Block 6\n\nlet N15_peptide_short = \n    \u0022PEPTIDES\u0022 \n    |\u003E BioSeq.ofAminoAcidString\n    |\u003E toFormula\n    |\u003E label\n\nlet N15_peptide_long  = \n    \u0022PEPTIDEPEPTIDEPEPTIDEPEPTIDES\u0022 \n    |\u003E BioSeq.ofAminoAcidString\n    |\u003E toFormula\n    |\u003E label\n\n//result: N15_peptide_short\nN15_peptide_short\n(*** include-value:N15_peptide_short ***)\n\n//result: N15_peptide_long\nN15_peptide_long\n(*** include-value:N15_peptide_long ***)\n\n// Code-Block 7\n\n// create pattern for N15_peptide_short\nlet N15_isoPattern_peptide_short = \n    generateIsotopicDistribution 1 N15_peptide_short\n\n// create pattern for N15_peptide_long\nlet N15_isoPattern_peptid_long = \n    generateIsotopicDistribution 1 N15_peptide_long\n\n(***include-value:N15_isoPattern_peptide_short***)\n(***include-value:N15_isoPattern_peptid_long***)\n\n// Code-Block 8\n\n// Create two charts. Each with the related 14N and 15N isotopic clusters. Then stack them two one unit.\nlet isoPatternChart2 = \n    [\n        [\n            Chart.Column(isoPattern_peptide_short,Name= \u0022peptide_short\u0022 )\n            Chart.Column(N15_isoPattern_peptide_short,Name= \u0022N15_peptide_short\u0022 )\n        ] \n        |\u003E Chart.Combine \n        |\u003E Chart.withX_AxisStyle (\u0022m/z\u0022,MinMax=(885., 905.0))\n\n        [\n            Chart.Column(isoPattern_peptide_long,Name= \u0022peptide_long\u0022 )\n            Chart.Column(N15_isoPattern_peptid_long,Name= \u0022N15_peptide_long\u0022 )            \n        ] \n        |\u003E Chart.Combine \n        |\u003E Chart.withX_AxisStyle (\u0022m/z\u0022,MinMax=(3230.0, 3270.0))\n    ]\n    |\u003E Chart.Stack 2\n    |\u003E Chart.withTitle \u0022Isotopeclusters\u0022\n    |\u003E Chart.withY_AxisStyle \u0022intensity\u0022\nisoPatternChart2\n(***hide***)\nisoPatternChart2 |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Questions\n\n1. Does the isotopic distribution tend to vary more or less the larger a peptide sequence becomes?\n2. How does the isotopic distribution of the amino acid-sequence \u0022SEQUENCE\u0022 look like with natural and heavy N-labelling? Plot it via using the functions provided above.\n3. Which information can be drawn from the distance of two values of adjacent signals (of one isotopic cluster) regarding m/z?\n*)\n\n(**\n## References\n\n25. Yergey, J. A. A General-Approach to Calculating Isotopic Distributions for Mass-Spectrometry. Int J Mass Spectrom 52, 337\u2013349; 10.1016/0020-7381(83)85053-0 (1983).\n26. Claesen, J., Dittwald, P., Burzykowski, T. \u0026 Valkenborg, D. An efficient method to calculate the aggregated isotopic distribution and exact center-masses. Journal of the American Society for Mass Spectrometry 23, 753\u2013763; 10.1007/s13361-011-0326-2 (2012).\n27. Rockwood, A. L., Vanorden, S. L. \u0026 Smith, R. D. Rapid Calculation of Isotope Distributions. Anal Chem 67, 2699\u20132704; 10.1021/Ac00111a031 (1995).\n28. Snider, R. K. Efficient calculation of exact mass isotopic distributions. Journal of the American Society for Mass Spectrometry 18, 1511\u20131515; 10.1016/j.jasms.2007.05.016 (2007).\n29. Alves, G. \u0026 Yu, Y. K. Robust accurate identification of peptides (RAId). deciphering MS2 data using a structured library search with de novo based statistics. Bioinformatics 21, 3726\u20133732; 10.1093/bioinformatics/bti620 (2005).\n30. Becker, G. W. Stable isotopic labeling of proteins for quantitative proteomic applications. Brief Funct Genomic Proteomic 7, 371\u2013382; 10.1093/bfgp/eln047 (2008).\n*)\n"},{"uri":"/BIO-BTE-06-L-7/NB06c_Targeted_quantification_of_photosynthetic_proteins_LE.html","title":"NB06c Targeted quantification of photosynthetic proteins (Label Efficiency)\n","content":"(**\n# NB06c Targeted quantification of photosynthetic proteins (Label Efficiency)\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB06c_Targeted_quantification_of_photosynthetic_proteins_LE.ipynb)\n\n1. Label Efficiency of 15N QProteins\n2. Read in .txt as Deedle Frame\n3. Verify Limit of Detection\n    1. Pearson correlation coefficient\n4. Calculate Label Efficiency\n    1. Median Label Efficiency\n5. Midas Results\n    1. Midas Results Var 1\n    2. Midas Results Var 2\n6. Label Efficiency Conclusion Frame\n7. References\n\n*)\n\n(**\n## Label Efficiency of 15N QProteins\n\nThe amount of measured 15N QProtein quantities can, even if you pipette perfectly, vary due to a faulty label efficiency.\nThe label efficiency is an indicator on how many atoms of the designated type (here 15N) are in fact their stable isotope.\nA lower label efficiency will lead to lower quantities of the measured labeled peptides, as they will be detected on other m/z values than the predicted ones.\n*)\n\n#r \u0022nuget: FSharp.Stats, 0.4.0\u0022\n#r \u0022nuget: BioFSharp, 2.0.0-beta5\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta5\u0022\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: BIO-BTE-06-L-7_Aux, 0.0.1\u0022\n#r \u0022nuget: Deedle, 2.3.0\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen Deedle\nopen BioFSharp\nopen FSharpAux\nopen FSharp.Stats\nopen Plotly.NET\nopen FSharp.Stats.Fitting.LinearRegression.OrdinaryLeastSquares.Linear\nopen System.IO\nopen BIO_BTE_06_L_7_Aux.FS3_Aux\n\n(**\nWe will use the same auxiliary functions as in *NB06a\\_Targeted\\_quantification\\_of\\_photosynthetic\\_proteins\\_WC.ipynb*.\n*)\n\n// Code-Block 1\n\nlet colorArray = [|\u0022#E2001A\u0022; \u0022#FB6D26\u0022; \u0022#00519E\u0022; \u0022#00e257\u0022;|]\n\nlet colorForMean = \u0022#366F8E\u0022\n\nlet xAxis showGrid title titleSize tickSize = Axis.LinearAxis.init(Title=title,Showgrid=showGrid,Showline=true,Mirror=StyleParam.Mirror.All,Zeroline=false,Tickmode=StyleParam.TickMode.Auto,Ticks= StyleParam.TickOptions.Inside, Tickfont=Font.init(StyleParam.FontFamily.Arial,Size=tickSize),Titlefont=Font.init(StyleParam.FontFamily.Arial,Size=titleSize))\nlet yAxis showGrid title titleSize tickSize = Axis.LinearAxis.init(Title=title,Showgrid=showGrid,Showline=true,Mirror=StyleParam.Mirror.All,Tickmode=StyleParam.TickMode.Auto,Ticks= StyleParam.TickOptions.Inside,Tickfont=Font.init(StyleParam.FontFamily.Arial,Size=tickSize),Titlefont=Font.init(StyleParam.FontFamily.Arial,Size=titleSize))\n\nlet config = Config.init(ShowEditInChartStudio=true, ToImageButtonOptions = ToImageButtonOptions.init(Format = StyleParam.ImageFormat.SVG, Filename = \u0022praktikumsplot.svg\u0022), EditableAnnotations = [AnnotationEditOptions.LegendPosition])\n\n(**\nNext, we need a \u0060map\u0060 of all proteins present in our QconCat proteins with their corresponding peptides.\n*)\n\n// Code block 2\n\nlet peptideProtMapping =\n    [\n    //PS\n    \u0022iRT\u0022   =\u003E  \u0022LGGNEQVTR\u0022\n    \u0022LCI5\u0022  =\u003E  \u0022SALPSNWK\u0022\n    \u0022LCI5\u0022  =\u003E  \u0022SVLPANWR\u0022\n    \u0022rbcL\u0022  =\u003E  \u0022DTDILAAFR\u0022\n    \u0022rbcL\u0022  =\u003E  \u0022EVTLGFVDLMR\u0022\n    \u0022rbcL\u0022  =\u003E  \u0022FLFVAEAIYK\u0022\n    \u0022rbcL\u0022  =\u003E  \u0022LTYYTPDYVVR\u0022\n    \u0022RBCS2\u0022 =\u003E  \u0022AYVSNESAIR\u0022\n    \u0022RBCS2\u0022 =\u003E  \u0022LVAFDNQK\u0022\n    \u0022RBCS2\u0022 =\u003E  \u0022YWTMWK\u0022\n    \u0022RBCS2\u0022 =\u003E  \u0022AFPDAYVR\u0022\n    \u0022RCA1\u0022  =\u003E  \u0022VPLILGIWGGK\u0022\n    \u0022RCA1\u0022  =\u003E  \u0022IGQQLVNAR\u0022\n    \u0022RCA1\u0022  =\u003E  \u0022SLVDEQENVK\u0022\n    \u0022PCY1\u0022  =\u003E  \u0022LGADSGALEFVPK\u0022\n    \u0022PCY1\u0022  =\u003E  \u0022DDYLNAPGETYSVK\u0022\n    \u0022psaB\u0022  =\u003E  \u0022TPLANLVYWK\u0022\n    \u0022psaB\u0022  =\u003E  \u0022ALYGFDFLLSSK\u0022\n    \u0022psaB\u0022  =\u003E  \u0022TNFGIGHR\u0022\n    \u0022atpB\u0022  =\u003E  \u0022LSIFETGIK\u0022\n    \u0022atpB\u0022  =\u003E  \u0022TAPAFVDLDTR\u0022\n    \u0022petA\u0022  =\u003E  \u0022IPAGPDLIVK\u0022\n    \u0022petA\u0022  =\u003E  \u0022NILVVGPVPGK\u0022\n    \u0022petA\u0022  =\u003E  \u0022IVAITALSEK\u0022\n    \u0022petA\u0022  =\u003E  \u0022YPIYFGGNR\u0022\n    \u0022FNR1\u0022  =\u003E  \u0022LYSIASSR\u0022\n    \u0022FNR1\u0022  =\u003E  \u0022LDYALSR\u0022\n    \u0022D1\u0022    =\u003E  \u0022VLNTWADIINR\u0022\n    \u0022D1\u0022    =\u003E  \u0022EWELSFR\u0022\n    \u0022D1\u0022    =\u003E  \u0022NTWADIINR\u0022\n    \u0022D1\u0022    =\u003E  \u0022LIFQYASFNNSR\u0022\n    \u0022LCI5\u0022  =\u003E  \u0022TALPADWR\u0022\n    \u0022psbD\u0022  =\u003E  \u0022LVFPEEVLPR\u0022\n    \u0022psbD\u0022  =\u003E  \u0022NILLNEGIR\u0022\n    \u0022psbD\u0022  =\u003E  \u0022TWFDDADDWLR\u0022\n    //CBC\n    \u0022PGK\u0022   =\u003E  \u0022ADLNVPLDK\u0022\n    \u0022PGK\u0022   =\u003E  \u0022TFNDALADAK\u0022\n    \u0022PGK\u0022   =\u003E  \u0022LSELLGKPVTK\u0022\n    \u0022Gap3\u0022  =\u003E  \u0022AVSLVLPSLK\u0022\n    \u0022Gap3\u0022  =\u003E  \u0022VLITAPAK\u0022\n    \u0022FBA3\u0022  =\u003E  \u0022ALQNTVLK\u0022\n    \u0022FBA3\u0022  =\u003E  \u0022VMFEGILLK\u0022\n    \u0022FBA3\u0022  =\u003E  \u0022SVVSIPHGPSIIAAR\u0022\n    \u0022FBP1\u0022  =\u003E  \u0022VPLFIGSK\u0022\n    \u0022FBP1\u0022  =\u003E  \u0022TLLYGGIYGYPGDAK\u0022\n    \u0022FBP1\u0022  =\u003E  \u0022IYSFNEGNYGLWDDSVK\u0022\n    \u0022SBP\u0022   =\u003E  \u0022LTNITGR\u0022\n    \u0022SBP\u0022   =\u003E  \u0022LLFEALK\u0022\n    \u0022TRK1\u0022  =\u003E  \u0022FLAIDAINK\u0022\n    \u0022TRK1\u0022  =\u003E  \u0022VSTLIGYGSPNK\u0022\n    \u0022TRK1\u0022  =\u003E  \u0022NPDFFNR\u0022\n    \u0022RPE1\u0022  =\u003E  \u0022FIESQVAK\u0022\n    \u0022RPE1\u0022  =\u003E  \u0022GVNPWIEVDGGVTPENAYK\u0022\n    \u0022RPE1\u0022  =\u003E  \u0022SDIIVSPSILSADFSR\u0022\n    \u0022PRK1\u0022  =\u003E  \u0022IYLDISDDIK\u0022\n    \u0022PRK1\u0022  =\u003E  \u0022VAELLDFK\u0022\n    \u0022PRK1\u0022  =\u003E  \u0022GHSLESIK\u0022\n    \u0022TPI1\u0022  =\u003E  \u0022SLFGESNEVVAK\u0022\n    \u0022TPI1\u0022  =\u003E  \u0022LVDELNAGTIPR\u0022\n    \u0022RPI1\u0022  =\u003E  \u0022LANLPEVK\u0022\n    \u0022RPI1\u0022  =\u003E  \u0022LQNIVGVPTSIR\u0022\n    \u0022RPI1\u0022  =\u003E  \u0022TQLSQDELK\u0022\n    \u0022DP12\u0022  =\u003E  \u0022SGQPAVDLNK\u0022\n    \u0022DP12\u0022  =\u003E  \u0022ASGQPAVDLNK\u0022\n    \u0022RMT1\u0022  =\u003E  \u0022AEAALLVR\u0022\n    \u0022RMT1\u0022  =\u003E  \u0022SNSTPLGSR\u0022\n    \u0022FBA1\u0022  =\u003E  \u0022GILASDESNATTGK\u0022\n    \u0022FBA1\u0022  =\u003E  \u0022ALQSSTLK\u0022\n    \u0022FBA2\u0022  =\u003E  \u0022VSAADVAR\u0022\n    \u0022FBA2\u0022  =\u003E  \u0022ALQASVLK\u0022\n    \u0022Cre07.g338451\u0022 =\u003E  \u0022VTEAAALASGR\u0022\n    \u0022FBP1\u0022  =\u003E  \u0022NLALELVR\u0022\n    \u0022CalSciex\u0022  =\u003E  \u0022SAEGLDASASLR\u0022\n    ]\n    |\u003E List.map (fun (x,y) -\u003E y,x)\n    |\u003E Map.ofList\n\npeptideProtMapping\n\n(***include-it***)\n\n(**\nAfter we got our peptide \u0026#8594; protein map, we need a \u0060map\u0060 for the files we want to analyze. For that we need the filename and a description of what \nthe file contains (experiment, spiked in peptide concentration).\nThis will be used as a schema for the .txt reader later on.\n*)\n\n// Code block 3\n\nlet labelEfficiencyNameMapping = \n    [\n    // filename(from QuantifiedPeptides.txt) =\u003E (\u0022LabelEfficiency\u0022, (\u0022Descriptive Text\u0022, Dilution))\n    \u0022G1 q1 zu 0.00032\u0022  =\u003E  (\u0022LabelEfficiency\u0022, (\u002215N Q \u002B 14N Q\u0022,           0.00032 ))\n    \u0022G1 q1 zu 0.0016\u0022   =\u003E  (\u0022LabelEfficiency\u0022, (\u002215N Q \u002B 14N Q\u0022,           0.0016  ))\n    \u0022G1 q1 zu 0.008\u0022    =\u003E  (\u0022LabelEfficiency\u0022, (\u002215N Q \u002B 14N Q\u0022,           0.008   ))\n    \u0022G1 q1 zu 0.04\u0022     =\u003E  (\u0022LabelEfficiency\u0022, (\u002215N Q \u002B 14N Q\u0022,           0.04    ))\n    \u0022G1 q1 zu 0.2\u0022      =\u003E  (\u0022LabelEfficiency\u0022, (\u002215N Q \u002B 14N Q\u0022,           0.2     ))\n    \u0022G1 Q1 zu 1zu 1\u0022    =\u003E  (\u0022LabelEfficiency\u0022, (\u002215N Q \u002B 14N Q \u002B 13C Q\u0022,   1.      ))\n    ]\n    |\u003E Map.ofList\n\nlabelEfficiencyNameMapping\n\n(***include-it***)\n\n(**\n## Read in .txt as Deedle Frame \nIn the first step we will just read in the data with the correct data types and assign it with descriptive rowKeys\n*)\n\n// Code block 4\n\nlet readQConcatResultFrame p : Frame\u003Cstring*(bool*int),string\u003E=\n    // read in .txt as deedle frame\n    let schemaFrame =\n        Frame.ReadCsv(path = p,separators=\u0022\\t\u0022)\n    // when creating deedle frames from files, the program can not always assume the correct type for all entries.\n    // Therefore we give it a list of all type defitions for all columns.\n    let schema =\n        schemaFrame.ColumnKeys\n        // only three tables are not float and these are the ones we filter out in the next step\n        |\u003E Seq.filter (fun x -\u003E not (x = \u0022StringSequence\u0022 || x = \u0022GlobalMod\u0022 || x = \u0022Charge\u0022))\n        // add float definition to all columns\n        |\u003E Seq.map (sprintf \u0022%s=float\u0022)\n        // specify the previously filtered out columns with the correct type defitions\n        |\u003E Seq.append [\u0022StringSequence=string\u0022;\u0022GlobalMod=bool\u0022;\u0022Charge=int\u0022]\n        |\u003E String.concat \u0022,\u0022\n    // read in the file again, this time with the correct types indicates as by schema\n    Frame.ReadCsv(path = p,schema=schema,separators=\u0022\\t\u0022)\n    // schemaFrames rows are labeled with increasing numbers, we want to give them unique descriptive keys.\n    // In this case we will use their peptideSequence (for example \u0022LVFPEEVLPR\u0022), the global modifier and charge\n    |\u003E Frame.indexRowsUsing (fun os -\u003E (os.GetAs\u003Cstring\u003E(\u0022StringSequence\u0022),((os.GetAs\u003Cbool\u003E(\u0022GlobalMod\u0022),(os.GetAs\u003Cint\u003E(\u0022Charge\u0022))))))\n    // as we now have the information about seq, global mod and charge in the row keys we can drop the origin columns.\n    |\u003E Frame.dropCol \u0022StringSequence\u0022\n    |\u003E Frame.dropCol \u0022GlobalMod\u0022\n    |\u003E Frame.dropCol \u0022Charge\u0022\n    |\u003E Frame.sortRowsByKey\n\nlet directory = __SOURCE_DIRECTORY__\nlet path = Path.Combine[|directory;\u0022downloads/Group1/G1_Q1_zu_1zu_1_QuantifiedPeptides.txt\u0022|]\ndownloadFile path \u0022G1_Q1_zu_1zu_1_QuantifiedPeptides.txt\u0022 \u0022bio-bte-06-l-7/Group1\u0022\n    \n/// DO NOT CHANGE THIS NAME! This value will be used in further code blocks.\n/// Insert your path to your QuantifiedPeptides.txt file for your label efficiency (only QProteins) here.\nlet qConCatResults =\n    readQConcatResultFrame path\n    \n// This part is only meant to show you the current state of your data  \nqConCatResults\n|\u003E Frame.sliceCols (qConCatResults.ColumnKeys |\u003E Array.ofSeq |\u003E fun x -\u003E x.[0..2])\n|\u003E fun x -\u003E x.Print()\n\nqConCatResults\n\n(***include-it***)\n\n(**\nNext we apply all our label \u0060map\u0060s to the data and filter to reduce the information to only include necessary data for these functions.\nPay attention to the all caps comment in the code below!\n*)\n\n// Code block 5\n\nlet labelEfficiencyResults : Frame\u003Cstring*(string*(string*float)),(string*(string*int))\u003E = \n    qConCatResults\n    // first use our \u0022labelEfficiencyNameMapping\u0022 to correctly label all columns\n    |\u003E Frame.mapColKeys \n        (fun (ck:string) -\u003E \n            let newCK = Map.find (ck.Split(\u0027_\u0027).[1 ..] |\u003E String.concat \u0022_\u0022) labelEfficiencyNameMapping\n            ck.Split(\u0027_\u0027).[0] , newCK\n        )\n    |\u003E Frame.sortColsByKey\n    // filter out all extra information noted in the file, but not needed for now.\n    |\u003E Frame.filterCols (fun ck _ -\u003E (fst ck).Contains(\u0022Quant\u0022) || (fst ck).Contains(\u0022N15MZ\u0022) || (fst ck).Contains(\u0022N15Minus1MZ\u0022))\n    // get mean values for all peptides, for which we found different charged versions.\n    |\u003E Frame.applyLevel (fun (sequence,(gmod,charge)) -\u003E sequence,charge) Stats.mean\n    // swap rows and columns\n    |\u003E Frame.transpose\n    // map over \u0022peptideProtMapping\u0022 to assign a related protein to all peptide sequences.\n    |\u003E Frame.mapColKeys\n        (fun ck -\u003E\n            match Map.tryFind (fst ck) peptideProtMapping with\n            |Some prot  -\u003E prot,ck\n            |None       -\u003E \u0022NotFound\u0022,ck\n        )\n    // THE FOLLOWING PART IS ONLY MEANT TO EASE ACCESS TO THESE FUNCTIONS AS FILTERING FOR ONLY \n    // RBCL GREATLY REDUCES THE COMPUTATION TIME. PLEASE REMOVE THIS FUNCTION AFTER YOU FAMILIARIZED \n    // YOURSELF WITH THE CODE AND OUTPUT TO ANALYZE ALL PROTEINS \n    |\u003E Frame.filterCols (fun ck cs -\u003E fst ck = \u0022rbcL\u0022)\n    \n// This part is only meant to show you the current state of your data  \nlabelEfficiencyResults\n|\u003E Frame.sliceCols (labelEfficiencyResults.ColumnKeys |\u003E Array.ofSeq |\u003E fun x -\u003E x.[0..1])\n//|\u003E Frame.filterCols (fun ck cs -\u003E fst ck = \u0022rbcL\u0022 \u0026\u0026 ((snd \u003E\u003E fst) ck = \u0022FLFVAEAIYK\u0022 || (snd \u003E\u003E fst) ck = \u0022EVTLGFVDLMR\u0022))\n|\u003E fun x -\u003E x.Print()\n\nlabelEfficiencyResults\n\n(***include-it***)\n\n(**\nIn the following we define helper functions and record types to increase readability/accessability for our code.\n*)\n\n// Code block 6\n\nopen Isotopes\nopen Elements\n\nlet initlabelN15Partial n15Prob =\n    ///Diisotopic representation of nitrogen with abundancy of N14 and N15 swapped\n    let n14Prob = 1. - n15Prob\n    let N15 = Di (createDi \u0022N15\u0022 (Isotopes.Table.N15,n15Prob) (Isotopes.Table.N14,n14Prob) )\n    fun f -\u003E Formula.replaceElement f Elements.Table.N N15\n\n//let labelFullN15 =\n//    let N15 = Elements.Table.Heavy.N15\n//    fun f -\u003E Formula.replaceElement f Elements.Table.N N15\n\nlet generateIsotopicDistributionOfFormulaBySum (charge:int) (f:Formula.Formula) =\n    IsotopicDistribution.MIDA.ofFormula \n        IsotopicDistribution.MIDA.normalizeByProbSum\n        0.01\n        0.001\n        charge\n        f\n\nlet generateIsotopicDistributionOfFormulaByMax (charge:int) (f:Formula.Formula) =\n    IsotopicDistribution.MIDA.ofFormula \n        IsotopicDistribution.MIDA.normalizeByMaxProb\n        0.01\n        0.001\n        charge\n        f\n\ntype LabelEffCollector = \n    {\n        Dilution: float\n        N15Minus1Quant: float\n        N15Quant:float\n        N15Minus1MOverZ: float\n        N15MOverZ: float\n    }\n    \n    static member create n15Minus1quant n15quant n15Minus1MOverZ n15MOverZ dilution = {\n        Dilution            = dilution\n        N15Minus1Quant      = n15Minus1quant\n        N15Quant            = n15quant\n        N15Minus1MOverZ     = n15Minus1MOverZ\n        N15MOverZ           = n15MOverZ\n    }\n    \ntype LabelEffCollectorLinearity = \n    {\n        Dilution        : float []\n        N14ToN15Quant   : float []\n        Protein         : string\n        Peptide         : string\n        Charge          : int\n        PCoEff          : Vector\u003Cfloat\u003E option\n        PFitVals        : float [] option\n        PDetermination  : float option\n    }\n    \n    static member create dil n14n15 prot pept charge coeff fitvals deter =\n        {\n            Dilution        = dil\n            N14ToN15Quant   = n14n15\n            Protein         = prot\n            Peptide         = pept \n            Charge          = charge\n            PCoEff          = coeff\n            PFitVals        = fitvals\n            PDetermination  = deter\n        }\n\n(**\n## Verify Limit of Detection\n\u0060getLabelData\u0060 filters the data for the given dilutions and returns relative quantifications for each peptide. \nAdditionally, it also tells us the corresponding protein and the charge of the peptide.\n*)\n\n// Code block 7\n\nlet dilutionArr = [|0.00032;0.0016;0.008;0.04;0.2;1.|]\n\nlet getLabelData dilutionArr= \n    labelEfficiencyResults\n    // drop all columns with missing values\n    |\u003E Frame.dropSparseCols\n    // filter for dilutions of interest\n    |\u003E Frame.filterRows (fun (prot,(_,(fileName,dilution))) rs -\u003E Array.exists (fun x -\u003E x = dilution) dilutionArr)\n    // break frame format and start working on arrays\n    |\u003E fun x -\u003E \n        x\n        |\u003E Frame.toArray2D\n        |\u003E Array2D.toJaggedArray\n        |\u003E JaggedArray.transpose\n        |\u003E Array.zip (x.ColumnKeys |\u003E Array.ofSeq)\n        //Calculate fully/uncompletely labeled peak ratio\n        |\u003E Array.map \n            (fun ((prot,(pepSeq,charge)),values) -\u003E \n                // we use multiple dilutions of 15N and we can calculate a label efficiency for each of them and\n                // take the mean in the end, as all originate from the same QProtein sample. This could also\n                // show differences in measured label efficiency for high or low sample quantities.\n                let quant, dil =\n                    Array.init\n                        dilutionArr.Length\n                        (fun ind -\u003E\n                            [|for num in ind .. dilutionArr.Length .. values.Length-1 do\n                                yield values.[num]|]\n                        )\n                    |\u003E Array.mapi (fun i values -\u003E \n                        // 14N/15N, dilution\n                        values.[0]/values.[4], 1./dilutionArr.[i]\n                    )\n                    |\u003E Array.sortBy snd\n                    |\u003E Array.unzip\n                LabelEffCollectorLinearity.create dil quant prot pepSeq charge None None None\n            )\n    \n/// DO NOT CHANGE THIS NAME! This value will be used in further code blocks.\n/// Insert a dilution array with the dilutions you want to include\nlet labelData = getLabelData dilutionArr\n\n// This part is only meant to show you the current state of your data  \nlabelData\n\n(***include-it***)\n\n(**\n### Pearson correlation coefficient\nTesting the limit of detection can be done with a dilution array and the [pearson coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient).\n As you should assume a rather low pipetting error you can check the mass spectrometry detection for all \n QProtein peptides with this experiment. If for any peptide the pearson coefficient is not high (so the relation would be non-linear) \n the mass spectrometry was not able to detect the small quantities for some of the given dilutions and therefore underestimated the real amount of QProtein.\n*)\n\n// Code block 8\n\n// Use the \u0022labelData\u0022 to calculate the pearson coefficient for the measured data points for all dilutions for each peptide\nlet lEInfo =\n    labelData\n    |\u003E Array.map (fun peptVal -\u003E\n        peptVal.N14ToN15Quant\n        |\u003E fun strainVals -\u003E\n            // RBCL Regression of relative quantification values\n            let RBCLcoeff = Univariable.coefficient (vector peptVal.Dilution) (vector strainVals)\n            let RBCLfitFunc = Univariable.fit RBCLcoeff\n            let RBCLfitVals = peptVal.Dilution |\u003E Array.map RBCLfitFunc\n            let RBCLdetermination = FSharp.Stats.Fitting.GoodnessOfFit.calculateDeterminationFromValue strainVals RBCLfitVals\n            let RBCLpearson = FSharp.Stats.Correlation.Seq.pearson strainVals peptVal.Dilution\n            printfn \u0022Pearson WholeCell [%s]-%s @ z=%i: %f\u0022 peptVal.Protein peptVal.Peptide peptVal.Charge RBCLpearson\n            {peptVal with \n                PCoEff = Some RBCLcoeff; \n                PFitVals = Some RBCLfitVals; \n                PDetermination = Some RBCLdetermination}\n    )\n\nlEInfo\n\n(***include-it***)\n\n(**\nThose graphs shows the linearity of the peptides for our protein by displaying the single data points and their linear fit.\n*)\n\n// Code block 9\n\nlet showLinearity  =\n\n    lEInfo\n    |\u003E Array.groupBy (fun x -\u003E x.Protein)\n    |\u003E Array.map (fun (_,valArr) -\u003E\n        valArr\n        |\u003E Array.map (fun peptVal -\u003E\n            [\n                Chart.Point (Array.zip peptVal.Dilution peptVal.N14ToN15Quant,Name = sprintf \u0022[%s]-%s @z=%i Quantified Ratios\u0022 peptVal.Protein peptVal.Peptide peptVal.Charge)\n                |\u003E Chart.withMarkerStyle(Size=10,Symbol = StyleParam.Symbol.Cross)\n                Chart.Line(Array.zip peptVal.Dilution peptVal.PFitVals.Value,Name = (sprintf \u0022%s linear regression: %.2f x \u002B (%2f);\u003Cbr\u003E R\u003Csup\u003E2\u003C/sup\u003E = %.4f\u0022 peptVal.Peptide peptVal.PCoEff.Value.[1] peptVal.PCoEff.Value.[0] peptVal.PDetermination.Value))\n                |\u003E Chart.withLineStyle(Color=\u0022lightblue\u0022,Dash=StyleParam.DrawingStyle.DashDot)\n            ] \n            |\u003E Chart.Combine\n        )\n        |\u003E Chart.Combine\n        |\u003E Chart.withTitle ((Array.head valArr).Protein \u002B \u0022 N15 QProtein Dilution\u0022)\n        |\u003E Chart.withY_Axis (yAxis false \u0022N14 / N15 Peak instensity ratio\u0022 20 16)\n        |\u003E Chart.withX_Axis (xAxis false \u0022Dilution of N15 Q Protein\u0022 20 16)\n        |\u003E Chart.withConfig config\n        |\u003E Chart.withMargin (Margin.init(Right=400))\n        |\u003E Chart.withSize (900.,600.)\n    )\n    \nshowLinearity\n|\u003E Array.head\n\n(***hide***)\nshowLinearity |\u003E Array.head |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n## Calculate Label Efficiency\n\u0060prepareLabelEfficiencyResults\u0060 extracts all the information needed for label efficiency determination from our read-in mass \nspectrometry results for the given dilutions.\n*)\n\n// Code block 10\n\nlet prepareLabelEfficiencyResults (dilutionArr:float []) =\n    labelEfficiencyResults\n    |\u003E Frame.filterRows \n        (fun (rk,_) _ -\u003E not (rk.Contains(\u0022N14\u0022)))\n    |\u003E Frame.dropSparseCols\n    |\u003E fun x -\u003E \n        x\n        |\u003E Frame.toArray2D\n        |\u003E Array2D.toJaggedArray\n        |\u003E JaggedArray.transpose\n        |\u003E Array.zip (x.ColumnKeys |\u003E Array.ofSeq)\n        //Calculate fully/uncompletely labeled peak ratio\n        //|\u003E Array.find (fun x -\u003E (fst \u003E\u003E fst) x = \u0022rbcL\u0022)\n        |\u003E Array.map \n        //|\u003E\n            (fun (key,values) -\u003E \n                key,\n                // we use multiple dilutions of N15 and we can calculate a label efficiency for each of them and\n                // take the mean in the end, as all originate from the same QProtein sample. This could also\n                // show differences in measured label efficiency for high or low sample quantities.\n                Array.init\n                    dilutionArr.Length\n                    (fun ind -\u003E\n                        [|for num in ind .. dilutionArr.Length .. values.Length-1 do\n                            yield values.[num]|]\n                    )\n                |\u003E Array.mapi (fun i values -\u003E \n                    LabelEffCollector.create values.[1] values.[3] values.[0] values.[2] dilutionArr.[i]\n                )\n            )\n            \nlet preparedLabelEfficiencyResults =\n    prepareLabelEfficiencyResults dilutionArr\n\npreparedLabelEfficiencyResults\n|\u003E Array.head\n\n(***include-it***)\n\n(**\nHere MIDAS calculates a label efficiency with corresponding isotopic distribution for our peptides.\n*)\n\n// Code block 11\n\n// This function may take several minutes with up to an hour depending on the number of peptides and dilutions of interest\n// Here, theoretical isotopic spectra are created and compared with the measured spectra.\nlet labelEfficiency =\n    preparedLabelEfficiencyResults\n    |\u003E Array.collect \n        (fun ((prot,(peptideSequence,charge)),labelEffCollectorArr) -\u003E\n\n            let calculateLabelEffs (labelEffCollect:LabelEffCollector) =\n            \n                // ratio between the N15 peak and the N15-1 peak\n                let peakRatio = labelEffCollect.N15Minus1Quant / labelEffCollect.N15Quant\n                //printfn \u0022peakRatio: %A\u0022 peakRatio\n                \n                // get chemical information about petide sequence\n                let peptide =\n                    peptideSequence\n                    |\u003E BioArray.ofAminoAcidString\n                    |\u003E BioSeq.toFormula\n                //printfn \u0022peptide: %A\u0022 peptide\n\n                // create theoretical isotopic distributions for label efficiency 0.5 .. 0.001 .. 0.999\n                let theoreticalIsotopicDistributions =\n                    [for le in 0.5 .. 0.001 .. 0.999 do\n                         yield\n                             le,\n                             peptide\n                             |\u003E initlabelN15Partial le\n                             |\u003E Formula.add Formula.Table.H2O\n                             |\u003E generateIsotopicDistributionOfFormulaByMax charge\n                    ]\n\n                \n                let theoreticalRatios =\n                    theoreticalIsotopicDistributions\n                    // get all theoretical probabilities for the N15 and N15-1 peak\n                    |\u003E List.map \n                        (fun (le,dist) -\u003E\n                            let n15Prob = \n                                dist\n                                // get the value from the list, for which the theoretical mz is closest to the\n                                // measured m/z\n                                |\u003E List.minBy \n                                    (fun (mz,prob) -\u003E\n                                        abs (labelEffCollect.N15MOverZ - mz)\n                                    )\n                                // get probabilitie for the closest theoretical peak\n                                |\u003E snd\n                            \n                            let n15Minus1Prob = \n                                dist\n                                // get the value from the list, for which the theoretical mz is closest to the\n                                // measured m/z\n                                |\u003E List.minBy \n                                    (fun (mz,prob) -\u003E\n                                        //old: abs (n15Minus1MZ - mz)\n                                        abs (labelEffCollect.N15Minus1MOverZ - mz)\n                                    )\n                                // get probabilitie for the closest theoretical peak\n                                |\u003E snd\n                            // return le and dist and the theoretical probability (n15Minus1Prob / n15Prob)\n                            le,(n15Minus1Prob / n15Prob), dist\n                        )\n\n                // get the theoretical le,ratio,dist that features the lowest difference in N15-1/N15 \n                // peak ratio between the theoretical and the measured distributions\n                let bestLE = \n                    theoreticalRatios\n                    |\u003E List.minBy\n                        (fun (le,ratio,dist) -\u003E\n                            abs (peakRatio - ratio)\n                        )\n                // header information about protein, peptide, charge\n                (prot,(peptideSequence,charge)),\n                // LabelEffCollector Record type; saved information from measured data\n                labelEffCollect,\n                // found best fitting theoretical le, ratio and isotopic distribution\n                bestLE\n            labelEffCollectorArr\n            |\u003E Array.map calculateLabelEffs\n        )\n\nlabelEfficiency |\u003E Array.head\n\n(***include-it***)\n\n(**\n### Median Label Efficiency\nIn the following, we will determine outlier borders for our calculated label efficiencies. \nWe will do this via [tukey outlier calculation](https://en.wikipedia.org/wiki/Outlier).\n*)\n\n// Code block 12\n\n// Drop all information except protein, peptide, dilution and le.\nlet allPredictedLE =\n    labelEfficiency\n    |\u003E Array.map \n        (fun ((prot,(peptideSequence,charge)),experimentalDist,(le,ratio,dist)) -\u003E\n            (prot,peptideSequence,experimentalDist.Dilution),le\n        )\n        \n// calculate outlier borders with tukey (n=3)\nlet outlierBorders = FSharp.Stats.Testing.Outliers.tukey 3. (allPredictedLE |\u003E Array.map snd)\n\nallPredictedLE\n\n(***include-it***)\n\noutlierBorders\n\n(***include-it***)\n\n// Code block 13\n\n//Boxplot with outlier borders\nlet showLEsBoxPlot =\n    allPredictedLE\n    |\u003E Array.unzip\n    |\u003E fun (header,leValues) -\u003E \n        [\n            Chart.BoxPlot(\n                x = (\n                    allPredictedLE\n                    |\u003E Array.filter (fun (keys,eff) -\u003E eff \u003C outlierBorders.Upper \u0026\u0026 eff \u003E outlierBorders.Lower)\n                    |\u003E Array.map snd\n                ),\n                Jitter = 0.3,\n                Boxpoints=StyleParam.Boxpoints.All,\n                Name=\u0022Measured Label \u003Cbr\u003E Efficiencies\u0022\n                )\n            Chart.BoxPlot(x=leValues,Jitter = 0.3,Boxpoints=StyleParam.Boxpoints.All,Name=\u0022Measured Label \u003Cbr\u003E Efficiencies - \u003Cbr\u003E without outliers\u0022)\n            |\u003E Chart.withShapes \n                [\n                    (Shape.init(StyleParam.ShapeType.Line, X0 = outlierBorders.Upper, X1 = outlierBorders.Upper, Y0 = -0.4, Y1 = 1.4))\n                    (Shape.init(StyleParam.ShapeType.Line, X0 = outlierBorders.Lower, X1 = outlierBorders.Lower, Y0 = -0.4, Y1 = 1.4))\n                ]\n        ]\n    |\u003E Chart.Combine\n    |\u003E Chart.withX_Axis (yAxis false \u0022N15 / N15 - 1 m/z Peak instensity ratio\u0022 20 16)\n    |\u003E Chart.withY_Axis (xAxis false \u0022\u0022 20 16)\n    |\u003E Chart.withMargin (Margin.init(Left=200))\n    |\u003E Chart.withTitle \u0022Label efficiency - Outlier detection\u0022\n    // adjust chart size\n    |\u003E Chart.withSize (1200.,600.)\n    |\u003E Chart.withConfig config\n\n// You can use this function to find peptides of a specific LE of interest, which you found on the box blot.\nlet findPeptideOfLE le =\n    let foundVals =\n        allPredictedLE\n        |\u003E Array.filter (fun x -\u003E snd x = le)\n    if foundVals |\u003E Array.isEmpty then failwithf \u0022We could not find any label efficiency at the given value: %.3f\u0022 le\n    else foundVals\n\nfindPeptideOfLE 0.972 \n\n(***include-it***)\n\n///// Use this function for an added description below the chart\n//showLEs\n//|\u003E Chart.ShowWithDescription\n//    {Heading = \u0022Borders From tukey outlier detection with k = 3:\u0022; Text = sprintf \u0022Upper: %.3f \u003Cbr\u003E\u003C/br\u003ELower: %.3f\u0022 outlierBorders.Upper outlierBorders.Lower}\n\nshowLEsBoxPlot\n\n(***hide***)\nshowLEsBoxPlot |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n// Code block 14\n\n// Calculate the median label efficiency for all LE inside the borders given by the tukey outlier test\nlet filteredOverallPredictedLabelEfficiency =\n    allPredictedLE\n    |\u003E Array.filter (fun (keys,eff) -\u003E eff \u003C outlierBorders.Upper \u0026\u0026 eff \u003E outlierBorders.Lower)\n    |\u003E Array.map snd\n    |\u003E Seq.median \n\nfilteredOverallPredictedLabelEfficiency\n\n(***include-it***)\n\n(**\n## Midas Results\nFrom here on you will find functions for charts displaying midas results on a single peptide basis. \nThe two available options differ in complexity and it is not necessary to understand 100% of the code used. \nBut it can be useful to change parameters for the chart creation and adjust them for your needs.\n*)\n(**\n### Midas Results Var 1\nThis Variant shows basic information to the midas label efficiency calculation for all peptides of any protein.\n*)\n\n// Code block 15\n\nlet showLabelEfficiencyChartsSimple =\n    labelEfficiency\n    |\u003E Array.groupBy (fun ((prot,(peptideSequence,charge)),experimentalDist,(le,ratio,dist)) -\u003E prot,peptideSequence,charge)\n    |\u003E Array.map (\n        fun ((prot,peptideSequence,charge),arr) -\u003E\n            prot,\n            peptideSequence,\n            arr\n            |\u003E Array.sortByDescending (fun ((prot,(peptideSequence,charge)),experimentalDist,(le,ratio,dist)) -\u003E experimentalDist.Dilution)\n            |\u003E Array.map (fun ((prot,(peptideSequence,charge)),experimentalDist,(le,ratio,dist)) -\u003E\n                let normExperimental =\n                    experimentalDist\n                    |\u003E fun x -\u003E\n                        List.zip\n                            [x.N15Minus1MOverZ;x.N15MOverZ]\n                            (\n                                [x.N15Minus1Quant; x.N15Quant]\n                                |\u003E fun vals -\u003E \n                                    let max = List.max vals\n                                    vals\n                                    |\u003E List.map (fun v -\u003E v / max)\n                            )\n                [\n                    dist\n                    |\u003E List.map (fun (x,y) -\u003E [(x,0.);(x,y);(x,0.)])\n                    |\u003E List.concat\n                    |\u003E Chart.Line\n                    |\u003E Chart.withTraceName (sprintf \u0022[%s] %s : PID @ %.3f \u0022 prot peptideSequence le)\n                    Chart.Point(normExperimental,Name= sprintf \u0022[%s] %s : Experimental Masses 1 to %s\u0022  prot peptideSequence (string experimentalDist.Dilution))\n                ]\n                |\u003E Chart.Combine\n                |\u003E Chart.withTitle (sprintf \u0022[%s] : %s @ \u002B %i\u0022 prot peptideSequence charge )\n                |\u003E Chart.withX_Axis (xAxis false \u0022\u0022 20 16)\n                |\u003E Chart.withY_Axis (yAxis false \u0022\u0022 20 16)\n                |\u003E Chart.withConfig config \n            )\n        )\n        |\u003E Array.map ( fun (prot,pepSeq,charts) -\u003E\n            charts\n            |\u003E Chart.Stack charts.Length\n            |\u003E Chart.withSize (1500.,600.)\n        )\n        \nshowLabelEfficiencyChartsSimple\n|\u003E Array.head \n\n(***hide***)\nshowLabelEfficiencyChartsSimple |\u003E Array.head |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n(**\n### Midas Results Var 2\nThe following code is used to generate in depth charts with most information about the midas calculation.\nIf variant 1 does not contain enough information, this variant can be used instead.\n*)\n\n// Code block 16\n\ntype LabelEfficiencyPredictor =\n    {\n        Protein: string\n        PeptideSequence: string\n        Charge: int\n        PredictedDistribution: (float*float) list\n        PredictedLabelEfficiency: float\n        ExperimentalDistribution: (float*float) list\n        EFCollector: LabelEffCollector\n    }\n\nlet createLabelEfficiencyPredictor p ps c pred eff exp efCollector=\n    {\n        Protein                     = p\n        PeptideSequence             = ps\n        Charge                      = c\n        PredictedDistribution       = pred\n        PredictedLabelEfficiency    = eff\n        ExperimentalDistribution    = exp\n        EFCollector                 = efCollector\n    }\n\n\ntype LabelEfficiencyResult =\n    {\n        Protein                 : string\n        PeptideSequence         : string\n        Charge                  : int\n        PredictedLabelEfficiency: float\n        PredictedPattern        : (float*float) list\n        ActualPattern           : (float*float) list\n        MedianLabelEfficiency   : float\n        MedianPattern           : (float*float) list\n        FullLabeledPattern      : (float*float) list\n        CorrectionFactor        : float\n        EFCollector             : LabelEffCollector\n    }\n\nlet createLabelEfficiencyResult p ps c predLE predP aP mLE mP flP cf efCollector=\n    {\n        Protein                     = p\n        PeptideSequence             = ps\n        Charge                      = c\n        PredictedLabelEfficiency    = predLE\n        PredictedPattern            = predP\n        ActualPattern               = aP\n        MedianLabelEfficiency       = mLE\n        MedianPattern               = mP\n        FullLabeledPattern          = flP\n        CorrectionFactor            = cf\n        EFCollector                 = efCollector\n    }\n\n// Code block 17\n\nlet labelEfficiencyResultsFinalPre =\n    labelEfficiency\n    |\u003E Array.map \n        (fun ((prot,(peptideSequence,charge)),experimentalDist,(le,ratio,dist)) -\u003E\n            let prepExperimentalDist =\n                [\n                    experimentalDist.N15Minus1MOverZ, experimentalDist.N15Minus1Quant;\n                    experimentalDist.N15MOverZ, experimentalDist.N15Quant\n                ]\n            createLabelEfficiencyPredictor prot peptideSequence charge dist le prepExperimentalDist experimentalDist\n        )\nlabelEfficiencyResultsFinalPre\n|\u003E Array.head\n\n(***include-it***)\n\n// Code block 18\n\nlet getCorrectionFactors (medianPredictedLabelEfficiency:float) (predictors: LabelEfficiencyPredictor []) =\n    predictors\n    |\u003E Array.map \n       (fun lePredictor -\u003E\n\n           let n15Minus1Mz, n15Minus1Quant =\n               lePredictor.ExperimentalDistribution.[0]\n\n           let n15Mz, n15Quant =\n               lePredictor.ExperimentalDistribution.[1]\n\n           let formulaWithH2O =\n               lePredictor.PeptideSequence\n               |\u003E BioArray.ofAminoAcidString\n               |\u003E BioSeq.toFormula\n               |\u003E Formula.add Formula.Table.H2O\n\n           let predictedWithMedianLE =\n               formulaWithH2O\n               |\u003E initlabelN15Partial medianPredictedLabelEfficiency\n               |\u003E generateIsotopicDistributionOfFormulaBySum lePredictor.Charge\n\n           let predictedWithMedianLENorm = \n               formulaWithH2O\n               |\u003E initlabelN15Partial medianPredictedLabelEfficiency\n               |\u003E generateIsotopicDistributionOfFormulaByMax lePredictor.Charge\n\n           let predictedWithFullLE = \n               formulaWithH2O\n               |\u003E initlabelN15Partial 0.99999\n               |\u003E generateIsotopicDistributionOfFormulaBySum lePredictor.Charge\n\n           let predictedWithFullLENorm =\n               formulaWithH2O\n               |\u003E initlabelN15Partial 0.99999\n               |\u003E generateIsotopicDistributionOfFormulaByMax lePredictor.Charge\n\n           let n15ProbWithMedianLE =\n               predictedWithMedianLE\n               |\u003E List.minBy   \n                   (fun (mz,prob) -\u003E abs (mz - n15Mz))\n\n           let n15ProbWithFullLE =\n               predictedWithFullLE\n               |\u003E List.minBy   \n                   (fun (mz,prob) -\u003E abs (mz - n15Mz))\n\n           let correctionFactor = \n               snd n15ProbWithFullLE / snd n15ProbWithMedianLE\n\n           createLabelEfficiencyResult\n               lePredictor.Protein\n               lePredictor.PeptideSequence\n               lePredictor.Charge\n               lePredictor.PredictedLabelEfficiency\n               lePredictor.PredictedDistribution\n               (\n                   lePredictor.ExperimentalDistribution\n                   |\u003E List.unzip\n                   |\u003E fun (x,y) -\u003E\n                       List.zip\n                           x\n                           (\n                               y\n                               |\u003E fun vals -\u003E \n                                   let max = List.max vals\n                                   vals\n                                   |\u003E List.map (fun v -\u003E v / max)\n                           )\n               )\n               medianPredictedLabelEfficiency\n               predictedWithMedianLENorm\n               predictedWithFullLENorm\n               correctionFactor\n               lePredictor.EFCollector\n       )\n       \nlet labelEfficiencyResultsFinal =\n    labelEfficiencyResultsFinalPre\n    |\u003E getCorrectionFactors filteredOverallPredictedLabelEfficiency\n    \nlabelEfficiencyResultsFinal\n|\u003E Array.head\n\n(***include-it***)\n\n// Code block 19\n\nlet plotLabelEfficiencyResult (leRes: LabelEfficiencyResult) =\n    [\n        leRes.FullLabeledPattern\n        |\u003E List.map (fun (x,y) -\u003E [(x,0.);(x,y);(x,0.)])\n        |\u003E List.concat\n        |\u003E Chart.Line\n        |\u003E Chart.withTraceName (sprintf \u0022Dil=%s; Fully Labeled Pattern\u0022 (string leRes.EFCollector.Dilution))\n        |\u003E Chart.withLineStyle(Color=\u0022lightgray\u0022,Width = 20)\n\n        leRes.MedianPattern\n        |\u003E List.map (fun (x,y) -\u003E [(x,0.);(x,y);(x,0.)])\n        |\u003E List.concat\n        |\u003E Chart.Line\n        |\u003E Chart.withTraceName (sprintf \u0022Dil=%s; CorrectedPattern @ Median LE of %.3f\u0022 (string leRes.EFCollector.Dilution) leRes.MedianLabelEfficiency)\n        |\u003E Chart.withLineStyle(Width = 10,Color=\u0022lightgreen\u0022)\n\n        leRes.PredictedPattern\n        |\u003E List.map (fun (x,y) -\u003E [(x,0.);(x,y);(x,0.)])\n        |\u003E List.concat\n        |\u003E Chart.Line\n        |\u003E Chart.withTraceName (sprintf \u0022Dil=%s; PredictedPattern @ %.3f LE\u0022 (string leRes.EFCollector.Dilution) leRes.PredictedLabelEfficiency)\n        |\u003E Chart.withLineStyle(Color=\u0022orange\u0022,Width = 5)\n\n        Chart.Point(leRes.ActualPattern,Name=sprintf \u0022Dil=%s; Experimental Values\u0022 (string leRes.EFCollector.Dilution))\n        |\u003E Chart.withMarkerStyle(Size = 15,Symbol = StyleParam.Symbol.X, Color = \u0022lightred\u0022)\n\n    ]\n    |\u003E Chart.Combine\n    |\u003E Chart.withX_Axis \n        (xAxis false (sprintf \u0022m/z for Dilution = %s\u0022 (string leRes.EFCollector.Dilution)) 20 16 )\n    |\u003E Chart.withY_Axis (yAxis false \u0022normalized probability\u0022 20 16)\n    |\u003E Chart.withConfig config\n\nlet showLabelEfficiencyResults =\n    labelEfficiencyResultsFinal\n    |\u003E Array.groupBy (fun x -\u003E x.Protein, x.PeptideSequence, x.Charge)\n    |\u003E Array.map (fun (header,pepSortedVals) -\u003E\n        let header = Array.head pepSortedVals\n        pepSortedVals\n        |\u003E Array.sortByDescending (fun x -\u003E x.EFCollector.Dilution)\n        |\u003E Array.map plotLabelEfficiencyResult\n        |\u003E Chart.Stack ((pepSortedVals.Length/2),Space=0.1)\n        |\u003E Chart.withTitle (sprintf \u0022[%s] : %s @ z = %i\u0022 header.Protein header.PeptideSequence header.Charge)\n        |\u003E Chart.withSize (1400.,1000.)\n    )\n    \nshowLabelEfficiencyResults\n|\u003E Array.head\n\n(***hide***)\nshowLabelEfficiencyResults |\u003E Array.head |\u003E GenericChart.toChartHTML\n(***include-it-raw***)\n\n// Code block 20\n\nlet labelEfficiencyFrame =\n    labelEfficiencyResultsFinal\n    |\u003E Array.map \n        (fun leRes -\u003E\n            (leRes.Protein,(leRes.PeptideSequence, leRes.Charge, leRes.EFCollector.Dilution)) =\u003E \n                series \n                    [\n                        \u0022PredictedLabelEfficiency\u0022      =\u003E leRes.PredictedLabelEfficiency\n                        \u0022MedianLabelEfficiency\u0022         =\u003E leRes.MedianLabelEfficiency\n                    ]\n        )\n    |\u003E frame\n    |\u003E Frame.transpose\n    \nlabelEfficiencyFrame\n\n(***include-it***)"},{"uri":"/BIO-BTE-06-L-7/NB06a_Working_With_Deedle.html","title":"NB06a Working with Deedle\n","content":"\n(**\n# NB06a Working with Deedle\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB06a_Working_With_Deedle.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB06a/NB06a_Working_With_Deedle.ipynb)\n\n[Deedle](http://bluemountaincapital.github.io/Deedle/index.html)  is an easy to use library for data and time series manipulation and for scientific \nprogramming. It supports working with structured data frames, ordered and unordered data, as well as time series.\n\nThe analysis of your data in the following notebooks will be mostly done in Deedle, so here are some explanations and examples to help you better understand \nthe analysis notebooks.\n\nWe start by loading our usual nuget packages and the Deedle package.\n*)\n\n#r \u0022nuget: Deedle, 2.3.0\u0022\n#r \u0022nuget: BioFSharp, 2.0.0-beta4\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta4\u0022\n#r \u0022nuget: BioFSharp.Mz, 0.1.5-beta\u0022\n#r \u0022nuget: BIO-BTE-06-L-7_Aux, 0.0.6\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen Plotly.NET\nopen BioFSharp\nopen BioFSharp.Mz\nopen BIO_BTE_06_L_7_Aux.FS3_Aux\nopen BIO_BTE_06_L_7_Aux.Deedle_Aux\nopen System.IO\nopen Deedle\nopen FSharp.Stats\n\n(**\n## Deedle Basics\nFamiliarize yourself with Deedle! Create a series yourself that you add to the frame \u0027persons\u0027 frame.\n*)\nlet firstNames      = Series.ofValues [\u0022Kevin\u0022;\u0022Lukas\u0022;\u0022Benedikt\u0022;\u0022Michael\u0022] \nlet coffeesPerWeek  = Series.ofValues [15;12;10;11] \nlet lastNames       = Series.ofValues [\u0022Schneider\u0022;\u0022Weil\u0022;\u0022Venn\u0022;\u0022Schroda\u0022]  \nlet group           = Series.ofValues [\u0022CSB\u0022;\u0022CSB\u0022;\u0022CSB\u0022;\u0022MBS\u0022] \nlet persons = \n    Frame.ofColumns(List.zip [\u0022fN\u0022;\u0022lN\u0022;\u0022g\u0022] [firstNames;lastNames;group])\n    |\u003E Frame.addCol \u0022cpw\u0022 coffeesPerWeek\n(***condition:ipynb***)\n#if IPYNB\npersons\n|\u003E formatAsTable \n#endif // IPYNB\n\n(**\nFollow the above scheme and create another frame that is exactly the same, but represents different persons (the frame can be small, e.g. two persons).\nUse the function Frame.merge to combine your frame and \u0027persons\u0027.\nBack to the frame \u0027persons\u0027! In the following you see a series of frame/series manipulations.\n*)\nlet coffeePerWeek\u0027 :Series\u003Cint,int\u003E = Frame.getCol (\u0022cpw\u0022) persons \nlet groupedByG :Frame\u003Cstring*int,_\u003E = persons |\u003E Frame.groupRowsBy \u0022g\u0022\nlet withOutG :Frame\u003Cstring*int,_\u003E = groupedByG |\u003E Frame.sliceCols [\u0022fN\u0022;\u0022lN\u0022;\u0022cpw\u0022]\nlet coffeePerWeek\u0027\u0027 :Series\u003Cstring*int,int\u003E= groupedByG |\u003E Frame.getCol (\u0022cpw\u0022)\nlet coffeePerWeekPerGroup = Series.applyLevel Pair.get1Of2 (Series.values \u003E\u003E Seq.sum) coffeePerWeek\u0027\u0027\n\n(**\nNow that you got to know the object \u0060Frame\u0060 which is a collection of \u0060Series\u0060, we move on to a real dataset. \nAs our dataset we take the FASTA with Chlamy proteins, select 50 random proteins, and digest them.\nThe digested peptides are represented using a record type. Deedle frames can be directly constructed from\nrecord types with \u0060Frame.ofRecords\u0060. Alternatively, a character separated file could be used as source for a Frame as well.\n*)\n\nlet path = Path.Combine[|__SOURCE_DIRECTORY__;\u0022downloads/Chlamy_JGI5_5(Cp_Mp).fasta\u0022|]\ndownloadFile path \u0022Chlamy_JGI5_5(Cp_Mp).fasta\u0022 \u0022bio-bte-06-l-7\u0022\n\nlet examplePeptides = \n    path\n    |\u003E IO.FastA.fromFile BioArray.ofAminoAcidString\n    |\u003E Seq.toArray\n    |\u003E Array.take 50\n    |\u003E Array.mapi (fun i fastAItem -\u003E\n        Digestion.BioArray.digest Digestion.Table.Trypsin i fastAItem.Sequence\n        |\u003E Digestion.BioArray.concernMissCleavages 0 0 \n        |\u003E Array.map (fun dp -\u003E\n            {|\n                PeptideSequence = dp.PepSequence\n                Protein = fastAItem.Header.Split \u0027 \u0027 |\u003E Array.head\n            |}\n        )\n    )\n    |\u003E Array.concat\n    |\u003E Array.filter (fun x -\u003E x.PeptideSequence.Length \u003E 5)\n\nlet peptidesFrame =\n    examplePeptides\n    |\u003E Frame.ofRecords\n\n(***condition:ipynb***)\n#if IPYNB\npeptidesFrame\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\npeptidesFrame |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n\n(**\nAs you can see, our columns are named the same as the field of the record type, while our rows are indexed by numbers only. It is often helpful to use a more descriptive\nrow key. In this case, we can use the peptide sequence for that. **Note** Row keys must be unique. By grouping with \u0022PeptidesSequence\u0022, we get the sequence tupled with the index as key. \nThe function \u0060Frame.reduceLevel\u0060 aggregates the rows now based on the first part of the tuple, the peptide sequence, ignoring the second part of the tuple, the index. \nThe aggregator function given to \u0060Frame.reduceLevel\u0060 aggregates each column separately.\n*)\n\nlet pfIndexedSequenceList : Frame\u003Clist\u003CAminoAcids.AminoAcid\u003E,string\u003E =\n    peptidesFrame\n    |\u003E Frame.groupRowsBy \u0022PeptideSequence\u0022\n    |\u003E Frame.dropCol \u0022PeptideSequence\u0022\n    |\u003E Frame.reduceLevel fst (fun a b -\u003E a \u002B \u0022,\u0022 \u002B b)\n\n(***condition:ipynb***)\n#if IPYNB\npfIndexedSequenceList\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\npfIndexedSequenceList |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n(**\nOur rows are now indexed with the peptide sequences. The peptide sequence is still an aarray of amino acids. For better visibility we can transform it to its string representation. \nFor that we can map over our row keys similar to an array and call the function \u0060BioList.toString\u0060 on each row key.\n*)\n\nlet pfIndexedStringSequence =\n    pfIndexedSequenceList\n    |\u003E Frame.mapRowKeys (fun rc -\u003E rc |\u003E BioList.toString)\n\n(***condition:ipynb***)\n#if IPYNB\npfIndexedStringSequence\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\npfIndexedStringSequence |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n(**\nWe now have a frame containing information about our peptides. To add additional information we can go back to the peptide array we started with and calculate \nthe monoisotopic mass, for example. The monoisotopic mass is tupled with the peptide sequence as string, the same as in our peptide frame. The resulting array\ncan then be transformed into a \u0060series\u0060\n*)\n\nlet peptidesAndMasses =\n    examplePeptides\n    |\u003E Array.distinctBy (fun x -\u003E x.PeptideSequence)\n    |\u003E Array.map (fun peptide -\u003E\n        // calculate mass for each peptide\n        peptide.PeptideSequence |\u003E BioList.toString, BioSeq.toMonoisotopicMassWith (BioItem.monoisoMass ModificationInfo.Table.H2O) peptide.PeptideSequence\n        )\n\nlet peptidesAndMassesSeries =\n    peptidesAndMasses\n    |\u003E series\n\n(**\nThe columns in frames consist of series. Since we now have a series containing our monoisotopic masses, together with the peptide sequence, we can simply add \nit to our frame and give the column a name.\n*)\n\nlet pfAddedMass =\n    pfIndexedStringSequence\n    |\u003E Frame.addCol \u0022Mass\u0022 peptidesAndMassesSeries\n\n(***condition:ipynb***)\n#if IPYNB\npfAddedMass\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\npfAddedMass |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n(**\nAlternatively, we can take a column from our frame, apply a function to it, and create a new frame from the series.\n*)\n\nlet pfChargedMass =\n    pfAddedMass\n    |\u003E Frame.getCol \u0022Mass\u0022\n    |\u003E Series.mapValues (fun mass -\u003E Mass.toMZ mass 2.)\n    |\u003E fun s -\u003E [\u0022Mass Charge 2\u0022, s]\n    |\u003E Frame.ofColumns\n\n(***condition:ipynb***)\n#if IPYNB\npfChargedMass\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\npfChargedMass |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n(**\nThe new frame has the same row keys as our previous frame. The information from our new frame can be joined with our old frame by using \u0060Frame.join\u0060.\n\u0060Frame.join\u0060 is similar to \u0060Frame.addCol\u0060, but can join whole frames at once instead of single columns.\n*)\n\nlet joinedFrame =\n    pfAddedMass\n    |\u003E Frame.join JoinKind.Left pfChargedMass\n\n(***condition:ipynb***)\n#if IPYNB\njoinedFrame\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\njoinedFrame |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)"},{"uri":"/BIO-BTE-06-L-7/NB02a_Mass_spectrometry_based_proteomics.html","title":"NB02a Mass Spectrometry Based Proteomics\n","content":"(** \n\n# NB02a Mass Spectrometry Based Proteomics\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CSBiology/BIO-BTE-06-L-7/gh-pages?filepath=NB02a_Mass_spectrometry_based_proteomics.ipynb)\n\n[Download Notebook](https://github.com/CSBiology/BIO-BTE-06-L-7/releases/download/NB02a_NB02b_NB02c/NB02a_Mass_spectrometry_based_proteomics.ipynb)\n\n1. Mass spectrometry (MS)-based proteomic\n6. References\n\n*)\n(**\n## Mass spectrometry (MS)-based proteomic\n\n![](https://raw.githubusercontent.com/CSBiology/BIO-BTE-06-L-7/main/docs/img/OmicsWorkflow.png)\n**Figure 2. Summary of a typical proteomics workflow following the bottom-up principle.**\n\nDuring sample preparation proteins are extracted from the samples and digested into peptides using proteases typically trypsin. An optional fractionation or enrichment may be applied at either the protein or peptide level to enhance the scope of identification. Peptides are separated by high-performance liquid chromatography (HPLC) and afterward transferred into the \nvacuum of the mass spectrometer mostly using electrospray ionization (ESI). Cycles of full MS including all peptide at a time followed by MS/MS of selected peptides are measured. \nThe consecutive measured MS and MS/MS spectra are then used to computationally identify and quantify the peptide sequence and infer the protein.\n\nThe proteome is understood as an entire complement of proteins in one cell, tissue or a whole organism. \nProteomics as a scientific field deals with the qualitative and quantitative analysis of protein expression patterns. \nThus, proteomics relies primarily on the ability to unambiguously identify proteins, followed by accurate quantification. \nMass spectrometry-based proteomics refers to the large-scale analysis of\nproteins using mass spectrometry, an analytical method to determine the mass of molecules. In the case of proteomics, the target \nmolecules are whole proteins or peptides.\n\nThe typical proteomics workflow is as follows (Figure 2): first, proteins are isolated from \ncells or tissues by lysis followed by biochemical fractionation or affinity selection. MS on whole proteins (top-down proteomics) \nis less sensitive and more difficult to handle when compared to MS on peptides (bottom-up proteomics), as the mass of the intact protein by \nitself is insufficient for protein identification (Breuker et al. 2008, Reid and McLuckey 2002). Therefore, the bottom-up approach is \nstandardly used, which comprises the enzymatic degradation of proteins to peptides using an endopeptidase (trypsin in most cases)\n (Olsen et al. 2004). Trypsin is advantageous as it generates peptides with C-terminally protonated amino acids to foster\n the detectability of a full ion ladder (series) in a subsequent, optional fragmentation step for sequencing. The peptides are separated by one\n or more steps of liquid chromatography (LC) and afterwards transferred into the vacuum of the mass spectrometer, where a mass spectrum\n of the peptides eluting at this time from the LC is taken (MSU\u002B00B9 spectrum or \u2018normal mass spectrum\u2019). A prioritized list of these peptides\n for fragmentation is either automatically generated or provided by the operator. These peptide ions are then fragmented by energetic collision with\n an inert gas and recorded as tandem MS spectra (MS/MS or MSU\u002B00B2 spectra). The consecutive MS and MS/MS\n spectra are then used to computationally identify the peptide\u2019s sequence and quantify its abundance (Walther and Mann 2010, Aebersold and Mann 2003).\n\n*)\n\n(** \n## References\n\n18. Breuker, K., Jin, M., Han, X., Jiang, H. \u0026 McLafferty, F. W. Top-down identification and characterization of biomolecules by mass spectrometry. Journal of the American Society for Mass Spectrometry 19, 1045\u20131053; 10.1016/j.jasms.2008.05.013 (2008).\n19. Reid, G. E. \u0026 McLuckey, S. A. \u0027Top down\u0027 protein characterization via tandem mass spectrometry. Journal of mass spectrometry : JMS 37, 663\u2013675; 10.1002/jms.346 (2002).\n20. Olsen, J. V., Ong, S.-E. \u0026 Mann, M. Trypsin cleaves exclusively C-terminal to arginine and lysine residues. Molecular \u0026 cellular proteomics : MCP 3, 608\u2013614; 10.1074/mcp.T400003-MCP200 (2004).\n21. Walther, T. C. \u0026 Mann, M. Mass spectrometry-based proteomics in cell biology. J. Cell Biol. 190, 491\u2013500; 10.1083/jcb.201004052 (2010).\n22. Aebersold, R. \u0026 Mann, M. Mass spectrometry-based proteomics. Nature 422, 198\u2013207; 10.1038/Nature01511 (2003).\n*)\n"},{"uri":"/BIO-BTE-06-L-7/Deedle.html","title":"Deedle Basics\n","content":"\n(**\n# Deedle Basics\n\n[Deedle](http://bluemountaincapital.github.io/Deedle/index.html)  is an easy to use library for data and time series manipulation and for scientific \nprogramming. It supports working with structured data frames, ordered and unordered data, as well as time series.\n\nThe analysis of your data in the following notebooks will be mostly done in Deedle, so here are some explanations and examples to help you better understand \nthe analysis notebooks.\n\nWe start by loading our usual nuget packages and the Deedle package.\n*)\n\n#r \u0022nuget: Deedle, 2.3.0\u0022\n#r \u0022nuget: BioFSharp, 2.0.0-beta4\u0022\n#r \u0022nuget: BioFSharp.IO, 2.0.0-beta4\u0022\n#r \u0022nuget: BioFSharp.Mz, 0.1.5-beta\u0022\n#r \u0022nuget: BIO-BTE-06-L-7_Aux, 0.0.5\u0022\n#r \u0022nuget: FSharp.Stats\u0022\n\n#if IPYNB\n#r \u0022nuget: Plotly.NET, 2.0.0-beta6\u0022\n#r \u0022nuget: Plotly.NET.Interactive, 2.0.0-beta6\u0022\n#endif // IPYNB\n\nopen Plotly.NET\nopen BioFSharp\nopen BioFSharp.Mz\nopen BIO_BTE_06_L_7_Aux.FS3_Aux\nopen BIO_BTE_06_L_7_Aux.Deedle_Aux\nopen System.IO\nopen Deedle\nopen FSharp.Stats\n\n(**\n## Deedle Basics\nFamiliarize yourself with Deedle! Create a series yourself that you add to the frame \u0027persons\u0027 frame.\n*)\nlet firstNames      = Series.ofValues [\u0022Kevin\u0022;\u0022Lukas\u0022;\u0022Benedikt\u0022;\u0022Michael\u0022] \nlet coffeesPerWeek  = Series.ofValues [15;12;10;11] \nlet lastNames       = Series.ofValues [\u0022Schneider\u0022;\u0022Weil\u0022;\u0022Venn\u0022;\u0022Schroda\u0022]  \nlet group           = Series.ofValues [\u0022CSB\u0022;\u0022CSB\u0022;\u0022CSB\u0022;\u0022MBS\u0022] \nlet persons = \n    Frame.ofColumns(List.zip [\u0022fN\u0022;\u0022lN\u0022;\u0022g\u0022] [firstNames;lastNames;group])\n    |\u003E Frame.addCol \u0022cpw\u0022 coffeesPerWeek\n\n#if IPYNB\npersons\n|\u003E formatAsTable \n#endif // IPYNB\n\n(**\nFollow the above scheme and create another frame that is exactly the same, but represents different persons (the frame can be small, e.g. two persons).\nUse the function Frame.merge to combine your frame and \u0027persons\u0027.\nBack to the frame \u0027persons\u0027! In the following you see a series of frame/series manipulations.\n*)\nlet coffeePerWeek\u0027 :Series\u003Cint,int\u003E = Frame.getCol (\u0022cpw\u0022) persons \nlet groupedByG :Frame\u003Cstring*int,_\u003E = persons |\u003E Frame.groupRowsBy \u0022g\u0022\nlet withOutG :Frame\u003Cstring*int,_\u003E = groupedByG |\u003E Frame.sliceCols [\u0022fN\u0022;\u0022lN\u0022;\u0022cpw\u0022]\nlet coffeePerWeek\u0027\u0027 :Series\u003Cstring*int,int\u003E= groupedByG |\u003E Frame.getCol (\u0022cpw\u0022)\nlet coffeePerWeekPerGroup = Series.applyLevel Pair.get1Of2 (Series.values \u003E\u003E Seq.sum) coffeePerWeek\u0027\u0027\n\n(**\nNow that you got to know the object \u0060Frame\u0060 which is a collection of \u0060Series\u0060, we move on to a real dataset. \nAs our dataset we take the FASTA with Chlamy proteins, select 50 random proteins, and digest them.\nThe digested peptides are represented using a record type. Deedle frames can be directly constructed from\nrecord types with \u0060Frame.ofRecords\u0060. Alternatively, a character separated file could be used as source for a Frame as well.\n*)\n\nlet path = Path.Combine[|__SOURCE_DIRECTORY__;\u0022downloads/Chlamy_JGI5_5(Cp_Mp).fasta\u0022|]\ndownloadFile path \u0022Chlamy_JGI5_5(Cp_Mp).fasta\u0022 \u0022bio-bte-06-l-7\u0022\n\nlet examplePeptides = \n    path\n    |\u003E IO.FastA.fromFile BioArray.ofAminoAcidString\n    |\u003E Seq.toArray\n    |\u003E Array.take 50\n    |\u003E Array.mapi (fun i fastAItem -\u003E\n        Digestion.BioArray.digest Digestion.Table.Trypsin i fastAItem.Sequence\n        |\u003E Digestion.BioArray.concernMissCleavages 0 0 \n        |\u003E Array.map (fun dp -\u003E\n            {|\n                PeptideSequence = dp.PepSequence\n                Protein = fastAItem.Header.Split \u0027 \u0027 |\u003E Array.head\n            |}\n        )\n    )\n    |\u003E Array.concat\n    |\u003E Array.filter (fun x -\u003E x.PeptideSequence.Length \u003E 5)\n\nlet peptidesFrame =\n    examplePeptides\n    |\u003E Frame.ofRecords\n\n(***condition:ipynb***)\n#if IPYNB\npeptidesFrame\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\npeptidesFrame |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n\n(**\nAs you can see, our columns are named the same as the field of the record type, while our rows are indexed by numbers only. It is often helpful to use a more descriptive\nrow key. In this case, we can use the peptide sequence for that. **Note** Row keys must be unique. By grouping with \u0022PeptidesSequence\u0022, we get the sequence tupled with the index as key. \nThe function \u0060Frame.reduceLevel\u0060 aggregates the rows now based on the first part of the tuple, the peptide sequence, ignoring the second part of the tuple, the index. \nThe aggregator function given to \u0060Frame.reduceLevel\u0060 aggregates each column separately.\n*)\n\nlet pfIndexedSequenceList : Frame\u003Clist\u003CAminoAcids.AminoAcid\u003E,string\u003E =\n    peptidesFrame\n    |\u003E Frame.groupRowsBy \u0022PeptideSequence\u0022\n    |\u003E Frame.dropCol \u0022PeptideSequence\u0022\n    |\u003E Frame.reduceLevel fst (fun a b -\u003E a \u002B \u0022,\u0022 \u002B b)\n\n(***condition:ipynb***)\n#if IPYNB\npfIndexedSequenceList\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\npfIndexedSequenceList |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n(**\nOur rows are now indexed with the peptide sequences. The peptide sequence is still an aarray of amino acids. For better visibility we can transform it to its string representation. \nFor that we can map over our row keys similar to an array and call the function \u0060BioList.toString\u0060 on each row key.\n*)\n\nlet pfIndexedStringSequence =\n    pfIndexedSequenceList\n    |\u003E Frame.mapRowKeys (fun rc -\u003E rc |\u003E BioList.toString)\n\n(***condition:ipynb***)\n#if IPYNB\npfIndexedStringSequence\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\npfIndexedStringSequence |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n(**\nWe now have a frame containing information about our peptides. To add additional information we can go back to the peptide array we started with and calculate \nthe monoisotopic mass, for example. The monoisotopic mass is tupled with the peptide sequence as string, the same as in our peptide frame. The resulting array\ncan then be transformed into a \u0060series\u0060\n*)\n\nlet peptidesAndMasses =\n    examplePeptides\n    |\u003E Array.distinctBy (fun x -\u003E x.PeptideSequence)\n    |\u003E Array.map (fun peptide -\u003E\n        // calculate mass for each peptide\n        peptide.PeptideSequence |\u003E BioList.toString, BioSeq.toMonoisotopicMassWith (BioItem.monoisoMass ModificationInfo.Table.H2O) peptide.PeptideSequence\n        )\n\nlet peptidesAndMassesSeries =\n    peptidesAndMasses\n    |\u003E series\n\n(**\nThe columns in frames consist of series. Since we now have a series containing our monoisotopic masses, together with the peptide sequence, we can simply add \nit to our frame and give the column a name.\n*)\n\nlet pfAddedMass =\n    pfIndexedStringSequence\n    |\u003E Frame.addCol \u0022Mass\u0022 peptidesAndMassesSeries\n\n(***condition:ipynb***)\n#if IPYNB\npfAddedMass\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\npfAddedMass |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n(**\nAlternatively, we can take a column from our frame, apply a function to it, and create a new frame from the series.\n*)\n\nlet pfChargedMass =\n    pfAddedMass\n    |\u003E Frame.getCol \u0022Mass\u0022\n    |\u003E Series.mapValues (fun mass -\u003E Mass.toMZ mass 2.)\n    |\u003E fun s -\u003E [\u0022Mass Charge 2\u0022, s]\n    |\u003E Frame.ofColumns\n\n(***condition:ipynb***)\n#if IPYNB\npfChargedMass\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\npfChargedMass |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)\n(**\nThe new frame has the same row keys as our previous frame. The information from our new frame can be joined with our old frame by using \u0060Frame.join\u0060.\n\u0060Frame.join\u0060 is similar to \u0060Frame.addCol\u0060, but can join whole frames at once instead of single columns.\n*)\n\nlet joinedFrame =\n    pfAddedMass\n    |\u003E Frame.join JoinKind.Left pfChargedMass\n\n(***condition:ipynb***)\n#if IPYNB\njoinedFrame\n|\u003E Frame.take 10\n|\u003E formatAsTable \n#endif // IPYNB\n(***hide***)\njoinedFrame |\u003E Frame.take 10 |\u003E fun x -\u003E x.Print()\n(***include-fsi-merged-output***)"}]